[
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "collections",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "collections",
        "description": "collections",
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "namedtuple",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "abc",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "urlparse",
        "importPath": "urllib.parse",
        "description": "urllib.parse",
        "isExtraImport": true,
        "detail": "urllib.parse",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageOps",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ExifTags",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageOps",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ExifTags",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageOps",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageDraw",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "ImageFont",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "yolo.utils",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG_DICT",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG_KEYS",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "get_default_args",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "yaml_save",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "TQDM_BAR_FORMAT",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "yaml_save",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "SETTINGS",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "TQDM_BAR_FORMAT",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "AUTOINSTALL",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "FONT",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "USER_CONFIG_DIR",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "TryExcept",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "emojis",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "is_docker",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "is_jupyter_notebook",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "TryExcept",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "FONT",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "USER_CONFIG_DIR",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "threaded",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG_DICT",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG_KEYS",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "yolo.utils",
        "description": "yolo.utils",
        "isExtraImport": true,
        "detail": "yolo.utils",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_suffix",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imgsz",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imgsz",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imgsz",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "print_args",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imgsz",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "git_describe",
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "isExtraImport": true,
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "attempt_download",
        "importPath": "yolo.utils.downloads",
        "description": "yolo.utils.downloads",
        "isExtraImport": true,
        "detail": "yolo.utils.downloads",
        "documentation": {}
    },
    {
        "label": "is_url",
        "importPath": "yolo.utils.downloads",
        "description": "yolo.utils.downloads",
        "isExtraImport": true,
        "detail": "yolo.utils.downloads",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "isExtraImport": true,
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "isExtraImport": true,
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "isExtraImport": true,
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "isExtraImport": true,
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "scale_boxes",
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "isExtraImport": true,
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "isExtraImport": true,
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "isExtraImport": true,
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "Profile",
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "isExtraImport": true,
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "deepcopy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "copy",
        "importPath": "copy",
        "description": "copy",
        "isExtraImport": true,
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "requests",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "requests",
        "description": "requests",
        "detail": "requests",
        "documentation": {}
    },
    {
        "label": "amp",
        "importPath": "torch.cuda",
        "description": "torch.cuda",
        "isExtraImport": true,
        "detail": "torch.cuda",
        "documentation": {}
    },
    {
        "label": "amp",
        "importPath": "torch.cuda",
        "description": "torch.cuda",
        "isExtraImport": true,
        "detail": "torch.cuda",
        "documentation": {}
    },
    {
        "label": "AutoBackend",
        "importPath": "nn.autobackend",
        "description": "nn.autobackend",
        "isExtraImport": true,
        "detail": "nn.autobackend",
        "documentation": {}
    },
    {
        "label": "AutoBackend",
        "importPath": "nn.autobackend",
        "description": "nn.autobackend",
        "isExtraImport": true,
        "detail": "nn.autobackend",
        "documentation": {}
    },
    {
        "label": "AutoBackend",
        "importPath": "nn.autobackend",
        "description": "nn.autobackend",
        "isExtraImport": true,
        "detail": "nn.autobackend",
        "documentation": {}
    },
    {
        "label": "LetterBox",
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "isExtraImport": true,
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "isExtraImport": true,
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "file_size",
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "isExtraImport": true,
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "isExtraImport": true,
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "get_latest_run",
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "isExtraImport": true,
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "isExtraImport": true,
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "isExtraImport": true,
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "yolo.utils.plotting",
        "description": "yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "yolo.utils.plotting",
        "description": "yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "save_one_box",
        "importPath": "yolo.utils.plotting",
        "description": "yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "dist2bbox",
        "importPath": "yolo.utils.tal",
        "description": "yolo.utils.tal",
        "isExtraImport": true,
        "detail": "yolo.utils.tal",
        "documentation": {}
    },
    {
        "label": "make_anchors",
        "importPath": "yolo.utils.tal",
        "description": "yolo.utils.tal",
        "isExtraImport": true,
        "detail": "yolo.utils.tal",
        "documentation": {}
    },
    {
        "label": "copy_attr",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "fuse_conv_and_bn",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "initialize_weights",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "intersect_dicts",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "scale_img",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "time_sync",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "guess_task_from_head",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "guess_task_from_head",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "ModelEMA",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "init_seeds",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "one_cycle",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "strip_optimizer",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_flops",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_num_params",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_flops",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_num_params",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "profile",
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "contextlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "contextlib",
        "description": "contextlib",
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "contextmanager",
        "importPath": "contextlib",
        "description": "contextlib",
        "isExtraImport": true,
        "detail": "contextlib",
        "documentation": {}
    },
    {
        "label": "thop",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "thop",
        "description": "thop",
        "detail": "thop",
        "documentation": {}
    },
    {
        "label": "C1",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C2",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C3",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C3TR",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "SPP",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "SPPF",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "BottleneckCSP",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C2f",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C3Ghost",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C3x",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Classify",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Concat",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Conv",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "ConvTranspose",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Detect",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "DWConv",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "DWConvTranspose2d",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Ensemble",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Focus",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "GhostBottleneck",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "GhostConv",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Segment",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Detect",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Segment",
        "importPath": "nn.modules",
        "description": "nn.modules",
        "isExtraImport": true,
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "get_close_matches",
        "importPath": "difflib",
        "description": "difflib",
        "isExtraImport": true,
        "detail": "difflib",
        "documentation": {}
    },
    {
        "label": "dedent",
        "importPath": "textwrap",
        "description": "textwrap",
        "isExtraImport": true,
        "detail": "textwrap",
        "documentation": {}
    },
    {
        "label": "hydra",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hydra",
        "description": "hydra",
        "detail": "hydra",
        "documentation": {}
    },
    {
        "label": "ConfigCompositionException",
        "importPath": "hydra.errors",
        "description": "hydra.errors",
        "isExtraImport": true,
        "detail": "hydra.errors",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "open_dict",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "open_dict",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "OmegaConf",
        "importPath": "omegaconf",
        "description": "omegaconf",
        "isExtraImport": true,
        "detail": "omegaconf",
        "documentation": {}
    },
    {
        "label": "ConfigAttributeError",
        "importPath": "omegaconf.errors",
        "description": "omegaconf.errors",
        "isExtraImport": true,
        "detail": "omegaconf.errors",
        "documentation": {}
    },
    {
        "label": "ConfigKeyError",
        "importPath": "omegaconf.errors",
        "description": "omegaconf.errors",
        "isExtraImport": true,
        "detail": "omegaconf.errors",
        "documentation": {}
    },
    {
        "label": "OmegaConfBaseException",
        "importPath": "omegaconf.errors",
        "description": "omegaconf.errors",
        "isExtraImport": true,
        "detail": "omegaconf.errors",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "time",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "Thread",
        "importPath": "threading",
        "description": "threading",
        "isExtraImport": true,
        "detail": "threading",
        "documentation": {}
    },
    {
        "label": "LetterBox",
        "importPath": "ultralytics.yolo.data.augment",
        "description": "ultralytics.yolo.data.augment",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "IMG_FORMATS",
        "importPath": "ultralytics.yolo.data.utils",
        "description": "ultralytics.yolo.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "VID_FORMATS",
        "importPath": "ultralytics.yolo.data.utils",
        "description": "ultralytics.yolo.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "importPath": "ultralytics.yolo.data.utils",
        "description": "ultralytics.yolo.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "unzip_file",
        "importPath": "ultralytics.yolo.data.utils",
        "description": "ultralytics.yolo.data.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "is_colab",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "is_kaggle",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "DATASETS_DIR",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "NUM_THREADS",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "TQDM_BAR_FORMAT",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "is_colab",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "is_kaggle",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "LOGGER",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "ROOT",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "DEFAULT_CONFIG",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "colorstr",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "ops",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "yaml_load",
        "importPath": "ultralytics.yolo.utils",
        "description": "ultralytics.yolo.utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.yolo.utils.checks",
        "description": "ultralytics.yolo.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_version",
        "importPath": "ultralytics.yolo.utils.checks",
        "description": "ultralytics.yolo.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.yolo.utils.checks",
        "description": "ultralytics.yolo.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "importPath": "ultralytics.yolo.utils.checks",
        "description": "ultralytics.yolo.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "ultralytics.yolo.utils.checks",
        "description": "ultralytics.yolo.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_font",
        "importPath": "ultralytics.yolo.utils.checks",
        "description": "ultralytics.yolo.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "is_ascii",
        "importPath": "ultralytics.yolo.utils.checks",
        "description": "ultralytics.yolo.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imgsz",
        "importPath": "ultralytics.yolo.utils.checks",
        "description": "ultralytics.yolo.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imgsz",
        "importPath": "ultralytics.yolo.utils.checks",
        "description": "ultralytics.yolo.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_file",
        "importPath": "ultralytics.yolo.utils.checks",
        "description": "ultralytics.yolo.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "importPath": "ultralytics.yolo.utils.checks",
        "description": "ultralytics.yolo.utils.checks",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "randint",
        "importPath": "random",
        "description": "random",
        "isExtraImport": true,
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "torchvision.transforms",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "torchvision.transforms.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.transforms.functional",
        "description": "torchvision.transforms.functional",
        "detail": "torchvision.transforms.functional",
        "documentation": {}
    },
    {
        "label": "bbox_ioa",
        "importPath": "ultralytics.yolo.utils.metrics",
        "description": "ultralytics.yolo.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrix",
        "importPath": "ultralytics.yolo.utils.metrics",
        "description": "ultralytics.yolo.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "DetMetrics",
        "importPath": "ultralytics.yolo.utils.metrics",
        "description": "ultralytics.yolo.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "importPath": "ultralytics.yolo.utils.metrics",
        "description": "ultralytics.yolo.utils.metrics",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "resample_segments",
        "importPath": "ultralytics.yolo.utils.ops",
        "description": "ultralytics.yolo.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "segment2box",
        "importPath": "ultralytics.yolo.utils.ops",
        "description": "ultralytics.yolo.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywhn2xyxy",
        "importPath": "ultralytics.yolo.utils.ops",
        "description": "ultralytics.yolo.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "clean_str",
        "importPath": "ultralytics.yolo.utils.ops",
        "description": "ultralytics.yolo.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "segments2boxes",
        "importPath": "ultralytics.yolo.utils.ops",
        "description": "ultralytics.yolo.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyn2xy",
        "importPath": "ultralytics.yolo.utils.ops",
        "description": "ultralytics.yolo.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "ultralytics.yolo.utils.ops",
        "description": "ultralytics.yolo.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywhn2xyxy",
        "importPath": "ultralytics.yolo.utils.ops",
        "description": "ultralytics.yolo.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyxy2xywhn",
        "importPath": "ultralytics.yolo.utils.ops",
        "description": "ultralytics.yolo.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "importPath": "ultralytics.yolo.utils.ops",
        "description": "ultralytics.yolo.utils.ops",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "repeat",
        "importPath": "itertools",
        "description": "itertools",
        "isExtraImport": true,
        "detail": "itertools",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "Pool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "ThreadPool",
        "importPath": "multiprocessing.pool",
        "description": "multiprocessing.pool",
        "isExtraImport": true,
        "detail": "multiprocessing.pool",
        "documentation": {}
    },
    {
        "label": "psutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psutil",
        "description": "psutil",
        "detail": "psutil",
        "documentation": {}
    },
    {
        "label": "torchvision",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision",
        "description": "torchvision",
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "dataloader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "distributed",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "dataloader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "distributed",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "importPath": "ultralytics.yolo.utils.torch_utils",
        "description": "ultralytics.yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "ultralytics.yolo.utils.torch_utils",
        "description": "ultralytics.yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "importPath": "ultralytics.yolo.utils.torch_utils",
        "description": "ultralytics.yolo.utils.torch_utils",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "check_output",
        "importPath": "subprocess",
        "description": "subprocess",
        "isExtraImport": true,
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "is_tarfile",
        "importPath": "tarfile",
        "description": "tarfile",
        "isExtraImport": true,
        "detail": "tarfile",
        "documentation": {}
    },
    {
        "label": "is_zipfile",
        "importPath": "zipfile",
        "description": "zipfile",
        "isExtraImport": true,
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "ZipFile",
        "importPath": "zipfile",
        "description": "zipfile",
        "isExtraImport": true,
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "ZipFile",
        "importPath": "zipfile",
        "description": "zipfile",
        "isExtraImport": true,
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "download",
        "importPath": "ultralytics.yolo.utils.downloads",
        "description": "ultralytics.yolo.utils.downloads",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.downloads",
        "documentation": {}
    },
    {
        "label": "unzip_file",
        "importPath": "ultralytics.yolo.utils.files",
        "description": "ultralytics.yolo.utils.files",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "ultralytics",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ultralytics",
        "description": "ultralytics",
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "yolo",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "__version__",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "ClassificationModel",
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "isExtraImport": true,
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "DetectionModel",
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "isExtraImport": true,
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "isExtraImport": true,
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "ClassificationModel",
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "isExtraImport": true,
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "DetectionModel",
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "isExtraImport": true,
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "isExtraImport": true,
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "attempt_load_one_weight",
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "isExtraImport": true,
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "attempt_load_one_weight",
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "isExtraImport": true,
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "get_config",
        "importPath": "yolo.configs",
        "description": "yolo.configs",
        "isExtraImport": true,
        "detail": "yolo.configs",
        "documentation": {}
    },
    {
        "label": "get_config",
        "importPath": "yolo.configs",
        "description": "yolo.configs",
        "isExtraImport": true,
        "detail": "yolo.configs",
        "documentation": {}
    },
    {
        "label": "get_config",
        "importPath": "yolo.configs",
        "description": "yolo.configs",
        "isExtraImport": true,
        "detail": "yolo.configs",
        "documentation": {}
    },
    {
        "label": "get_config",
        "importPath": "yolo.configs",
        "description": "yolo.configs",
        "isExtraImport": true,
        "detail": "yolo.configs",
        "documentation": {}
    },
    {
        "label": "LoadImages",
        "importPath": "yolo.data.dataloaders.stream_loaders",
        "description": "yolo.data.dataloaders.stream_loaders",
        "isExtraImport": true,
        "detail": "yolo.data.dataloaders.stream_loaders",
        "documentation": {}
    },
    {
        "label": "LoadImages",
        "importPath": "yolo.data.dataloaders.stream_loaders",
        "description": "yolo.data.dataloaders.stream_loaders",
        "isExtraImport": true,
        "detail": "yolo.data.dataloaders.stream_loaders",
        "documentation": {}
    },
    {
        "label": "LoadScreenshots",
        "importPath": "yolo.data.dataloaders.stream_loaders",
        "description": "yolo.data.dataloaders.stream_loaders",
        "isExtraImport": true,
        "detail": "yolo.data.dataloaders.stream_loaders",
        "documentation": {}
    },
    {
        "label": "LoadStreams",
        "importPath": "yolo.data.dataloaders.stream_loaders",
        "description": "yolo.data.dataloaders.stream_loaders",
        "isExtraImport": true,
        "detail": "yolo.data.dataloaders.stream_loaders",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "isExtraImport": true,
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "IMG_FORMATS",
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "isExtraImport": true,
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "VID_FORMATS",
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "isExtraImport": true,
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "isExtraImport": true,
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "check_dataset_yaml",
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "isExtraImport": true,
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "isExtraImport": true,
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "check_dataset_yaml",
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "isExtraImport": true,
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "Exporter",
        "importPath": "yolo.engine.exporter",
        "description": "yolo.engine.exporter",
        "isExtraImport": true,
        "detail": "yolo.engine.exporter",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "sort",
        "description": "sort",
        "isExtraImport": true,
        "detail": "sort",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "sort",
        "description": "sort",
        "isExtraImport": true,
        "detail": "sort",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "print_function",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "matplotlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib",
        "description": "matplotlib",
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "matplotlib.patches",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "io",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "io",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "KalmanFilter",
        "importPath": "filterpy.kalman",
        "description": "filterpy.kalman",
        "isExtraImport": true,
        "detail": "filterpy.kalman",
        "documentation": {}
    },
    {
        "label": "KalmanFilter",
        "importPath": "filterpy.kalman",
        "description": "filterpy.kalman",
        "isExtraImport": true,
        "detail": "filterpy.kalman",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "torch.distributed",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.distributed",
        "description": "torch.distributed",
        "detail": "torch.distributed",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "DistributedDataParallel",
        "importPath": "torch.nn.parallel",
        "description": "torch.nn.parallel",
        "isExtraImport": true,
        "detail": "torch.nn.parallel",
        "documentation": {}
    },
    {
        "label": "lr_scheduler",
        "importPath": "torch.optim",
        "description": "torch.optim",
        "isExtraImport": true,
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "check_train_batch_size",
        "importPath": "yolo.utils.autobatch",
        "description": "yolo.utils.autobatch",
        "isExtraImport": true,
        "detail": "yolo.utils.autobatch",
        "documentation": {}
    },
    {
        "label": "ddp_cleanup",
        "importPath": "yolo.utils.dist",
        "description": "yolo.utils.dist",
        "isExtraImport": true,
        "detail": "yolo.utils.dist",
        "documentation": {}
    },
    {
        "label": "generate_ddp_command",
        "importPath": "yolo.utils.dist",
        "description": "yolo.utils.dist",
        "isExtraImport": true,
        "detail": "yolo.utils.dist",
        "documentation": {}
    },
    {
        "label": "PREFIX",
        "importPath": "hub.utils",
        "description": "hub.utils",
        "isExtraImport": true,
        "detail": "hub.utils",
        "documentation": {}
    },
    {
        "label": "sync_analytics",
        "importPath": "hub.utils",
        "description": "hub.utils",
        "isExtraImport": true,
        "detail": "hub.utils",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "urllib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib",
        "description": "urllib",
        "detail": "urllib",
        "documentation": {}
    },
    {
        "label": "pkg_resources",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pkg_resources",
        "description": "pkg_resources",
        "detail": "pkg_resources",
        "documentation": {}
    },
    {
        "label": "socket",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "socket",
        "description": "socket",
        "detail": "socket",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "Number",
        "importPath": "numbers",
        "description": "numbers",
        "isExtraImport": true,
        "detail": "numbers",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "URLError",
        "importPath": "urllib.error",
        "description": "urllib.error",
        "isExtraImport": true,
        "detail": "urllib.error",
        "documentation": {}
    },
    {
        "label": "BasePredictor",
        "importPath": "ultralytics.yolo.engine.predictor",
        "description": "ultralytics.yolo.engine.predictor",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.engine.predictor",
        "documentation": {}
    },
    {
        "label": "BasePredictor",
        "importPath": "ultralytics.yolo.engine.predictor",
        "description": "ultralytics.yolo.engine.predictor",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.engine.predictor",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.yolo.utils.plotting",
        "description": "ultralytics.yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "ultralytics.yolo.utils.plotting",
        "description": "ultralytics.yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "save_one_box",
        "importPath": "ultralytics.yolo.utils.plotting",
        "description": "ultralytics.yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "importPath": "ultralytics.yolo.utils.plotting",
        "description": "ultralytics.yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "importPath": "ultralytics.yolo.utils.plotting",
        "description": "ultralytics.yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "save_one_box",
        "importPath": "ultralytics.yolo.utils.plotting",
        "description": "ultralytics.yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "ultralytics.yolo.utils.plotting",
        "description": "ultralytics.yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "importPath": "ultralytics.yolo.utils.plotting",
        "description": "ultralytics.yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "output_to_target",
        "importPath": "ultralytics.yolo.utils.plotting",
        "description": "ultralytics.yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "importPath": "ultralytics.yolo.utils.plotting",
        "description": "ultralytics.yolo.utils.plotting",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "DetectionModel",
        "importPath": "ultralytics.nn.tasks",
        "description": "ultralytics.nn.tasks",
        "isExtraImport": true,
        "detail": "ultralytics.nn.tasks",
        "documentation": {}
    },
    {
        "label": "v8",
        "importPath": "ultralytics.yolo",
        "description": "ultralytics.yolo",
        "isExtraImport": true,
        "detail": "ultralytics.yolo",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "importPath": "ultralytics.yolo.data",
        "description": "ultralytics.yolo.data",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.data",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "importPath": "ultralytics.yolo.data",
        "description": "ultralytics.yolo.data",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.data",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "ultralytics.yolo.data.dataloaders.v5loader",
        "description": "ultralytics.yolo.data.dataloaders.v5loader",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "importPath": "ultralytics.yolo.data.dataloaders.v5loader",
        "description": "ultralytics.yolo.data.dataloaders.v5loader",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "importPath": "ultralytics.yolo.engine.trainer",
        "description": "ultralytics.yolo.engine.trainer",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.engine.trainer",
        "documentation": {}
    },
    {
        "label": "BboxLoss",
        "importPath": "ultralytics.yolo.utils.loss",
        "description": "ultralytics.yolo.utils.loss",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.loss",
        "documentation": {}
    },
    {
        "label": "TaskAlignedAssigner",
        "importPath": "ultralytics.yolo.utils.tal",
        "description": "ultralytics.yolo.utils.tal",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.tal",
        "documentation": {}
    },
    {
        "label": "dist2bbox",
        "importPath": "ultralytics.yolo.utils.tal",
        "description": "ultralytics.yolo.utils.tal",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.tal",
        "documentation": {}
    },
    {
        "label": "make_anchors",
        "importPath": "ultralytics.yolo.utils.tal",
        "description": "ultralytics.yolo.utils.tal",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.utils.tal",
        "documentation": {}
    },
    {
        "label": "BaseValidator",
        "importPath": "ultralytics.yolo.engine.validator",
        "description": "ultralytics.yolo.engine.validator",
        "isExtraImport": true,
        "detail": "ultralytics.yolo.engine.validator",
        "documentation": {}
    },
    {
        "label": "hub,",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hub.",
        "description": "hub.",
        "detail": "hub.",
        "documentation": {}
    },
    {
        "label": "AutoBackend",
        "kind": 6,
        "importPath": "nn.autobackend",
        "description": "nn.autobackend",
        "peekOfCode": "class AutoBackend(nn.Module):\n    def __init__(self, weights='yolov8n.pt', device=torch.device('cpu'), dnn=False, data=None, fp16=False, fuse=True):\n        \"\"\"\n        Ultralytics YOLO MultiBackend class for python inference on various backends\n        Args:\n          weights: the path to the weights file. Defaults to yolov8n.pt\n          device: The device to run the model on.\n          dnn: If you want to use OpenCV's DNN module to run the inference, set this to True. Defaults to\n        False\n          data: a dictionary containing the following keys:",
        "detail": "nn.autobackend",
        "documentation": {}
    },
    {
        "label": "Conv",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class Conv(nn.Module):\n    # Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)\n    default_act = nn.SiLU()  # default activation\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):\n        super().__init__()\n        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)\n        self.bn = nn.BatchNorm2d(c2)\n        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n    def forward(self, x):\n        return self.act(self.bn(self.conv(x)))",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "DWConv",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class DWConv(Conv):\n    # Depth-wise convolution\n    def __init__(self, c1, c2, k=1, s=1, d=1, act=True):  # ch_in, ch_out, kernel, stride, dilation, activation\n        super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), d=d, act=act)\nclass DWConvTranspose2d(nn.ConvTranspose2d):\n    # Depth-wise transpose convolution\n    def __init__(self, c1, c2, k=1, s=1, p1=0, p2=0):  # ch_in, ch_out, kernel, stride, padding, padding_out\n        super().__init__(c1, c2, k, s, p1, p2, groups=math.gcd(c1, c2))\nclass ConvTranspose(nn.Module):\n    # Convolution transpose 2d layer",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "DWConvTranspose2d",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class DWConvTranspose2d(nn.ConvTranspose2d):\n    # Depth-wise transpose convolution\n    def __init__(self, c1, c2, k=1, s=1, p1=0, p2=0):  # ch_in, ch_out, kernel, stride, padding, padding_out\n        super().__init__(c1, c2, k, s, p1, p2, groups=math.gcd(c1, c2))\nclass ConvTranspose(nn.Module):\n    # Convolution transpose 2d layer\n    default_act = nn.SiLU()  # default activation\n    def __init__(self, c1, c2, k=2, s=2, p=0, bn=True, act=True):\n        super().__init__()\n        self.conv_transpose = nn.ConvTranspose2d(c1, c2, k, s, p, bias=not bn)",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "ConvTranspose",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class ConvTranspose(nn.Module):\n    # Convolution transpose 2d layer\n    default_act = nn.SiLU()  # default activation\n    def __init__(self, c1, c2, k=2, s=2, p=0, bn=True, act=True):\n        super().__init__()\n        self.conv_transpose = nn.ConvTranspose2d(c1, c2, k, s, p, bias=not bn)\n        self.bn = nn.BatchNorm2d(c2) if bn else nn.Identity()\n        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n    def forward(self, x):\n        return self.act(self.bn(self.conv_transpose(x)))",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "DFL",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class DFL(nn.Module):\n    # DFL module\n    def __init__(self, c1=16):\n        super().__init__()\n        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)\n        x = torch.arange(c1, dtype=torch.float)\n        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))\n        self.c1 = c1\n    def forward(self, x):\n        b, c, a = x.shape  # batch, channels, anchors",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "TransformerLayer",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class TransformerLayer(nn.Module):\n    # Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance)\n    def __init__(self, c, num_heads):\n        super().__init__()\n        self.q = nn.Linear(c, c, bias=False)\n        self.k = nn.Linear(c, c, bias=False)\n        self.v = nn.Linear(c, c, bias=False)\n        self.ma = nn.MultiheadAttention(embed_dim=c, num_heads=num_heads)\n        self.fc1 = nn.Linear(c, c, bias=False)\n        self.fc2 = nn.Linear(c, c, bias=False)",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "TransformerBlock",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class TransformerBlock(nn.Module):\n    # Vision Transformer https://arxiv.org/abs/2010.11929\n    def __init__(self, c1, c2, num_heads, num_layers):\n        super().__init__()\n        self.conv = None\n        if c1 != c2:\n            self.conv = Conv(c1, c2)\n        self.linear = nn.Linear(c2, c2)  # learnable position embedding\n        self.tr = nn.Sequential(*(TransformerLayer(c2, num_heads) for _ in range(num_layers)))\n        self.c2 = c2",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Bottleneck",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class Bottleneck(nn.Module):\n    # Standard bottleneck\n    def __init__(self, c1, c2, shortcut=True, g=1, k=(3, 3), e=0.5):  # ch_in, ch_out, shortcut, kernels, groups, expand\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, k[0], 1)\n        self.cv2 = Conv(c_, c2, k[1], 1, g=g)\n        self.add = shortcut and c1 == c2\n    def forward(self, x):\n        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "BottleneckCSP",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class BottleneckCSP(nn.Module):\n    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)\n        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)\n        self.cv4 = Conv(2 * c_, c2, 1, 1)\n        self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C3",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class C3(nn.Module):\n    # CSP Bottleneck with 3 convolutions\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c1, c_, 1, 1)\n        self.cv3 = Conv(2 * c_, c2, 1)  # optional act=FReLU(c2)\n        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))\n    def forward(self, x):",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C2",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class C2(nn.Module):\n    # CSP Bottleneck with 2 convolutions\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__()\n        self.c = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, 2 * self.c, 1, 1)\n        self.cv2 = Conv(2 * self.c, c2, 1)  # optional act=FReLU(c2)\n        # self.attention = ChannelAttention(2 * self.c)  # or SpatialAttention()\n        self.m = nn.Sequential(*(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n)))\n    def forward(self, x):",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C2f",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class C2f(nn.Module):\n    # CSP Bottleneck with 2 convolutions\n    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__()\n        self.c = int(c2 * e)  # hidden channels\n        self.cv1 = Conv(c1, 2 * self.c, 1, 1)\n        self.cv2 = Conv((2 + n) * self.c, c2, 1)  # optional act=FReLU(c2)\n        self.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n))\n    def forward(self, x):\n        y = list(self.cv1(x).split((self.c, self.c), 1))",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "ChannelAttention",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class ChannelAttention(nn.Module):\n    # Channel-attention module https://github.com/open-mmlab/mmdetection/tree/v3.0.0rc1/configs/rtmdet\n    def __init__(self, channels: int) -> None:\n        super().__init__()\n        self.pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Conv2d(channels, channels, 1, 1, 0, bias=True)\n        self.act = nn.Sigmoid()\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return x * self.act(self.fc(self.pool(x)))\nclass SpatialAttention(nn.Module):",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "SpatialAttention",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class SpatialAttention(nn.Module):\n    # Spatial-attention module\n    def __init__(self, kernel_size=7):\n        super().__init__()\n        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n        padding = 3 if kernel_size == 7 else 1\n        self.cv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n        self.act = nn.Sigmoid()\n    def forward(self, x):\n        return x * self.act(self.cv1(torch.cat([torch.mean(x, 1, keepdim=True), torch.max(x, 1, keepdim=True)[0]], 1)))",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "CBAM",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class CBAM(nn.Module):\n    # CSP Bottleneck with 3 convolutions\n    def __init__(self, c1, ratio=16, kernel_size=7):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__()\n        self.channel_attention = ChannelAttention(c1)\n        self.spatial_attention = SpatialAttention(kernel_size)\n    def forward(self, x):\n        return self.spatial_attention(self.channel_attention(x))\nclass C1(nn.Module):\n    # CSP Bottleneck with 3 convolutions",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C1",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class C1(nn.Module):\n    # CSP Bottleneck with 3 convolutions\n    def __init__(self, c1, c2, n=1):  # ch_in, ch_out, number, shortcut, groups, expansion\n        super().__init__()\n        self.cv1 = Conv(c1, c2, 1, 1)\n        self.m = nn.Sequential(*(Conv(c2, c2, 3) for _ in range(n)))\n    def forward(self, x):\n        y = self.cv1(x)\n        return self.m(y) + y\nclass C3x(C3):",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C3x",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class C3x(C3):\n    # C3 module with cross-convolutions\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        super().__init__(c1, c2, n, shortcut, g, e)\n        self.c_ = int(c2 * e)\n        self.m = nn.Sequential(*(Bottleneck(self.c_, self.c_, shortcut, g, k=((1, 3), (3, 1)), e=1) for _ in range(n)))\nclass C3TR(C3):\n    # C3 module with TransformerBlock()\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C3TR",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class C3TR(C3):\n    # C3 module with TransformerBlock()\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)\n        self.m = TransformerBlock(c_, c_, 4, n)\nclass C3Ghost(C3):\n    # C3 module with GhostBottleneck()\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        super().__init__(c1, c2, n, shortcut, g, e)",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "C3Ghost",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class C3Ghost(C3):\n    # C3 module with GhostBottleneck()\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*(GhostBottleneck(c_, c_) for _ in range(n)))\nclass SPP(nn.Module):\n    # Spatial Pyramid Pooling (SPP) layer https://arxiv.org/abs/1406.4729\n    def __init__(self, c1, c2, k=(5, 9, 13)):\n        super().__init__()",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "SPP",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class SPP(nn.Module):\n    # Spatial Pyramid Pooling (SPP) layer https://arxiv.org/abs/1406.4729\n    def __init__(self, c1, c2, k=(5, 9, 13)):\n        super().__init__()\n        c_ = c1 // 2  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)\n        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])\n    def forward(self, x):\n        x = self.cv1(x)",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "SPPF",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class SPPF(nn.Module):\n    # Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher\n    def __init__(self, c1, c2, k=5):  # equivalent to SPP(k=(5, 9, 13))\n        super().__init__()\n        c_ = c1 // 2  # hidden channels\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_ * 4, c2, 1, 1)\n        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)\n    def forward(self, x):\n        x = self.cv1(x)",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Focus",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class Focus(nn.Module):\n    # Focus wh information into c-space\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n        super().__init__()\n        self.conv = Conv(c1 * 4, c2, k, s, p, g, act=act)\n        # self.contract = Contract(gain=2)\n    def forward(self, x):  # x(b,c,w,h) -> y(b,4c,w/2,h/2)\n        return self.conv(torch.cat((x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]), 1))\n        # return self.conv(self.contract(x))\nclass GhostConv(nn.Module):",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "GhostConv",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class GhostConv(nn.Module):\n    # Ghost Convolution https://github.com/huawei-noah/ghostnet\n    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):  # ch_in, ch_out, kernel, stride, groups\n        super().__init__()\n        c_ = c2 // 2  # hidden channels\n        self.cv1 = Conv(c1, c_, k, s, None, g, act=act)\n        self.cv2 = Conv(c_, c_, 5, 1, None, c_, act=act)\n    def forward(self, x):\n        y = self.cv1(x)\n        return torch.cat((y, self.cv2(y)), 1)",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "GhostBottleneck",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class GhostBottleneck(nn.Module):\n    # Ghost Bottleneck https://github.com/huawei-noah/ghostnet\n    def __init__(self, c1, c2, k=3, s=1):  # ch_in, ch_out, kernel, stride\n        super().__init__()\n        c_ = c2 // 2\n        self.conv = nn.Sequential(\n            GhostConv(c1, c_, 1, 1),  # pw\n            DWConv(c_, c_, k, s, act=False) if s == 2 else nn.Identity(),  # dw\n            GhostConv(c_, c2, 1, 1, act=False))  # pw-linear\n        self.shortcut = nn.Sequential(DWConv(c1, c1, k, s, act=False), Conv(c1, c2, 1, 1,",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Concat",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class Concat(nn.Module):\n    # Concatenate a list of tensors along dimension\n    def __init__(self, dimension=1):\n        super().__init__()\n        self.d = dimension\n    def forward(self, x):\n        return torch.cat(x, self.d)\nclass AutoShape(nn.Module):\n    # YOLOv5 input-robust model wrapper for passing cv2/np/PIL/torch inputs. Includes preprocessing, inference and NMS\n    conf = 0.25  # NMS confidence threshold",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "AutoShape",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class AutoShape(nn.Module):\n    # YOLOv5 input-robust model wrapper for passing cv2/np/PIL/torch inputs. Includes preprocessing, inference and NMS\n    conf = 0.25  # NMS confidence threshold\n    iou = 0.45  # NMS IoU threshold\n    agnostic = False  # NMS class-agnostic\n    multi_label = False  # NMS multiple labels per box\n    classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs\n    max_det = 1000  # maximum number of detections per image\n    amp = False  # Automatic Mixed Precision (AMP) inference\n    def __init__(self, model, verbose=True):",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Detections",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class Detections:\n    # YOLOv5 detections class for inference results\n    def __init__(self, ims, pred, files, times=(0, 0, 0), names=None, shape=None):\n        super().__init__()\n        d = pred[0].device  # device\n        gn = [torch.tensor([*(im.shape[i] for i in [1, 0, 1, 0]), 1, 1], device=d) for im in ims]  # normalizations\n        self.ims = ims  # list of images as numpy arrays\n        self.pred = pred  # list of tensors pred[0] = (xyxy, conf, cls)\n        self.names = names  # class names\n        self.files = files  # image filenames",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Proto",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class Proto(nn.Module):\n    # YOLOv8 mask Proto module for segmentation models\n    def __init__(self, c1, c_=256, c2=32):  # ch_in, number of protos, number of masks\n        super().__init__()\n        self.cv1 = Conv(c1, c_, k=3)\n        self.upsample = nn.ConvTranspose2d(c_, c_, 2, 2, 0, bias=True)  # nn.Upsample(scale_factor=2, mode='nearest')\n        self.cv2 = Conv(c_, c_, k=3)\n        self.cv3 = Conv(c_, c2)\n    def forward(self, x):\n        return self.cv3(self.cv2(self.upsample(self.cv1(x))))",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Ensemble",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class Ensemble(nn.ModuleList):\n    # Ensemble of models\n    def __init__(self):\n        super().__init__()\n    def forward(self, x, augment=False, profile=False, visualize=False):\n        y = [module(x, augment, profile, visualize)[0] for module in self]\n        # y = torch.stack(y).max(0)[0]  # max ensemble\n        # y = torch.stack(y).mean(0)  # mean ensemble\n        y = torch.cat(y, 1)  # nms ensemble\n        return y, None  # inference, train output",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Detect",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class Detect(nn.Module):\n    # YOLOv5 Detect head for detection models\n    dynamic = False  # force grid reconstruction\n    export = False  # export mode\n    shape = None\n    anchors = torch.empty(0)  # init\n    strides = torch.empty(0)  # init\n    def __init__(self, nc=80, ch=()):  # detection layer\n        super().__init__()\n        self.nc = nc  # number of classes",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Segment",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class Segment(Detect):\n    # YOLOv5 Segment head for segmentation models\n    def __init__(self, nc=80, nm=32, npr=256, ch=()):\n        super().__init__(nc, ch)\n        self.nm = nm  # number of masks\n        self.npr = npr  # number of protos\n        self.proto = Proto(ch[0], self.npr, self.nm)  # protos\n        self.detect = Detect.forward\n        c4 = max(ch[0] // 4, self.nm)\n        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(c4, c4, 3), nn.Conv2d(c4, self.nm, 1)) for x in ch)",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "Classify",
        "kind": 6,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "class Classify(nn.Module):\n    # YOLOv5 classification head, i.e. x(b,c1,20,20) to x(b,c2)\n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1):  # ch_in, ch_out, kernel, stride, padding, groups\n        super().__init__()\n        c_ = 1280  # efficientnet_b0 size\n        self.conv = Conv(c1, c_, k, s, autopad(k, p), g)\n        self.pool = nn.AdaptiveAvgPool2d(1)  # to x(b,c_,1,1)\n        self.drop = nn.Dropout(p=0.0, inplace=True)\n        self.linear = nn.Linear(c_, c2)  # to x(b,c2)\n    def forward(self, x):",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "autopad",
        "kind": 2,
        "importPath": "nn.modules",
        "description": "nn.modules",
        "peekOfCode": "def autopad(k, p=None, d=1):  # kernel, padding, dilation\n    # Pad to 'same' shape outputs\n    if d > 1:\n        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # actual kernel-size\n    if p is None:\n        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n    return p\nclass Conv(nn.Module):\n    # Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)\n    default_act = nn.SiLU()  # default activation",
        "detail": "nn.modules",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "kind": 6,
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "peekOfCode": "class BaseModel(nn.Module):\n    '''\n     The BaseModel class is a base class for all the models in the Ultralytics YOLO family.\n    '''\n    def forward(self, x, profile=False, visualize=False):\n        \"\"\"\n        > `forward` is a wrapper for `_forward_once` that runs the model on a single scale\n        Args:\n          x: the input image\n          profile: whether to profile the model. Defaults to False",
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "DetectionModel",
        "kind": 6,
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "peekOfCode": "class DetectionModel(BaseModel):\n    # YOLOv5 detection model\n    def __init__(self, cfg='yolov8n.yaml', ch=3, nc=None, verbose=True):  # model, input channels, number of classes\n        super().__init__()\n        self.yaml = cfg if isinstance(cfg, dict) else yaml_load(check_yaml(cfg), append_filename=True)  # cfg dict\n        # Define model\n        ch = self.yaml['ch'] = self.yaml.get('ch', ch)  # input channels\n        if nc and nc != self.yaml['nc']:\n            LOGGER.info(f\"Overriding model.yaml nc={self.yaml['nc']} with nc={nc}\")\n            self.yaml['nc'] = nc  # override yaml value",
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "SegmentationModel",
        "kind": 6,
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "peekOfCode": "class SegmentationModel(DetectionModel):\n    # YOLOv5 segmentation model\n    def __init__(self, cfg='yolov8n-seg.yaml', ch=3, nc=None, verbose=True):\n        super().__init__(cfg, ch, nc, verbose)\nclass ClassificationModel(BaseModel):\n    # YOLOv5 classification model\n    def __init__(self,\n                 cfg=None,\n                 model=None,\n                 ch=3,",
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "ClassificationModel",
        "kind": 6,
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "peekOfCode": "class ClassificationModel(BaseModel):\n    # YOLOv5 classification model\n    def __init__(self,\n                 cfg=None,\n                 model=None,\n                 ch=3,\n                 nc=1000,\n                 cutoff=10,\n                 verbose=True):  # yaml, model, number of classes, cutoff index\n        super().__init__()",
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "attempt_load_weights",
        "kind": 2,
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "peekOfCode": "def attempt_load_weights(weights, device=None, inplace=True, fuse=False):\n    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a\n    from yolo.utils.downloads import attempt_download\n    model = Ensemble()\n    for w in weights if isinstance(weights, list) else [weights]:\n        ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n        args = {**DEFAULT_CONFIG_DICT, **ckpt['train_args']}  # combine model and default args, preferring model args\n        ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model\n        # Model compatibility updates\n        ckpt.args = {k: v for k, v in args.items() if k in DEFAULT_CONFIG_KEYS}  # attach args to model",
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "attempt_load_one_weight",
        "kind": 2,
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "peekOfCode": "def attempt_load_one_weight(weight, device=None, inplace=True, fuse=False):\n    # Loads a single model weights\n    from yolo.utils.downloads import attempt_download\n    ckpt = torch.load(attempt_download(weight), map_location='cpu')  # load\n    args = {**DEFAULT_CONFIG_DICT, **ckpt['train_args']}  # combine model and default args, preferring model args\n    model = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model\n    # Model compatibility updates\n    model.args = {k: v for k, v in args.items() if k in DEFAULT_CONFIG_KEYS}  # attach args to model\n    model.pt_path = weight  # attach *.pt file path to model\n    if not hasattr(model, 'stride'):",
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "parse_model",
        "kind": 2,
        "importPath": "nn.tasks",
        "description": "nn.tasks",
        "peekOfCode": "def parse_model(d, ch, verbose=True):  # model_dict, input_channels(3)\n    # Parse a YOLO model.yaml dictionary\n    if verbose:\n        LOGGER.info(f\"\\n{'':>3}{'from':>20}{'n':>3}{'params':>10}  {'module':<45}{'arguments':<30}\")\n    nc, gd, gw, act = d['nc'], d['depth_multiple'], d['width_multiple'], d.get('activation')\n    if act:\n        Conv.default_act = eval(act)  # redefine default activation, i.e. Conv.default_act = nn.SiLU()\n        if verbose:\n            LOGGER.info(f\"{colorstr('activation:')} {act}\")  # print\n    layers, save, c2 = [], [], ch[-1]  # layers, savelist, ch out",
        "detail": "nn.tasks",
        "documentation": {}
    },
    {
        "label": "override_config",
        "kind": 2,
        "importPath": "yolo.configs.hydra_patch",
        "description": "yolo.configs.hydra_patch",
        "peekOfCode": "def override_config(overrides, cfg):\n    override_keys = [override.key_or_group for override in overrides]\n    check_config_mismatch(override_keys, cfg.keys())\n    for override in overrides:\n        if override.package is not None:\n            raise ConfigCompositionException(f\"Override {override.input_line} looks like a config group\"\n                                             f\" override, but config group '{override.key_or_group}' does not exist.\")\n        key = override.key_or_group\n        value = override.value()\n        try:",
        "detail": "yolo.configs.hydra_patch",
        "documentation": {}
    },
    {
        "label": "check_config_mismatch",
        "kind": 2,
        "importPath": "yolo.configs.hydra_patch",
        "description": "yolo.configs.hydra_patch",
        "peekOfCode": "def check_config_mismatch(overrides, cfg):\n    mismatched = [option for option in overrides if option not in cfg and 'hydra.' not in option]\n    for option in mismatched:\n        LOGGER.info(f\"{colorstr(option)} is not a valid key. Similar keys: {get_close_matches(option, cfg, 3, 0.6)}\")\n    if mismatched:\n        exit()\nhydra._internal.config_loader_impl.ConfigLoaderImpl._apply_overrides_to_config = override_config",
        "detail": "yolo.configs.hydra_patch",
        "documentation": {}
    },
    {
        "label": "hydra._internal.config_loader_impl.ConfigLoaderImpl._apply_overrides_to_config",
        "kind": 5,
        "importPath": "yolo.configs.hydra_patch",
        "description": "yolo.configs.hydra_patch",
        "peekOfCode": "hydra._internal.config_loader_impl.ConfigLoaderImpl._apply_overrides_to_config = override_config",
        "detail": "yolo.configs.hydra_patch",
        "documentation": {}
    },
    {
        "label": "LoadStreams",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.stream_loaders",
        "description": "yolo.data.dataloaders.stream_loaders",
        "peekOfCode": "class LoadStreams:\n    # YOLOv5 streamloader, i.e. `python detect.py --source 'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP streams`\n    def __init__(self, sources='file.streams', imgsz=640, stride=32, auto=True, transforms=None, vid_stride=1):\n        torch.backends.cudnn.benchmark = True  # faster for fixed-size inference\n        self.mode = 'stream'\n        self.imgsz = imgsz\n        self.stride = stride\n        self.vid_stride = vid_stride  # video frame-rate stride\n        sources = Path(sources).read_text().rsplit() if os.path.isfile(sources) else [sources]\n        n = len(sources)",
        "detail": "yolo.data.dataloaders.stream_loaders",
        "documentation": {}
    },
    {
        "label": "LoadScreenshots",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.stream_loaders",
        "description": "yolo.data.dataloaders.stream_loaders",
        "peekOfCode": "class LoadScreenshots:\n    # YOLOv5 screenshot dataloader, i.e. `python detect.py --source \"screen 0 100 100 512 256\"`\n    def __init__(self, source, imgsz=640, stride=32, auto=True, transforms=None):\n        # source = [screen_number left top width height] (pixels)\n        check_requirements('mss')\n        import mss\n        source, *params = source.split()\n        self.screen, left, top, width, height = 0, None, None, None, None  # default to full screen 0\n        if len(params) == 1:\n            self.screen = int(params[0])",
        "detail": "yolo.data.dataloaders.stream_loaders",
        "documentation": {}
    },
    {
        "label": "LoadImages",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.stream_loaders",
        "description": "yolo.data.dataloaders.stream_loaders",
        "peekOfCode": "class LoadImages:\n    # YOLOv5 image/video dataloader, i.e. `python detect.py --source image.jpg/vid.mp4`\n    def __init__(self, path, imgsz=640, stride=32, auto=True, transforms=None, vid_stride=1):\n        if isinstance(path, str) and Path(path).suffix == \".txt\":  # *.txt file with img/vid/dir on each line\n            path = Path(path).read_text().rsplit()\n        files = []\n        for p in sorted(path) if isinstance(path, (list, tuple)) else [path]:\n            p = str(Path(p).resolve())\n            if '*' in p:\n                files.extend(sorted(glob.glob(p, recursive=True)))  # glob",
        "detail": "yolo.data.dataloaders.stream_loaders",
        "documentation": {}
    },
    {
        "label": "Albumentations",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "class Albumentations:\n    # YOLOv5 Albumentations class (optional, only used if package is installed)\n    def __init__(self, size=640):\n        self.transform = None\n        prefix = colorstr('albumentations: ')\n        try:\n            import albumentations as A\n            check_version(A.__version__, '1.0.3', hard=True)  # version requirement\n            T = [\n                A.RandomResizedCrop(height=size, width=size, scale=(0.8, 1.0), ratio=(0.9, 1.11), p=0.0),",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "LetterBox",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "class LetterBox:\n    # YOLOv5 LetterBox class for image preprocessing, i.e. T.Compose([LetterBox(size), ToTensor()])\n    def __init__(self, size=(640, 640), auto=False, stride=32):\n        super().__init__()\n        self.h, self.w = (size, size) if isinstance(size, int) else size\n        self.auto = auto  # pass max size integer, automatically solve for short side using stride\n        self.stride = stride  # used with auto\n    def __call__(self, im):  # im = np.array HWC\n        imh, imw = im.shape[:2]\n        r = min(self.h / imh, self.w / imw)  # ratio of new/old",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "CenterCrop",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "class CenterCrop:\n    # YOLOv5 CenterCrop class for image preprocessing, i.e. T.Compose([CenterCrop(size), ToTensor()])\n    def __init__(self, size=640):\n        super().__init__()\n        self.h, self.w = (size, size) if isinstance(size, int) else size\n    def __call__(self, im):  # im = np.array HWC\n        imh, imw = im.shape[:2]\n        m = min(imh, imw)  # min dimension\n        top, left = (imh - m) // 2, (imw - m) // 2\n        return cv2.resize(im[top:top + m, left:left + m], (self.w, self.h), interpolation=cv2.INTER_LINEAR)",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "class ToTensor:\n    # YOLOv5 ToTensor class for image preprocessing, i.e. T.Compose([LetterBox(size), ToTensor()])\n    def __init__(self, half=False):\n        super().__init__()\n        self.half = half\n    def __call__(self, im):  # im = np.array HWC in BGR order\n        im = np.ascontiguousarray(im.transpose((2, 0, 1))[::-1])  # HWC to CHW -> BGR to RGB -> contiguous\n        im = torch.from_numpy(im)  # to torch\n        im = im.half() if self.half else im.float()  # uint8 to fp16/32\n        im /= 255.0  # 0-255 to 0.0-1.0",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "normalize",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def normalize(x, mean=IMAGENET_MEAN, std=IMAGENET_STD, inplace=False):\n    # Denormalize RGB images x per ImageNet stats in BCHW format, i.e. = (x - mean) / std\n    return TF.normalize(x, mean, std, inplace=inplace)\ndef denormalize(x, mean=IMAGENET_MEAN, std=IMAGENET_STD):\n    # Denormalize RGB images x per ImageNet stats in BCHW format, i.e. = x * std + mean\n    for i in range(3):\n        x[:, i] = x[:, i] * std[i] + mean[i]\n    return x\ndef augment_hsv(im, hgain=0.5, sgain=0.5, vgain=0.5):\n    # HSV color-space augmentation",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "denormalize",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def denormalize(x, mean=IMAGENET_MEAN, std=IMAGENET_STD):\n    # Denormalize RGB images x per ImageNet stats in BCHW format, i.e. = x * std + mean\n    for i in range(3):\n        x[:, i] = x[:, i] * std[i] + mean[i]\n    return x\ndef augment_hsv(im, hgain=0.5, sgain=0.5, vgain=0.5):\n    # HSV color-space augmentation\n    if hgain or sgain or vgain:\n        r = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # random gains\n        hue, sat, val = cv2.split(cv2.cvtColor(im, cv2.COLOR_BGR2HSV))",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "augment_hsv",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def augment_hsv(im, hgain=0.5, sgain=0.5, vgain=0.5):\n    # HSV color-space augmentation\n    if hgain or sgain or vgain:\n        r = np.random.uniform(-1, 1, 3) * [hgain, sgain, vgain] + 1  # random gains\n        hue, sat, val = cv2.split(cv2.cvtColor(im, cv2.COLOR_BGR2HSV))\n        dtype = im.dtype  # uint8\n        x = np.arange(0, 256, dtype=r.dtype)\n        lut_hue = ((x * r[0]) % 180).astype(dtype)\n        lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)\n        lut_val = np.clip(x * r[2], 0, 255).astype(dtype)",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "hist_equalize",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def hist_equalize(im, clahe=True, bgr=False):\n    # Equalize histogram on BGR image 'im' with im.shape(n,m,3) and range 0-255\n    yuv = cv2.cvtColor(im, cv2.COLOR_BGR2YUV if bgr else cv2.COLOR_RGB2YUV)\n    if clahe:\n        c = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n        yuv[:, :, 0] = c.apply(yuv[:, :, 0])\n    else:\n        yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])  # equalize Y channel histogram\n    return cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR if bgr else cv2.COLOR_YUV2RGB)  # convert YUV image to RGB\ndef replicate(im, labels):",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "replicate",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def replicate(im, labels):\n    # Replicate labels\n    h, w = im.shape[:2]\n    boxes = labels[:, 1:].astype(int)\n    x1, y1, x2, y2 = boxes.T\n    s = ((x2 - x1) + (y2 - y1)) / 2  # side length (pixels)\n    for i in s.argsort()[:round(s.size * 0.5)]:  # smallest indices\n        x1b, y1b, x2b, y2b = boxes[i]\n        bh, bw = y2b - y1b, x2b - x1b\n        yc, xc = int(random.uniform(0, h - bh)), int(random.uniform(0, w - bw))  # offset x, y",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "letterbox",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n    # Resize and pad image while meeting stride-multiple constraints\n    shape = im.shape[:2]  # current shape [height, width]\n    if isinstance(new_shape, int):\n        new_shape = (new_shape, new_shape)\n    # Scale ratio (new / old)\n    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n        r = min(r, 1.0)\n    # Compute padding",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "random_perspective",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def random_perspective(im,\n                       targets=(),\n                       segments=(),\n                       degrees=10,\n                       translate=.1,\n                       scale=.1,\n                       shear=10,\n                       perspective=0.0,\n                       border=(0, 0)):\n    # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(0.1, 0.1), scale=(0.9, 1.1), shear=(-10, 10))",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "copy_paste",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def copy_paste(im, labels, segments, p=0.5):\n    # Implement Copy-Paste augmentation https://arxiv.org/abs/2012.07177, labels as nx5 np.array(cls, xyxy)\n    n = len(segments)\n    if p and n:\n        h, w, c = im.shape  # height, width, channels\n        im_new = np.zeros(im.shape, np.uint8)\n        # calculate ioa first then select indexes randomly\n        boxes = np.stack([w - labels[:, 3], labels[:, 2], w - labels[:, 1], labels[:, 4]], axis=-1)  # (n, 4)\n        ioa = bbox_ioa(boxes, labels[:, 1:5])  # intersection over area\n        indexes = np.nonzero((ioa < 0.30).all(1))[0]  # (N, )",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "cutout",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def cutout(im, labels, p=0.5):\n    # Applies image cutout augmentation https://arxiv.org/abs/1708.04552\n    if random.random() < p:\n        h, w = im.shape[:2]\n        scales = [0.5] * 1 + [0.25] * 2 + [0.125] * 4 + [0.0625] * 8 + [0.03125] * 16  # image size fraction\n        for s in scales:\n            mask_h = random.randint(1, int(h * s))  # create random masks\n            mask_w = random.randint(1, int(w * s))\n            # box\n            xmin = max(0, random.randint(0, w) - mask_w // 2)",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "mixup",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def mixup(im, labels, im2, labels2):\n    # Applies MixUp augmentation https://arxiv.org/pdf/1710.09412.pdf\n    r = np.random.beta(32.0, 32.0)  # mixup ratio, alpha=beta=32.0\n    im = (im * r + im2 * (1 - r)).astype(np.uint8)\n    labels = np.concatenate((labels, labels2), 0)\n    return im, labels\ndef box_candidates(box1, box2, wh_thr=2, ar_thr=100, area_thr=0.1, eps=1e-16):  # box1(4,n), box2(4,n)\n    # Compute candidate boxes: box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio\n    w1, h1 = box1[2] - box1[0], box1[3] - box1[1]\n    w2, h2 = box2[2] - box2[0], box2[3] - box2[1]",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "box_candidates",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def box_candidates(box1, box2, wh_thr=2, ar_thr=100, area_thr=0.1, eps=1e-16):  # box1(4,n), box2(4,n)\n    # Compute candidate boxes: box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio\n    w1, h1 = box1[2] - box1[0], box1[3] - box1[1]\n    w2, h2 = box2[2] - box2[0], box2[3] - box2[1]\n    ar = np.maximum(w2 / (h2 + eps), h2 / (w2 + eps))  # aspect ratio\n    return (w2 > wh_thr) & (h2 > wh_thr) & (w2 * h2 / (w1 * h1 + eps) > area_thr) & (ar < ar_thr)  # candidates\ndef classify_albumentations(\n        augment=True,\n        size=224,\n        scale=(0.08, 1.0),",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "classify_albumentations",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def classify_albumentations(\n        augment=True,\n        size=224,\n        scale=(0.08, 1.0),\n        ratio=(0.75, 1.0 / 0.75),  # 0.75, 1.33\n        hflip=0.5,\n        vflip=0.0,\n        jitter=0.4,\n        mean=IMAGENET_MEAN,\n        std=IMAGENET_STD,",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "classify_transforms",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "def classify_transforms(size=224):\n    # Transforms to apply if albumentations not installed\n    assert isinstance(size, int), f'ERROR: classify_transforms size {size} must be integer, not (list, tuple)'\n    # T.Compose([T.ToTensor(), T.Resize(size), T.CenterCrop(size), T.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\n    return T.Compose([CenterCrop(size), ToTensor(), T.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\nclass LetterBox:\n    # YOLOv5 LetterBox class for image preprocessing, i.e. T.Compose([LetterBox(size), ToTensor()])\n    def __init__(self, size=(640, 640), auto=False, stride=32):\n        super().__init__()\n        self.h, self.w = (size, size) if isinstance(size, int) else size",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "IMAGENET_MEAN",
        "kind": 5,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "IMAGENET_MEAN = 0.485, 0.456, 0.406  # RGB mean\nIMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation\nclass Albumentations:\n    # YOLOv5 Albumentations class (optional, only used if package is installed)\n    def __init__(self, size=640):\n        self.transform = None\n        prefix = colorstr('albumentations: ')\n        try:\n            import albumentations as A\n            check_version(A.__version__, '1.0.3', hard=True)  # version requirement",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "IMAGENET_STD",
        "kind": 5,
        "importPath": "yolo.data.dataloaders.v5augmentations",
        "description": "yolo.data.dataloaders.v5augmentations",
        "peekOfCode": "IMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation\nclass Albumentations:\n    # YOLOv5 Albumentations class (optional, only used if package is installed)\n    def __init__(self, size=640):\n        self.transform = None\n        prefix = colorstr('albumentations: ')\n        try:\n            import albumentations as A\n            check_version(A.__version__, '1.0.3', hard=True)  # version requirement\n            T = [",
        "detail": "yolo.data.dataloaders.v5augmentations",
        "documentation": {}
    },
    {
        "label": "InfiniteDataLoader",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "class InfiniteDataLoader(dataloader.DataLoader):\n    \"\"\" Dataloader that reuses workers\n    Uses same syntax as vanilla DataLoader\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        object.__setattr__(self, 'batch_sampler', _RepeatSampler(self.batch_sampler))\n        self.iterator = super().__iter__()\n    def __len__(self):\n        return len(self.batch_sampler.sampler)",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "_RepeatSampler",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "class _RepeatSampler:\n    \"\"\" Sampler that repeats forever\n    Args:\n        sampler (Sampler)\n    \"\"\"\n    def __init__(self, sampler):\n        self.sampler = sampler\n    def __iter__(self):\n        while True:\n            yield from iter(self.sampler)",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "LoadScreenshots",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "class LoadScreenshots:\n    # YOLOv5 screenshot dataloader, i.e. `python detect.py --source \"screen 0 100 100 512 256\"`\n    def __init__(self, source, img_size=640, stride=32, auto=True, transforms=None):\n        # source = [screen_number left top width height] (pixels)\n        check_requirements('mss')\n        import mss\n        source, *params = source.split()\n        self.screen, left, top, width, height = 0, None, None, None, None  # default to full screen 0\n        if len(params) == 1:\n            self.screen = int(params[0])",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "LoadImages",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "class LoadImages:\n    # YOLOv5 image/video dataloader, i.e. `python detect.py --source image.jpg/vid.mp4`\n    def __init__(self, path, img_size=640, stride=32, auto=True, transforms=None, vid_stride=1):\n        if isinstance(path, str) and Path(path).suffix == \".txt\":  # *.txt file with img/vid/dir on each line\n            path = Path(path).read_text().rsplit()\n        files = []\n        for p in sorted(path) if isinstance(path, (list, tuple)) else [path]:\n            p = str(Path(p).resolve())\n            if '*' in p:\n                files.extend(sorted(glob.glob(p, recursive=True)))  # glob",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "LoadStreams",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "class LoadStreams:\n    # YOLOv5 streamloader, i.e. `python detect.py --source 'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP streams`\n    def __init__(self, sources='file.streams', img_size=640, stride=32, auto=True, transforms=None, vid_stride=1):\n        torch.backends.cudnn.benchmark = True  # faster for fixed-size inference\n        self.mode = 'stream'\n        self.img_size = img_size\n        self.stride = stride\n        self.vid_stride = vid_stride  # video frame-rate stride\n        sources = Path(sources).read_text().rsplit() if os.path.isfile(sources) else [sources]\n        n = len(sources)",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "LoadImagesAndLabels",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "class LoadImagesAndLabels(Dataset):\n    # YOLOv5 train_loader/val_loader, loads images and labels for training and validation\n    cache_version = 0.6  # dataset labels *.cache version\n    rand_interp_methods = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4]\n    def __init__(self,\n                 path,\n                 img_size=640,\n                 batch_size=16,\n                 augment=False,\n                 hyp=None,",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "HUBDatasetStats",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "class HUBDatasetStats():\n    \"\"\" Class for generating HUB dataset JSON and `-hub` dataset directory\n    Arguments\n        path:           Path to data.yaml or data.zip (with data.yaml inside data.zip)\n        autodownload:   Attempt to download dataset if not found locally\n    Usage\n        from utils.dataloaders import HUBDatasetStats\n        stats = HUBDatasetStats('coco128.yaml', autodownload=True)  # usage 1\n        stats = HUBDatasetStats('path/to/coco128.zip')  # usage 2\n        stats.get_json(save=False)",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "ClassificationDataset",
        "kind": 6,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "class ClassificationDataset(torchvision.datasets.ImageFolder):\n    \"\"\"\n    YOLOv5 Classification Dataset.\n    Arguments\n        root:  Dataset path\n        transform:  torchvision transforms, used by default\n        album_transform: Albumentations transforms, used if installed\n    \"\"\"\n    def __init__(self, root, augment, imgsz, cache=False):\n        super().__init__(root=root)",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "get_hash",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "def get_hash(paths):\n    # Returns a single hash value of a list of paths (files or dirs)\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes\n    h = hashlib.md5(str(size).encode())  # hash sizes\n    h.update(''.join(paths).encode())  # hash paths\n    return h.hexdigest()  # return hash\ndef exif_size(img):\n    # Returns exif-corrected PIL size\n    s = img.size  # (width, height)\n    with contextlib.suppress(Exception):",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "exif_size",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "def exif_size(img):\n    # Returns exif-corrected PIL size\n    s = img.size  # (width, height)\n    with contextlib.suppress(Exception):\n        rotation = dict(img._getexif().items())[orientation]\n        if rotation in [6, 8]:  # rotation 270 or 90\n            s = (s[1], s[0])\n    return s\ndef exif_transpose(image):\n    \"\"\"",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "exif_transpose",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "def exif_transpose(image):\n    \"\"\"\n    Transpose a PIL image accordingly if it has an EXIF Orientation tag.\n    Inplace version of https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py exif_transpose()\n    :param image: The image to transpose.\n    :return: An image.\n    \"\"\"\n    exif = image.getexif()\n    orientation = exif.get(0x0112, 1)  # default 1\n    if orientation > 1:",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "seed_worker",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "def seed_worker(worker_id):\n    # Set dataloader worker seed https://pytorch.org/docs/stable/notes/randomness.html#dataloader\n    worker_seed = torch.initial_seed() % 2 ** 32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\ndef create_dataloader(path,\n                      imgsz,\n                      batch_size,\n                      stride,\n                      single_cls=False,",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "create_dataloader",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "def create_dataloader(path,\n                      imgsz,\n                      batch_size,\n                      stride,\n                      single_cls=False,\n                      hyp=None,\n                      augment=False,\n                      cache=False,\n                      pad=0.0,\n                      rect=False,",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "img2label_paths",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "def img2label_paths(img_paths):\n    # Define label paths as a function of image paths\n    sa, sb = f'{os.sep}images{os.sep}', f'{os.sep}labels{os.sep}'  # /images/, /labels/ substrings\n    return [sb.join(x.rsplit(sa, 1)).rsplit('.', 1)[0] + '.txt' for x in img_paths]\nclass LoadImagesAndLabels(Dataset):\n    # YOLOv5 train_loader/val_loader, loads images and labels for training and validation\n    cache_version = 0.6  # dataset labels *.cache version\n    rand_interp_methods = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4]\n    def __init__(self,\n                 path,",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "flatten_recursive",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "def flatten_recursive(path=DATASETS_DIR / 'coco128'):\n    # Flatten a recursive directory by bringing all files to top level\n    new_path = Path(f'{str(path)}_flat')\n    if os.path.exists(new_path):\n        shutil.rmtree(new_path)  # delete output folder\n    os.makedirs(new_path)  # make new output folder\n    for file in tqdm(glob.glob(f'{str(Path(path))}/**/*.*', recursive=True)):\n        shutil.copyfile(file, new_path / Path(file).name)\ndef extract_boxes(path=DATASETS_DIR / 'coco128'):  # from utils.dataloaders import *; extract_boxes()\n    # Convert detection dataset into classification dataset, with one directory per class",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "extract_boxes",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "def extract_boxes(path=DATASETS_DIR / 'coco128'):  # from utils.dataloaders import *; extract_boxes()\n    # Convert detection dataset into classification dataset, with one directory per class\n    path = Path(path)  # images dir\n    shutil.rmtree(path / 'classification') if (path / 'classification').is_dir() else None  # remove existing\n    files = list(path.rglob('*.*'))\n    n = len(files)  # number of files\n    for im_file in tqdm(files, total=n):\n        if im_file.suffix[1:] in IMG_FORMATS:\n            # image\n            im = cv2.imread(str(im_file))[..., ::-1]  # BGR to RGB",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "autosplit",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "def autosplit(path=DATASETS_DIR / 'coco128/images', weights=(0.9, 0.1, 0.0), annotated_only=False):\n    \"\"\" Autosplit a dataset into train/val/test splits and save path/autosplit_*.txt files\n    Usage: from utils.dataloaders import *; autosplit()\n    Arguments\n        path:            Path to images directory\n        weights:         Train, val, test weights (list, tuple)\n        annotated_only:  Only use images with an annotated txt file\n    \"\"\"\n    path = Path(path)  # images dir\n    files = sorted(x for x in path.rglob('*.*') if x.suffix[1:].lower() in IMG_FORMATS)  # image files only",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "verify_image_label",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "def verify_image_label(args):\n    # Verify one image-label pair\n    im_file, lb_file, prefix = args\n    nm, nf, ne, nc, msg, segments = 0, 0, 0, 0, '', []  # number (missing, found, empty, corrupt), message, segments\n    try:\n        # verify images\n        im = Image.open(im_file)\n        im.verify()  # PIL verify\n        shape = exif_size(im)  # image size\n        assert (shape[0] > 9) & (shape[1] > 9), f'image size {shape} <10 pixels'",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "create_classification_dataloader",
        "kind": 2,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "def create_classification_dataloader(path,\n                                     imgsz=224,\n                                     batch_size=16,\n                                     augment=True,\n                                     cache=False,\n                                     rank=-1,\n                                     workers=8,\n                                     shuffle=True):\n    # Returns Dataloader object to be used with YOLOv5 Classifier\n    with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "HELP_URL",
        "kind": 5,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "HELP_URL = 'See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data'\nIMG_FORMATS = 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm'  # include image suffixes\nVID_FORMATS = 'asf', 'avi', 'gif', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'ts', 'wmv'  # include video suffixes\nLOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv('RANK', -1))\nPIN_MEMORY = str(os.getenv('PIN_MEMORY', True)).lower() == 'true'  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == 'Orientation':\n        break",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "IMG_FORMATS",
        "kind": 5,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "IMG_FORMATS = 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm'  # include image suffixes\nVID_FORMATS = 'asf', 'avi', 'gif', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'ts', 'wmv'  # include video suffixes\nLOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv('RANK', -1))\nPIN_MEMORY = str(os.getenv('PIN_MEMORY', True)).lower() == 'true'  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == 'Orientation':\n        break\ndef get_hash(paths):",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "VID_FORMATS",
        "kind": 5,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "VID_FORMATS = 'asf', 'avi', 'gif', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'ts', 'wmv'  # include video suffixes\nLOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv('RANK', -1))\nPIN_MEMORY = str(os.getenv('PIN_MEMORY', True)).lower() == 'true'  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == 'Orientation':\n        break\ndef get_hash(paths):\n    # Returns a single hash value of a list of paths (files or dirs)",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "LOCAL_RANK",
        "kind": 5,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv('RANK', -1))\nPIN_MEMORY = str(os.getenv('PIN_MEMORY', True)).lower() == 'true'  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == 'Orientation':\n        break\ndef get_hash(paths):\n    # Returns a single hash value of a list of paths (files or dirs)\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "RANK",
        "kind": 5,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "RANK = int(os.getenv('RANK', -1))\nPIN_MEMORY = str(os.getenv('PIN_MEMORY', True)).lower() == 'true'  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == 'Orientation':\n        break\ndef get_hash(paths):\n    # Returns a single hash value of a list of paths (files or dirs)\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes\n    h = hashlib.md5(str(size).encode())  # hash sizes",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "PIN_MEMORY",
        "kind": 5,
        "importPath": "yolo.data.dataloaders.v5loader",
        "description": "yolo.data.dataloaders.v5loader",
        "peekOfCode": "PIN_MEMORY = str(os.getenv('PIN_MEMORY', True)).lower() == 'true'  # global pin_memory for dataloaders\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == 'Orientation':\n        break\ndef get_hash(paths):\n    # Returns a single hash value of a list of paths (files or dirs)\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes\n    h = hashlib.md5(str(size).encode())  # hash sizes\n    h.update(''.join(paths).encode())  # hash paths",
        "detail": "yolo.data.dataloaders.v5loader",
        "documentation": {}
    },
    {
        "label": "BaseTransform",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class BaseTransform:\n    def __init__(self) -> None:\n        pass\n    def apply_image(self, labels):\n        pass\n    def apply_instances(self, labels):\n        pass\n    def apply_semantic(self, labels):\n        pass\n    def __call__(self, labels):",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "Compose",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class Compose:\n    def __init__(self, transforms):\n        self.transforms = transforms\n    def __call__(self, data):\n        for t in self.transforms:\n            data = t(data)\n        return data\n    def append(self, transform):\n        self.transforms.append(transform)\n    def tolist(self):",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "BaseMixTransform",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class BaseMixTransform:\n    \"\"\"This implementation is from mmyolo\"\"\"\n    def __init__(self, dataset, pre_transform=None, p=0.0) -> None:\n        self.dataset = dataset\n        self.pre_transform = pre_transform\n        self.p = p\n    def __call__(self, labels):\n        if random.uniform(0, 1) > self.p:\n            return labels\n        # get index of one or three other images",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "Mosaic",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class Mosaic(BaseMixTransform):\n    \"\"\"Mosaic augmentation.\n    Args:\n        imgsz (Sequence[int]): Image size after mosaic pipeline of single\n            image. The shape order should be (height, width).\n            Default to (640, 640).\n    \"\"\"\n    def __init__(self, dataset, imgsz=640, p=1.0, border=(0, 0)):\n        assert 0 <= p <= 1.0, \"The probability should be in range [0, 1]. \" f\"got {p}.\"\n        super().__init__(dataset=dataset, p=p)",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "MixUp",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class MixUp(BaseMixTransform):\n    def __init__(self, dataset, pre_transform=None, p=0.0) -> None:\n        super().__init__(dataset=dataset, pre_transform=pre_transform, p=p)\n    def get_indexes(self):\n        return random.randint(0, len(self.dataset) - 1)\n    def _mix_transform(self, labels):\n        # Applies MixUp augmentation https://arxiv.org/pdf/1710.09412.pdf\n        r = np.random.beta(32.0, 32.0)  # mixup ratio, alpha=beta=32.0\n        labels2 = labels[\"mix_labels\"][0]\n        labels[\"img\"] = (labels[\"img\"] * r + labels2[\"img\"] * (1 - r)).astype(np.uint8)",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "RandomPerspective",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class RandomPerspective:\n    def __init__(self, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, border=(0, 0)):\n        self.degrees = degrees\n        self.translate = translate\n        self.scale = scale\n        self.shear = shear\n        self.perspective = perspective\n        # mosaic border\n        self.border = border\n    def affine_transform(self, img):",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "RandomHSV",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class RandomHSV:\n    def __init__(self, hgain=0.5, sgain=0.5, vgain=0.5) -> None:\n        self.hgain = hgain\n        self.sgain = sgain\n        self.vgain = vgain\n    def __call__(self, labels):\n        img = labels[\"img\"]\n        if self.hgain or self.sgain or self.vgain:\n            r = np.random.uniform(-1, 1, 3) * [self.hgain, self.sgain, self.vgain] + 1  # random gains\n            hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "RandomFlip",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class RandomFlip:\n    def __init__(self, p=0.5, direction=\"horizontal\") -> None:\n        assert direction in [\"horizontal\", \"vertical\"], f\"Support direction `horizontal` or `vertical`, got {direction}\"\n        assert 0 <= p <= 1.0\n        self.p = p\n        self.direction = direction\n    def __call__(self, labels):\n        img = labels[\"img\"]\n        instances = labels.pop(\"instances\")\n        instances.convert_bbox(format=\"xywh\")",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "LetterBox",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class LetterBox:\n    \"\"\"Resize image and padding for detection, instance segmentation, pose\"\"\"\n    def __init__(self, new_shape=(640, 640), auto=False, scaleFill=False, scaleup=True, stride=32):\n        self.new_shape = new_shape\n        self.auto = auto\n        self.scaleFill = scaleFill\n        self.scaleup = scaleup\n        self.stride = stride\n    def __call__(self, labels=None, image=None):\n        if labels is None:",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "CopyPaste",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class CopyPaste:\n    def __init__(self, p=0.5) -> None:\n        self.p = p\n    def __call__(self, labels):\n        # Implement Copy-Paste augmentation https://arxiv.org/abs/2012.07177, labels as nx5 np.array(cls, xyxy)\n        im = labels[\"img\"]\n        cls = labels[\"cls\"]\n        instances = labels.pop(\"instances\")\n        instances.convert_bbox(format=\"xyxy\")\n        if self.p and len(instances.segments):",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "Albumentations",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class Albumentations:\n    # YOLOv5 Albumentations class (optional, only used if package is installed)\n    def __init__(self, p=1.0):\n        self.p = p\n        self.transform = None\n        prefix = colorstr(\"albumentations: \")\n        try:\n            import albumentations as A\n            check_version(A.__version__, \"1.0.3\", hard=True)  # version requirement\n            T = [",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "Format",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class Format:\n    def __init__(self,\n                 bbox_format=\"xywh\",\n                 normalize=True,\n                 return_mask=False,\n                 return_keypoint=False,\n                 mask_ratio=4,\n                 mask_overlap=True,\n                 batch_idx=True):\n        self.bbox_format = bbox_format",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "ClassifyLetterBox",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class ClassifyLetterBox:\n    # YOLOv5 LetterBox class for image preprocessing, i.e. T.Compose([LetterBox(size), ToTensor()])\n    def __init__(self, size=(640, 640), auto=False, stride=32):\n        super().__init__()\n        self.h, self.w = (size, size) if isinstance(size, int) else size\n        self.auto = auto  # pass max size integer, automatically solve for short side using stride\n        self.stride = stride  # used with auto\n    def __call__(self, im):  # im = np.array HWC\n        imh, imw = im.shape[:2]\n        r = min(self.h / imh, self.w / imw)  # ratio of new/old",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "CenterCrop",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class CenterCrop:\n    # YOLOv5 CenterCrop class for image preprocessing, i.e. T.Compose([CenterCrop(size), ToTensor()])\n    def __init__(self, size=640):\n        super().__init__()\n        self.h, self.w = (size, size) if isinstance(size, int) else size\n    def __call__(self, im):  # im = np.array HWC\n        imh, imw = im.shape[:2]\n        m = min(imh, imw)  # min dimension\n        top, left = (imh - m) // 2, (imw - m) // 2\n        return cv2.resize(im[top:top + m, left:left + m], (self.w, self.h), interpolation=cv2.INTER_LINEAR)",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "kind": 6,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "class ToTensor:\n    # YOLOv5 ToTensor class for image preprocessing, i.e. T.Compose([LetterBox(size), ToTensor()])\n    def __init__(self, half=False):\n        super().__init__()\n        self.half = half\n    def __call__(self, im):  # im = np.array HWC in BGR order\n        im = np.ascontiguousarray(im.transpose((2, 0, 1))[::-1])  # HWC to CHW -> BGR to RGB -> contiguous\n        im = torch.from_numpy(im)  # to torch\n        im = im.half() if self.half else im.float()  # uint8 to fp16/32\n        im /= 255.0  # 0-255 to 0.0-1.0",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "mosaic_transforms",
        "kind": 2,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "def mosaic_transforms(dataset, imgsz, hyp):\n    pre_transform = Compose([\n        Mosaic(dataset, imgsz=imgsz, p=hyp.mosaic, border=[-imgsz // 2, -imgsz // 2]),\n        CopyPaste(p=hyp.copy_paste),\n        RandomPerspective(\n            degrees=hyp.degrees,\n            translate=hyp.translate,\n            scale=hyp.scale,\n            shear=hyp.shear,\n            perspective=hyp.perspective,",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "affine_transforms",
        "kind": 2,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "def affine_transforms(imgsz, hyp):\n    return Compose([\n        LetterBox(new_shape=(imgsz, imgsz)),\n        RandomPerspective(\n            degrees=hyp.degrees,\n            translate=hyp.translate,\n            scale=hyp.scale,\n            shear=hyp.shear,\n            perspective=hyp.perspective,\n            border=[0, 0],",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "classify_transforms",
        "kind": 2,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "def classify_transforms(size=224):\n    # Transforms to apply if albumentations not installed\n    assert isinstance(size, int), f\"ERROR: classify_transforms size {size} must be integer, not (list, tuple)\"\n    # T.Compose([T.ToTensor(), T.Resize(size), T.CenterCrop(size), T.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\n    return T.Compose([CenterCrop(size), ToTensor(), T.Normalize(IMAGENET_MEAN, IMAGENET_STD)])\ndef classify_albumentations(\n        augment=True,\n        size=224,\n        scale=(0.08, 1.0),\n        hflip=0.5,",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "classify_albumentations",
        "kind": 2,
        "importPath": "yolo.data.augment",
        "description": "yolo.data.augment",
        "peekOfCode": "def classify_albumentations(\n        augment=True,\n        size=224,\n        scale=(0.08, 1.0),\n        hflip=0.5,\n        vflip=0.0,\n        jitter=0.4,\n        mean=IMAGENET_MEAN,\n        std=IMAGENET_STD,\n        auto_aug=False,",
        "detail": "yolo.data.augment",
        "documentation": {}
    },
    {
        "label": "BaseDataset",
        "kind": 6,
        "importPath": "yolo.data.base",
        "description": "yolo.data.base",
        "peekOfCode": "class BaseDataset(Dataset):\n    \"\"\"Base Dataset.\n    Args:\n        img_path (str): image path.\n        pipeline (dict): a dict of image transforms.\n        label_path (str): label path, this can also be an ann_file or other custom label path.\n    \"\"\"\n    def __init__(\n        self,\n        img_path,",
        "detail": "yolo.data.base",
        "documentation": {}
    },
    {
        "label": "InfiniteDataLoader",
        "kind": 6,
        "importPath": "yolo.data.build",
        "description": "yolo.data.build",
        "peekOfCode": "class InfiniteDataLoader(dataloader.DataLoader):\n    \"\"\"Dataloader that reuses workers\n    Uses same syntax as vanilla DataLoader\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        object.__setattr__(self, \"batch_sampler\", _RepeatSampler(self.batch_sampler))\n        self.iterator = super().__iter__()\n    def __len__(self):\n        return len(self.batch_sampler.sampler)",
        "detail": "yolo.data.build",
        "documentation": {}
    },
    {
        "label": "_RepeatSampler",
        "kind": 6,
        "importPath": "yolo.data.build",
        "description": "yolo.data.build",
        "peekOfCode": "class _RepeatSampler:\n    \"\"\"Sampler that repeats forever\n    Args:\n        sampler (Sampler)\n    \"\"\"\n    def __init__(self, sampler):\n        self.sampler = sampler\n    def __iter__(self):\n        while True:\n            yield from iter(self.sampler)",
        "detail": "yolo.data.build",
        "documentation": {}
    },
    {
        "label": "seed_worker",
        "kind": 2,
        "importPath": "yolo.data.build",
        "description": "yolo.data.build",
        "peekOfCode": "def seed_worker(worker_id):\n    # Set dataloader worker seed https://pytorch.org/docs/stable/notes/randomness.html#dataloader\n    worker_seed = torch.initial_seed() % 2 ** 32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\ndef build_dataloader(cfg, batch_size, img_path, stride=32, label_path=None, rank=-1, mode=\"train\"):\n    assert mode in [\"train\", \"val\"]\n    shuffle = mode == \"train\"\n    if cfg.rect and shuffle:\n        LOGGER.warning(\"WARNING ⚠️ --rect is incompatible with DataLoader shuffle, setting shuffle=False\")",
        "detail": "yolo.data.build",
        "documentation": {}
    },
    {
        "label": "build_dataloader",
        "kind": 2,
        "importPath": "yolo.data.build",
        "description": "yolo.data.build",
        "peekOfCode": "def build_dataloader(cfg, batch_size, img_path, stride=32, label_path=None, rank=-1, mode=\"train\"):\n    assert mode in [\"train\", \"val\"]\n    shuffle = mode == \"train\"\n    if cfg.rect and shuffle:\n        LOGGER.warning(\"WARNING ⚠️ --rect is incompatible with DataLoader shuffle, setting shuffle=False\")\n        shuffle = False\n    with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP\n        dataset = YOLODataset(\n            img_path=img_path,\n            label_path=label_path,",
        "detail": "yolo.data.build",
        "documentation": {}
    },
    {
        "label": "build_classification_dataloader",
        "kind": 2,
        "importPath": "yolo.data.build",
        "description": "yolo.data.build",
        "peekOfCode": "def build_classification_dataloader(path,\n                                    imgsz=224,\n                                    batch_size=16,\n                                    augment=True,\n                                    cache=False,\n                                    rank=-1,\n                                    workers=8,\n                                    shuffle=True):\n    # Returns Dataloader object to be used with YOLOv5 Classifier\n    with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP",
        "detail": "yolo.data.build",
        "documentation": {}
    },
    {
        "label": "YOLODataset",
        "kind": 6,
        "importPath": "yolo.data.dataset",
        "description": "yolo.data.dataset",
        "peekOfCode": "class YOLODataset(BaseDataset):\n    cache_version = 1.0  # dataset labels *.cache version, >= 1.0 for YOLOv8\n    rand_interp_methods = [cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4]\n    \"\"\"YOLO Dataset.\n    Args:\n        img_path (str): image path.\n        prefix (str): prefix.\n    \"\"\"\n    def __init__(\n        self,",
        "detail": "yolo.data.dataset",
        "documentation": {}
    },
    {
        "label": "ClassificationDataset",
        "kind": 6,
        "importPath": "yolo.data.dataset",
        "description": "yolo.data.dataset",
        "peekOfCode": "class ClassificationDataset(torchvision.datasets.ImageFolder):\n    \"\"\"\n    YOLOv5 Classification Dataset.\n    Arguments\n        root:  Dataset path\n        transform:  torchvision transforms, used by default\n        album_transform: Albumentations transforms, used if installed\n    \"\"\"\n    def __init__(self, root, augment, imgsz, cache=False):\n        super().__init__(root=root)",
        "detail": "yolo.data.dataset",
        "documentation": {}
    },
    {
        "label": "SemanticDataset",
        "kind": 6,
        "importPath": "yolo.data.dataset",
        "description": "yolo.data.dataset",
        "peekOfCode": "class SemanticDataset(BaseDataset):\n    def __init__(self):\n        pass",
        "detail": "yolo.data.dataset",
        "documentation": {}
    },
    {
        "label": "MixAndRectDataset",
        "kind": 6,
        "importPath": "yolo.data.dataset_wrappers",
        "description": "yolo.data.dataset_wrappers",
        "peekOfCode": "class MixAndRectDataset:\n    \"\"\"A wrapper of multiple images mixed dataset.\n    Args:\n        dataset (:obj:`BaseDataset`): The dataset to be mixed.\n        transforms (Sequence[dict]): config dict to be composed.\n    \"\"\"\n    def __init__(self, dataset):\n        self.dataset = dataset\n        self.imgsz = dataset.imgsz\n    def __len__(self):",
        "detail": "yolo.data.dataset_wrappers",
        "documentation": {}
    },
    {
        "label": "img2label_paths",
        "kind": 2,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "def img2label_paths(img_paths):\n    # Define label paths as a function of image paths\n    sa, sb = f\"{os.sep}images{os.sep}\", f\"{os.sep}labels{os.sep}\"  # /images/, /labels/ substrings\n    return [sb.join(x.rsplit(sa, 1)).rsplit(\".\", 1)[0] + \".txt\" for x in img_paths]\ndef get_hash(paths):\n    # Returns a single hash value of a list of paths (files or dirs)\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes\n    h = hashlib.md5(str(size).encode())  # hash sizes\n    h.update(\"\".join(paths).encode())  # hash paths\n    return h.hexdigest()  # return hash",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "get_hash",
        "kind": 2,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "def get_hash(paths):\n    # Returns a single hash value of a list of paths (files or dirs)\n    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes\n    h = hashlib.md5(str(size).encode())  # hash sizes\n    h.update(\"\".join(paths).encode())  # hash paths\n    return h.hexdigest()  # return hash\ndef exif_size(img):\n    # Returns exif-corrected PIL size\n    s = img.size  # (width, height)\n    with contextlib.suppress(Exception):",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "exif_size",
        "kind": 2,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "def exif_size(img):\n    # Returns exif-corrected PIL size\n    s = img.size  # (width, height)\n    with contextlib.suppress(Exception):\n        rotation = dict(img._getexif().items())[orientation]\n        if rotation in [6, 8]:  # rotation 270 or 90\n            s = (s[1], s[0])\n    return s\ndef verify_image_label(args):\n    # Verify one image-label pair",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "verify_image_label",
        "kind": 2,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "def verify_image_label(args):\n    # Verify one image-label pair\n    im_file, lb_file, prefix, keypoint = args\n    # number (missing, found, empty, corrupt), message, segments, keypoints\n    nm, nf, ne, nc, msg, segments, keypoints = 0, 0, 0, 0, \"\", [], None\n    try:\n        # verify images\n        im = Image.open(im_file)\n        im.verify()  # PIL verify\n        shape = exif_size(im)  # image size",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "polygon2mask",
        "kind": 2,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "def polygon2mask(imgsz, polygons, color=1, downsample_ratio=1):\n    \"\"\"\n    Args:\n        imgsz (tuple): The image size.\n        polygons (np.ndarray): [N, M], N is the number of polygons, M is the number of points(Be divided by 2).\n        color (int): color\n        downsample_ratio (int): downsample ratio\n    \"\"\"\n    mask = np.zeros(imgsz, dtype=np.uint8)\n    polygons = np.asarray(polygons)",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "polygons2masks",
        "kind": 2,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "def polygons2masks(imgsz, polygons, color, downsample_ratio=1):\n    \"\"\"\n    Args:\n        imgsz (tuple): The image size.\n        polygons (list[np.ndarray]): each polygon is [N, M], N is number of polygons, M is number of points (M % 2 = 0)\n        color (int): color\n        downsample_ratio (int): downsample ratio\n    \"\"\"\n    masks = []\n    for si in range(len(polygons)):",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "polygons2masks_overlap",
        "kind": 2,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "def polygons2masks_overlap(imgsz, segments, downsample_ratio=1):\n    \"\"\"Return a (640, 640) overlap mask.\"\"\"\n    masks = np.zeros((imgsz[0] // downsample_ratio, imgsz[1] // downsample_ratio),\n                     dtype=np.int32 if len(segments) > 255 else np.uint8)\n    areas = []\n    ms = []\n    for si in range(len(segments)):\n        mask = polygon2mask(\n            imgsz,\n            [segments[si].reshape(-1)],",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "check_dataset_yaml",
        "kind": 2,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "def check_dataset_yaml(data, autodownload=True):\n    # Download, check and/or unzip dataset if not found locally\n    data = check_file(data)\n    DATASETS_DIR = (Path.cwd() / \"../datasets\").resolve()  # TODO: handle global dataset dir\n    # Download (optional)\n    extract_dir = ''\n    if isinstance(data, (str, Path)) and (is_zipfile(data) or is_tarfile(data)):\n        download(data, dir=f'{DATASETS_DIR}/{Path(data).stem}', unzip=True, delete=False, curl=False, threads=1)\n        data = next((DATASETS_DIR / Path(data).stem).rglob('*.yaml'))\n        extract_dir, autodownload = data.parent, False",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "check_dataset",
        "kind": 2,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "def check_dataset(dataset: str):\n    \"\"\"\n    Check a classification dataset such as Imagenet.\n    Copy code\n    This function takes a `dataset` name as input and returns a dictionary containing information about the dataset.\n    If the dataset is not found, it attempts to download the dataset from the internet and save it to the local file system.\n    Args:\n        dataset (str): Name of the dataset.\n    Returns:\n        data (dict): A dictionary containing the following keys and values:",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "HELP_URL",
        "kind": 5,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "HELP_URL = \"See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\"\nIMG_FORMATS = \"bmp\", \"dng\", \"jpeg\", \"jpg\", \"mpo\", \"png\", \"tif\", \"tiff\", \"webp\", \"pfm\"  # include image suffixes\nVID_FORMATS = \"asf\", \"avi\", \"gif\", \"m4v\", \"mkv\", \"mov\", \"mp4\", \"mpeg\", \"mpg\", \"ts\", \"wmv\"  # include video suffixes\nLOCAL_RANK = int(os.getenv(\"LOCAL_RANK\", -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv('RANK', -1))\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\nIMAGENET_MEAN = 0.485, 0.456, 0.406  # RGB mean\nIMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "IMG_FORMATS",
        "kind": 5,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "IMG_FORMATS = \"bmp\", \"dng\", \"jpeg\", \"jpg\", \"mpo\", \"png\", \"tif\", \"tiff\", \"webp\", \"pfm\"  # include image suffixes\nVID_FORMATS = \"asf\", \"avi\", \"gif\", \"m4v\", \"mkv\", \"mov\", \"mp4\", \"mpeg\", \"mpg\", \"ts\", \"wmv\"  # include video suffixes\nLOCAL_RANK = int(os.getenv(\"LOCAL_RANK\", -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv('RANK', -1))\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\nIMAGENET_MEAN = 0.485, 0.456, 0.406  # RGB mean\nIMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "VID_FORMATS",
        "kind": 5,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "VID_FORMATS = \"asf\", \"avi\", \"gif\", \"m4v\", \"mkv\", \"mov\", \"mp4\", \"mpeg\", \"mpg\", \"ts\", \"wmv\"  # include video suffixes\nLOCAL_RANK = int(os.getenv(\"LOCAL_RANK\", -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv('RANK', -1))\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\nIMAGENET_MEAN = 0.485, 0.456, 0.406  # RGB mean\nIMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":\n        break",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "LOCAL_RANK",
        "kind": 5,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "LOCAL_RANK = int(os.getenv(\"LOCAL_RANK\", -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv('RANK', -1))\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\nIMAGENET_MEAN = 0.485, 0.456, 0.406  # RGB mean\nIMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":\n        break\ndef img2label_paths(img_paths):",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "kind": 5,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "RANK = int(os.getenv('RANK', -1))\nPIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\nIMAGENET_MEAN = 0.485, 0.456, 0.406  # RGB mean\nIMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":\n        break\ndef img2label_paths(img_paths):\n    # Define label paths as a function of image paths",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "PIN_MEMORY",
        "kind": 5,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "PIN_MEMORY = str(os.getenv(\"PIN_MEMORY\", True)).lower() == \"true\"  # global pin_memory for dataloaders\nIMAGENET_MEAN = 0.485, 0.456, 0.406  # RGB mean\nIMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":\n        break\ndef img2label_paths(img_paths):\n    # Define label paths as a function of image paths\n    sa, sb = f\"{os.sep}images{os.sep}\", f\"{os.sep}labels{os.sep}\"  # /images/, /labels/ substrings",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "IMAGENET_MEAN",
        "kind": 5,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "IMAGENET_MEAN = 0.485, 0.456, 0.406  # RGB mean\nIMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":\n        break\ndef img2label_paths(img_paths):\n    # Define label paths as a function of image paths\n    sa, sb = f\"{os.sep}images{os.sep}\", f\"{os.sep}labels{os.sep}\"  # /images/, /labels/ substrings\n    return [sb.join(x.rsplit(sa, 1)).rsplit(\".\", 1)[0] + \".txt\" for x in img_paths]",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "IMAGENET_STD",
        "kind": 5,
        "importPath": "yolo.data.utils",
        "description": "yolo.data.utils",
        "peekOfCode": "IMAGENET_STD = 0.229, 0.224, 0.225  # RGB standard deviation\n# Get orientation exif tag\nfor orientation in ExifTags.TAGS.keys():\n    if ExifTags.TAGS[orientation] == \"Orientation\":\n        break\ndef img2label_paths(img_paths):\n    # Define label paths as a function of image paths\n    sa, sb = f\"{os.sep}images{os.sep}\", f\"{os.sep}labels{os.sep}\"  # /images/, /labels/ substrings\n    return [sb.join(x.rsplit(sa, 1)).rsplit(\".\", 1)[0] + \".txt\" for x in img_paths]\ndef get_hash(paths):",
        "detail": "yolo.data.utils",
        "documentation": {}
    },
    {
        "label": "Exporter",
        "kind": 6,
        "importPath": "yolo.engine.exporter",
        "description": "yolo.engine.exporter",
        "peekOfCode": "class Exporter:\n    \"\"\"\n    Exporter\n    A class for exporting a model.\n    Attributes:\n        args (OmegaConf): Configuration for the exporter.\n        save_dir (Path): Directory to save results.\n    \"\"\"\n    def __init__(self, config=DEFAULT_CONFIG, overrides=None):\n        \"\"\"",
        "detail": "yolo.engine.exporter",
        "documentation": {}
    },
    {
        "label": "export_formats",
        "kind": 2,
        "importPath": "yolo.engine.exporter",
        "description": "yolo.engine.exporter",
        "peekOfCode": "def export_formats():\n    # YOLOv5 export formats\n    x = [\n        ['PyTorch', '-', '.pt', True, True],\n        ['TorchScript', 'torchscript', '.torchscript', True, True],\n        ['ONNX', 'onnx', '.onnx', True, True],\n        ['OpenVINO', 'openvino', '_openvino_model', True, False],\n        ['TensorRT', 'engine', '.engine', False, True],\n        ['CoreML', 'coreml', '.mlmodel', True, False],\n        ['TensorFlow SavedModel', 'saved_model', '_saved_model', True, True],",
        "detail": "yolo.engine.exporter",
        "documentation": {}
    },
    {
        "label": "try_export",
        "kind": 2,
        "importPath": "yolo.engine.exporter",
        "description": "yolo.engine.exporter",
        "peekOfCode": "def try_export(inner_func):\n    # YOLOv5 export decorator, i..e @try_export\n    inner_args = get_default_args(inner_func)\n    def outer_func(*args, **kwargs):\n        prefix = inner_args['prefix']\n        try:\n            with Profile() as dt:\n                f, model = inner_func(*args, **kwargs)\n            LOGGER.info(f'{prefix} export success ✅ {dt.t:.1f}s, saved as {f} ({file_size(f):.1f} MB)')\n            return f, model",
        "detail": "yolo.engine.exporter",
        "documentation": {}
    },
    {
        "label": "export",
        "kind": 2,
        "importPath": "yolo.engine.exporter",
        "description": "yolo.engine.exporter",
        "peekOfCode": "def export(cfg):\n    cfg.model = cfg.model or \"yolov8n.yaml\"\n    cfg.format = cfg.format or \"torchscript\"\n    # exporter = Exporter(cfg)\n    #\n    # model = None\n    # if isinstance(cfg.model, (str, Path)):\n    #     if Path(cfg.model).suffix == '.yaml':\n    #         model = DetectionModel(cfg.model)\n    #     elif Path(cfg.model).suffix == '.pt':",
        "detail": "yolo.engine.exporter",
        "documentation": {}
    },
    {
        "label": "MACOS",
        "kind": 5,
        "importPath": "yolo.engine.exporter",
        "description": "yolo.engine.exporter",
        "peekOfCode": "MACOS = platform.system() == 'Darwin'  # macOS environment\ndef export_formats():\n    # YOLOv5 export formats\n    x = [\n        ['PyTorch', '-', '.pt', True, True],\n        ['TorchScript', 'torchscript', '.torchscript', True, True],\n        ['ONNX', 'onnx', '.onnx', True, True],\n        ['OpenVINO', 'openvino', '_openvino_model', True, False],\n        ['TensorRT', 'engine', '.engine', False, True],\n        ['CoreML', 'coreml', '.mlmodel', True, False],",
        "detail": "yolo.engine.exporter",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "kind": 6,
        "importPath": "yolo.engine.model",
        "description": "yolo.engine.model",
        "peekOfCode": "class YOLO:\n    \"\"\"\n    YOLO\n    A python interface which emulates a model-like behaviour by wrapping trainers.\n    \"\"\"\n    def __init__(self, model='yolov8n.yaml', type=\"v8\") -> None:\n        \"\"\"\n        > Initializes the YOLO object.\n        Args:\n            model (str, Path): model to load or create",
        "detail": "yolo.engine.model",
        "documentation": {}
    },
    {
        "label": "MODEL_MAP",
        "kind": 5,
        "importPath": "yolo.engine.model",
        "description": "yolo.engine.model",
        "peekOfCode": "MODEL_MAP = {\n    \"classify\": [\n        ClassificationModel, 'yolo.TYPE.classify.ClassificationTrainer', 'yolo.TYPE.classify.ClassificationValidator',\n        'yolo.TYPE.classify.ClassificationPredictor'],\n    \"detect\": [\n        DetectionModel, 'yolo.TYPE.detect.DetectionTrainer', 'yolo.TYPE.detect.DetectionValidator',\n        'yolo.TYPE.detect.DetectionPredictor'],\n    \"segment\": [\n        SegmentationModel, 'yolo.TYPE.segment.SegmentationTrainer', 'yolo.TYPE.segment.SegmentationValidator',\n        'yolo.TYPE.segment.SegmentationPredictor']}",
        "detail": "yolo.engine.model",
        "documentation": {}
    },
    {
        "label": "BasePredictor",
        "kind": 6,
        "importPath": "yolo.engine.predictor",
        "description": "yolo.engine.predictor",
        "peekOfCode": "class BasePredictor:\n    \"\"\"\n    BasePredictor\n    A base class for cre    ating predictors.\n    Attributes:\n        args (OmegaConf): Configuration for the predictor.\n        save_dir (Path): Directory to save results.\n        done_setup (bool): Whether the predictor has finished setup.\n        model (nn.Module): Model used for prediction.\n        data (dict): Data configuration.",
        "detail": "yolo.engine.predictor",
        "documentation": {}
    },
    {
        "label": "KalmanBoxTracker",
        "kind": 6,
        "importPath": "yolo.engine.sort",
        "description": "yolo.engine.sort",
        "peekOfCode": "class KalmanBoxTracker(object):\n    count = 0\n    def __init__(self, bbox):\n        \"\"\"\n        Initialize a tracker using initial bounding box\n        Parameter 'bbox' must have 'detected class' int number at the -1 position.\n        \"\"\"\n        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n        self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],[0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n        self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])",
        "detail": "yolo.engine.sort",
        "documentation": {}
    },
    {
        "label": "Sort",
        "kind": 6,
        "importPath": "yolo.engine.sort",
        "description": "yolo.engine.sort",
        "peekOfCode": "class Sort(object):\n    def __init__(self, max_age=1, min_hits=3, iou_threshold=0.3):\n        \"\"\"\n        Parameters for SORT\n        \"\"\"\n        self.max_age = max_age\n        self.min_hits = min_hits\n        self.iou_threshold = iou_threshold\n        self.trackers = []\n        self.frame_count = 0",
        "detail": "yolo.engine.sort",
        "documentation": {}
    },
    {
        "label": "linear_assignment",
        "kind": 2,
        "importPath": "yolo.engine.sort",
        "description": "yolo.engine.sort",
        "peekOfCode": "def linear_assignment(cost_matrix):\n    try:\n        import lap #linear assignment problem solver\n        _, x, y = lap.lapjv(cost_matrix, extend_cost = True)\n        return np.array([[y[i],i] for i in x if i>=0])\n    except ImportError:\n        from scipy.optimize import linear_sum_assignment\n        x,y = linear_sum_assignment(cost_matrix)\n        return np.array(list(zip(x,y)))\n\"\"\"From SORT: Computes IOU between two boxes in the form [x1,y1,x2,y2]\"\"\"",
        "detail": "yolo.engine.sort",
        "documentation": {}
    },
    {
        "label": "iou_batch",
        "kind": 2,
        "importPath": "yolo.engine.sort",
        "description": "yolo.engine.sort",
        "peekOfCode": "def iou_batch(bb_test, bb_gt):\n    bb_gt = np.expand_dims(bb_gt, 0)\n    bb_test = np.expand_dims(bb_test, 1)\n    xx1 = np.maximum(bb_test[...,0], bb_gt[..., 0])\n    yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n    xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n    yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n    w = np.maximum(0., xx2 - xx1)\n    h = np.maximum(0., yy2 - yy1)\n    wh = w * h",
        "detail": "yolo.engine.sort",
        "documentation": {}
    },
    {
        "label": "convert_bbox_to_z",
        "kind": 2,
        "importPath": "yolo.engine.sort",
        "description": "yolo.engine.sort",
        "peekOfCode": "def convert_bbox_to_z(bbox):\n    w = bbox[2] - bbox[0]\n    h = bbox[3] - bbox[1]\n    x = bbox[0] + w/2.\n    y = bbox[1] + h/2.\n    s = w * h    \n    #scale is just area\n    r = w / float(h)\n    return np.array([x, y, s, r]).reshape((4, 1))\n\"\"\"Takes a bounding box in the centre form [x,y,s,r] and returns it in the form",
        "detail": "yolo.engine.sort",
        "documentation": {}
    },
    {
        "label": "convert_x_to_bbox",
        "kind": 2,
        "importPath": "yolo.engine.sort",
        "description": "yolo.engine.sort",
        "peekOfCode": "def convert_x_to_bbox(x, score=None):\n    w = np.sqrt(x[2] * x[3])\n    h = x[2] / w\n    if(score==None):\n        return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.]).reshape((1,4))\n    else:\n        return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.,score]).reshape((1,5))\n\"\"\"This class represents the internal state of individual tracked objects observed as bbox.\"\"\"\nclass KalmanBoxTracker(object):\n    count = 0",
        "detail": "yolo.engine.sort",
        "documentation": {}
    },
    {
        "label": "associate_detections_to_trackers",
        "kind": 2,
        "importPath": "yolo.engine.sort",
        "description": "yolo.engine.sort",
        "peekOfCode": "def associate_detections_to_trackers(detections, trackers, iou_threshold = 0.3):\n    \"\"\"\n    Assigns detections to tracked object (both represented as bounding boxes)\n    Returns 3 lists of \n    1. matches,\n    2. unmatched_detections\n    3. unmatched_trackers\n    \"\"\"\n    if(len(trackers)==0):\n        return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,5),dtype=int)",
        "detail": "yolo.engine.sort",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "yolo.engine.sort",
        "description": "yolo.engine.sort",
        "peekOfCode": "def parse_args():\n    \"\"\"Parse input arguments.\"\"\"\n    parser = argparse.ArgumentParser(description='SORT demo')\n    parser.add_argument('--display', dest='display', help='Display online tracker output (slow) [False]',action='store_true')\n    parser.add_argument(\"--seq_path\", help=\"Path to detections.\", type=str, default='data')\n    parser.add_argument(\"--phase\", help=\"Subdirectory in seq_path.\", type=str, default='train')\n    parser.add_argument(\"--max_age\", \n                        help=\"Maximum number of frames to keep alive a track without associated detections.\", \n                        type=int, default=1)\n    parser.add_argument(\"--min_hits\", ",
        "detail": "yolo.engine.sort",
        "documentation": {}
    },
    {
        "label": "BaseTrainer",
        "kind": 6,
        "importPath": "yolo.engine.trainer",
        "description": "yolo.engine.trainer",
        "peekOfCode": "class BaseTrainer:\n    \"\"\"\n    BaseTrainer\n    > A base class for creating trainers.\n    Attributes:\n        args (OmegaConf): Configuration for the trainer.\n        check_resume (method): Method to check if training should be resumed from a saved checkpoint.\n        console (logging.Logger): Logger instance.\n        validator (BaseValidator): Validator instance.\n        model (nn.Module): Model instance.",
        "detail": "yolo.engine.trainer",
        "documentation": {}
    },
    {
        "label": "BaseValidator",
        "kind": 6,
        "importPath": "yolo.engine.validator",
        "description": "yolo.engine.validator",
        "peekOfCode": "class BaseValidator:\n    \"\"\"\n    BaseValidator\n    A base class for creating validators.\n    Attributes:\n        dataloader (DataLoader): Dataloader to use for validation.\n        pbar (tqdm): Progress bar to update during validation.\n        logger (logging.Logger): Logger to use for validation.\n        args (OmegaConf): Configuration for the validator.\n        model (nn.Module): Model to validate.",
        "detail": "yolo.engine.validator",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_pretrain_routine_start(trainer):\n    pass\ndef on_pretrain_routine_end(trainer):\n    pass\ndef on_train_start(trainer):\n    pass\ndef on_train_epoch_start(trainer):\n    pass\ndef on_train_batch_start(trainer):\n    pass",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_pretrain_routine_end(trainer):\n    pass\ndef on_train_start(trainer):\n    pass\ndef on_train_epoch_start(trainer):\n    pass\ndef on_train_batch_start(trainer):\n    pass\ndef optimizer_step(trainer):\n    pass",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_train_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_train_start(trainer):\n    pass\ndef on_train_epoch_start(trainer):\n    pass\ndef on_train_batch_start(trainer):\n    pass\ndef optimizer_step(trainer):\n    pass\ndef on_before_zero_grad(trainer):\n    pass",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_train_epoch_start(trainer):\n    pass\ndef on_train_batch_start(trainer):\n    pass\ndef optimizer_step(trainer):\n    pass\ndef on_before_zero_grad(trainer):\n    pass\ndef on_train_batch_end(trainer):\n    pass",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_train_batch_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_train_batch_start(trainer):\n    pass\ndef optimizer_step(trainer):\n    pass\ndef on_before_zero_grad(trainer):\n    pass\ndef on_train_batch_end(trainer):\n    pass\ndef on_train_epoch_end(trainer):\n    pass",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "optimizer_step",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def optimizer_step(trainer):\n    pass\ndef on_before_zero_grad(trainer):\n    pass\ndef on_train_batch_end(trainer):\n    pass\ndef on_train_epoch_end(trainer):\n    pass\ndef on_fit_epoch_end(trainer):\n    pass",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_before_zero_grad",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_before_zero_grad(trainer):\n    pass\ndef on_train_batch_end(trainer):\n    pass\ndef on_train_epoch_end(trainer):\n    pass\ndef on_fit_epoch_end(trainer):\n    pass\ndef on_model_save(trainer):\n    pass",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_train_batch_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_train_batch_end(trainer):\n    pass\ndef on_train_epoch_end(trainer):\n    pass\ndef on_fit_epoch_end(trainer):\n    pass\ndef on_model_save(trainer):\n    pass\ndef on_train_end(trainer):\n    pass",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_train_epoch_end(trainer):\n    pass\ndef on_fit_epoch_end(trainer):\n    pass\ndef on_model_save(trainer):\n    pass\ndef on_train_end(trainer):\n    pass\ndef on_params_update(trainer):\n    pass",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    pass\ndef on_model_save(trainer):\n    pass\ndef on_train_end(trainer):\n    pass\ndef on_params_update(trainer):\n    pass\ndef teardown(trainer):\n    pass",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_model_save",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_model_save(trainer):\n    pass\ndef on_train_end(trainer):\n    pass\ndef on_params_update(trainer):\n    pass\ndef teardown(trainer):\n    pass\n# Validator callbacks --------------------------------------------------------------------------------------------------\ndef on_val_start(validator):",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_train_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_train_end(trainer):\n    pass\ndef on_params_update(trainer):\n    pass\ndef teardown(trainer):\n    pass\n# Validator callbacks --------------------------------------------------------------------------------------------------\ndef on_val_start(validator):\n    pass\ndef on_val_batch_start(validator):",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_params_update",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_params_update(trainer):\n    pass\ndef teardown(trainer):\n    pass\n# Validator callbacks --------------------------------------------------------------------------------------------------\ndef on_val_start(validator):\n    pass\ndef on_val_batch_start(validator):\n    pass\ndef on_val_batch_end(validator):",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "teardown",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def teardown(trainer):\n    pass\n# Validator callbacks --------------------------------------------------------------------------------------------------\ndef on_val_start(validator):\n    pass\ndef on_val_batch_start(validator):\n    pass\ndef on_val_batch_end(validator):\n    pass\ndef on_val_end(validator):",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_val_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_val_start(validator):\n    pass\ndef on_val_batch_start(validator):\n    pass\ndef on_val_batch_end(validator):\n    pass\ndef on_val_end(validator):\n    pass\n# Predictor callbacks --------------------------------------------------------------------------------------------------\ndef on_predict_start(predictor):",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_val_batch_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_val_batch_start(validator):\n    pass\ndef on_val_batch_end(validator):\n    pass\ndef on_val_end(validator):\n    pass\n# Predictor callbacks --------------------------------------------------------------------------------------------------\ndef on_predict_start(predictor):\n    pass\ndef on_predict_batch_start(predictor):",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_val_batch_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_val_batch_end(validator):\n    pass\ndef on_val_end(validator):\n    pass\n# Predictor callbacks --------------------------------------------------------------------------------------------------\ndef on_predict_start(predictor):\n    pass\ndef on_predict_batch_start(predictor):\n    pass\ndef on_predict_batch_end(predictor):",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_val_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_val_end(validator):\n    pass\n# Predictor callbacks --------------------------------------------------------------------------------------------------\ndef on_predict_start(predictor):\n    pass\ndef on_predict_batch_start(predictor):\n    pass\ndef on_predict_batch_end(predictor):\n    pass\ndef on_predict_end(predictor):",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_predict_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_predict_start(predictor):\n    pass\ndef on_predict_batch_start(predictor):\n    pass\ndef on_predict_batch_end(predictor):\n    pass\ndef on_predict_end(predictor):\n    pass\n# Exporter callbacks ---------------------------------------------------------------------------------------------------\ndef on_export_start(exporter):",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_predict_batch_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_predict_batch_start(predictor):\n    pass\ndef on_predict_batch_end(predictor):\n    pass\ndef on_predict_end(predictor):\n    pass\n# Exporter callbacks ---------------------------------------------------------------------------------------------------\ndef on_export_start(exporter):\n    pass\ndef on_export_end(exporter):",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_predict_batch_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_predict_batch_end(predictor):\n    pass\ndef on_predict_end(predictor):\n    pass\n# Exporter callbacks ---------------------------------------------------------------------------------------------------\ndef on_export_start(exporter):\n    pass\ndef on_export_end(exporter):\n    pass\ndefault_callbacks = {",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_predict_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_predict_end(predictor):\n    pass\n# Exporter callbacks ---------------------------------------------------------------------------------------------------\ndef on_export_start(exporter):\n    pass\ndef on_export_end(exporter):\n    pass\ndefault_callbacks = {\n    # Run in trainer\n    'on_pretrain_routine_start': on_pretrain_routine_start,",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_export_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_export_start(exporter):\n    pass\ndef on_export_end(exporter):\n    pass\ndefault_callbacks = {\n    # Run in trainer\n    'on_pretrain_routine_start': on_pretrain_routine_start,\n    'on_pretrain_routine_end': on_pretrain_routine_end,\n    'on_train_start': on_train_start,\n    'on_train_epoch_start': on_train_epoch_start,",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_export_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def on_export_end(exporter):\n    pass\ndefault_callbacks = {\n    # Run in trainer\n    'on_pretrain_routine_start': on_pretrain_routine_start,\n    'on_pretrain_routine_end': on_pretrain_routine_end,\n    'on_train_start': on_train_start,\n    'on_train_epoch_start': on_train_epoch_start,\n    'on_train_batch_start': on_train_batch_start,\n    'optimizer_step': optimizer_step,",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "add_integration_callbacks",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "def add_integration_callbacks(instance):\n    from .clearml import callbacks as clearml_callbacks\n    from .comet import callbacks as comet_callbacks\n    from .hub import callbacks as hub_callbacks\n    from .tensorboard import callbacks as tb_callbacks\n    for x in clearml_callbacks, comet_callbacks, hub_callbacks, tb_callbacks:\n        for k, v in x.items():\n            instance.callbacks[k].append(v)  # callback[name].append(func)",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "default_callbacks",
        "kind": 5,
        "importPath": "yolo.utils.callbacks.base",
        "description": "yolo.utils.callbacks.base",
        "peekOfCode": "default_callbacks = {\n    # Run in trainer\n    'on_pretrain_routine_start': on_pretrain_routine_start,\n    'on_pretrain_routine_end': on_pretrain_routine_end,\n    'on_train_start': on_train_start,\n    'on_train_epoch_start': on_train_epoch_start,\n    'on_train_batch_start': on_train_batch_start,\n    'optimizer_step': optimizer_step,\n    'on_before_zero_grad': on_before_zero_grad,\n    'on_train_batch_end': on_train_batch_end,",
        "detail": "yolo.utils.callbacks.base",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.clearml",
        "description": "yolo.utils.callbacks.clearml",
        "peekOfCode": "def on_pretrain_routine_start(trainer):\n    # TODO: reuse existing task\n    task = Task.init(project_name=trainer.args.project or \"YOLOv8\",\n                     task_name=trainer.args.name,\n                     tags=['YOLOv8'],\n                     output_uri=True,\n                     reuse_last_task_id=False,\n                     auto_connect_frameworks={'pytorch': False})\n    task.connect(dict(trainer.args), name='General')\ndef on_train_epoch_end(trainer):",
        "detail": "yolo.utils.callbacks.clearml",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.clearml",
        "description": "yolo.utils.callbacks.clearml",
        "peekOfCode": "def on_train_epoch_end(trainer):\n    if trainer.epoch == 1:\n        _log_images({f.stem: str(f) for f in trainer.save_dir.glob('train_batch*.jpg')}, \"Mosaic\", trainer.epoch)\ndef on_fit_epoch_end(trainer):\n    if trainer.epoch == 0:\n        model_info = {\n            \"Parameters\": get_num_params(trainer.model),\n            \"GFLOPs\": round(get_flops(trainer.model), 3),\n            \"Inference speed (ms/img)\": round(trainer.validator.speed[1], 3)}\n        Task.current_task().connect(model_info, name='Model')",
        "detail": "yolo.utils.callbacks.clearml",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.clearml",
        "description": "yolo.utils.callbacks.clearml",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    if trainer.epoch == 0:\n        model_info = {\n            \"Parameters\": get_num_params(trainer.model),\n            \"GFLOPs\": round(get_flops(trainer.model), 3),\n            \"Inference speed (ms/img)\": round(trainer.validator.speed[1], 3)}\n        Task.current_task().connect(model_info, name='Model')\ndef on_train_end(trainer):\n    Task.current_task().update_output_model(model_path=str(trainer.best),\n                                            model_name=trainer.args.name,",
        "detail": "yolo.utils.callbacks.clearml",
        "documentation": {}
    },
    {
        "label": "on_train_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.clearml",
        "description": "yolo.utils.callbacks.clearml",
        "peekOfCode": "def on_train_end(trainer):\n    Task.current_task().update_output_model(model_path=str(trainer.best),\n                                            model_name=trainer.args.name,\n                                            auto_delete_file=False)\ncallbacks = {\n    \"on_pretrain_routine_start\": on_pretrain_routine_start,\n    \"on_train_epoch_end\": on_train_epoch_end,\n    \"on_fit_epoch_end\": on_fit_epoch_end,\n    \"on_train_end\": on_train_end} if clearml else {}",
        "detail": "yolo.utils.callbacks.clearml",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "yolo.utils.callbacks.clearml",
        "description": "yolo.utils.callbacks.clearml",
        "peekOfCode": "callbacks = {\n    \"on_pretrain_routine_start\": on_pretrain_routine_start,\n    \"on_train_epoch_end\": on_train_epoch_end,\n    \"on_fit_epoch_end\": on_fit_epoch_end,\n    \"on_train_end\": on_train_end} if clearml else {}",
        "detail": "yolo.utils.callbacks.clearml",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.comet",
        "description": "yolo.utils.callbacks.comet",
        "peekOfCode": "def on_pretrain_routine_start(trainer):\n    experiment = comet_ml.Experiment(project_name=trainer.args.project or \"YOLOv8\",)\n    experiment.log_parameters(dict(trainer.args))\ndef on_train_epoch_end(trainer):\n    experiment = comet_ml.get_global_experiment()\n    experiment.log_metrics(trainer.label_loss_items(trainer.tloss, prefix=\"train\"), step=trainer.epoch + 1)\n    if trainer.epoch == 1:\n        for f in trainer.save_dir.glob('train_batch*.jpg'):\n            experiment.log_image(f, name=f.stem, step=trainer.epoch + 1)\ndef on_fit_epoch_end(trainer):",
        "detail": "yolo.utils.callbacks.comet",
        "documentation": {}
    },
    {
        "label": "on_train_epoch_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.comet",
        "description": "yolo.utils.callbacks.comet",
        "peekOfCode": "def on_train_epoch_end(trainer):\n    experiment = comet_ml.get_global_experiment()\n    experiment.log_metrics(trainer.label_loss_items(trainer.tloss, prefix=\"train\"), step=trainer.epoch + 1)\n    if trainer.epoch == 1:\n        for f in trainer.save_dir.glob('train_batch*.jpg'):\n            experiment.log_image(f, name=f.stem, step=trainer.epoch + 1)\ndef on_fit_epoch_end(trainer):\n    experiment = comet_ml.get_global_experiment()\n    experiment.log_metrics(trainer.metrics, step=trainer.epoch + 1)\n    if trainer.epoch == 0:",
        "detail": "yolo.utils.callbacks.comet",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.comet",
        "description": "yolo.utils.callbacks.comet",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    experiment = comet_ml.get_global_experiment()\n    experiment.log_metrics(trainer.metrics, step=trainer.epoch + 1)\n    if trainer.epoch == 0:\n        model_info = {\n            \"model/parameters\": get_num_params(trainer.model),\n            \"model/GFLOPs\": round(get_flops(trainer.model), 3),\n            \"model/speed(ms)\": round(trainer.validator.speed[1], 3)}\n        experiment.log_metrics(model_info, step=trainer.epoch + 1)\ndef on_train_end(trainer):",
        "detail": "yolo.utils.callbacks.comet",
        "documentation": {}
    },
    {
        "label": "on_train_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.comet",
        "description": "yolo.utils.callbacks.comet",
        "peekOfCode": "def on_train_end(trainer):\n    experiment = comet_ml.get_global_experiment()\n    experiment.log_model(\"YOLOv8\", file_or_folder=trainer.best, file_name=\"best.pt\", overwrite=True)\ncallbacks = {\n    \"on_pretrain_routine_start\": on_pretrain_routine_start,\n    \"on_train_epoch_end\": on_train_epoch_end,\n    \"on_fit_epoch_end\": on_fit_epoch_end,\n    \"on_train_end\": on_train_end} if comet_ml else {}",
        "detail": "yolo.utils.callbacks.comet",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "yolo.utils.callbacks.comet",
        "description": "yolo.utils.callbacks.comet",
        "peekOfCode": "callbacks = {\n    \"on_pretrain_routine_start\": on_pretrain_routine_start,\n    \"on_train_epoch_end\": on_train_epoch_end,\n    \"on_fit_epoch_end\": on_fit_epoch_end,\n    \"on_train_end\": on_train_end} if comet_ml else {}",
        "detail": "yolo.utils.callbacks.comet",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.hub",
        "description": "yolo.utils.callbacks.hub",
        "peekOfCode": "def on_pretrain_routine_end(trainer):\n    session = getattr(trainer, 'hub_session', None)\n    if session:\n        # Start timer for upload rate limit\n        LOGGER.info(f\"{PREFIX}View model at https://hub.com/models/{session.model_id} 🚀\")\n        session.t = {'metrics': time(), 'ckpt': time()}  # start timer on self.rate_limit\ndef on_fit_epoch_end(trainer):\n    session = getattr(trainer, 'hub_session', None)\n    if session:\n        session.metrics_queue[trainer.epoch] = json.dumps(trainer.metrics)  # json string",
        "detail": "yolo.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.hub",
        "description": "yolo.utils.callbacks.hub",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    session = getattr(trainer, 'hub_session', None)\n    if session:\n        session.metrics_queue[trainer.epoch] = json.dumps(trainer.metrics)  # json string\n        if time() - session.t['metrics'] > session.rate_limits['metrics']:\n            session.upload_metrics()\n            session.t['metrics'] = time()  # reset timer\n            session.metrics_queue = {}  # reset queue\ndef on_model_save(trainer):\n    session = getattr(trainer, 'hub_session', None)",
        "detail": "yolo.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_model_save",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.hub",
        "description": "yolo.utils.callbacks.hub",
        "peekOfCode": "def on_model_save(trainer):\n    session = getattr(trainer, 'hub_session', None)\n    if session:\n        # Upload checkpoints with rate limiting\n        is_best = trainer.best_fitness == trainer.fitness\n        if time() - session.t['ckpt'] > session.rate_limits['ckpt']:\n            LOGGER.info(f\"{PREFIX}Uploading checkpoint {session.model_id}\")\n            session.upload_model(trainer.epoch, trainer.last, is_best)\n            session.t['ckpt'] = time()  # reset timer\ndef on_train_end(trainer):",
        "detail": "yolo.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_train_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.hub",
        "description": "yolo.utils.callbacks.hub",
        "peekOfCode": "def on_train_end(trainer):\n    session = getattr(trainer, 'hub_session', None)\n    if session:\n        # Upload final model and metrics with exponential standoff\n        LOGGER.info(f\"{PREFIX}Training completed successfully ✅\\n\"\n                    f\"{PREFIX}Uploading final {session.model_id}\")\n        session.upload_model(trainer.epoch, trainer.best, map=trainer.metrics['metrics/mAP50-95(B)'], final=True)\n        session.alive = False  # stop heartbeats\n        LOGGER.info(f\"{PREFIX}View model at https://hub.com/models/{session.model_id} 🚀\")\ndef on_train_start(trainer):",
        "detail": "yolo.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_train_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.hub",
        "description": "yolo.utils.callbacks.hub",
        "peekOfCode": "def on_train_start(trainer):\n    sync_analytics(trainer.args)\ndef on_val_start(validator):\n    sync_analytics(validator.args)\ndef on_predict_start(predictor):\n    sync_analytics(predictor.args)\ndef on_export_start(exporter):\n    sync_analytics(exporter.args)\ncallbacks = {\n    \"on_pretrain_routine_end\": on_pretrain_routine_end,",
        "detail": "yolo.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_val_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.hub",
        "description": "yolo.utils.callbacks.hub",
        "peekOfCode": "def on_val_start(validator):\n    sync_analytics(validator.args)\ndef on_predict_start(predictor):\n    sync_analytics(predictor.args)\ndef on_export_start(exporter):\n    sync_analytics(exporter.args)\ncallbacks = {\n    \"on_pretrain_routine_end\": on_pretrain_routine_end,\n    \"on_fit_epoch_end\": on_fit_epoch_end,\n    \"on_model_save\": on_model_save,",
        "detail": "yolo.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_predict_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.hub",
        "description": "yolo.utils.callbacks.hub",
        "peekOfCode": "def on_predict_start(predictor):\n    sync_analytics(predictor.args)\ndef on_export_start(exporter):\n    sync_analytics(exporter.args)\ncallbacks = {\n    \"on_pretrain_routine_end\": on_pretrain_routine_end,\n    \"on_fit_epoch_end\": on_fit_epoch_end,\n    \"on_model_save\": on_model_save,\n    \"on_train_end\": on_train_end,\n    \"on_train_start\": on_train_start,",
        "detail": "yolo.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_export_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.hub",
        "description": "yolo.utils.callbacks.hub",
        "peekOfCode": "def on_export_start(exporter):\n    sync_analytics(exporter.args)\ncallbacks = {\n    \"on_pretrain_routine_end\": on_pretrain_routine_end,\n    \"on_fit_epoch_end\": on_fit_epoch_end,\n    \"on_model_save\": on_model_save,\n    \"on_train_end\": on_train_end,\n    \"on_train_start\": on_train_start,\n    \"on_val_start\": on_val_start,\n    \"on_predict_start\": on_predict_start,",
        "detail": "yolo.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "yolo.utils.callbacks.hub",
        "description": "yolo.utils.callbacks.hub",
        "peekOfCode": "callbacks = {\n    \"on_pretrain_routine_end\": on_pretrain_routine_end,\n    \"on_fit_epoch_end\": on_fit_epoch_end,\n    \"on_model_save\": on_model_save,\n    \"on_train_end\": on_train_end,\n    \"on_train_start\": on_train_start,\n    \"on_val_start\": on_val_start,\n    \"on_predict_start\": on_predict_start,\n    \"on_export_start\": on_export_start}",
        "detail": "yolo.utils.callbacks.hub",
        "documentation": {}
    },
    {
        "label": "on_pretrain_routine_start",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.tensorboard",
        "description": "yolo.utils.callbacks.tensorboard",
        "peekOfCode": "def on_pretrain_routine_start(trainer):\n    global writer\n    writer = SummaryWriter(str(trainer.save_dir))\ndef on_batch_end(trainer):\n    _log_scalars(trainer.label_loss_items(trainer.tloss, prefix=\"train\"), trainer.epoch + 1)\ndef on_fit_epoch_end(trainer):\n    _log_scalars(trainer.metrics, trainer.epoch + 1)\ncallbacks = {\n    \"on_pretrain_routine_start\": on_pretrain_routine_start,\n    \"on_fit_epoch_end\": on_fit_epoch_end,",
        "detail": "yolo.utils.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "on_batch_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.tensorboard",
        "description": "yolo.utils.callbacks.tensorboard",
        "peekOfCode": "def on_batch_end(trainer):\n    _log_scalars(trainer.label_loss_items(trainer.tloss, prefix=\"train\"), trainer.epoch + 1)\ndef on_fit_epoch_end(trainer):\n    _log_scalars(trainer.metrics, trainer.epoch + 1)\ncallbacks = {\n    \"on_pretrain_routine_start\": on_pretrain_routine_start,\n    \"on_fit_epoch_end\": on_fit_epoch_end,\n    \"on_batch_end\": on_batch_end}",
        "detail": "yolo.utils.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "on_fit_epoch_end",
        "kind": 2,
        "importPath": "yolo.utils.callbacks.tensorboard",
        "description": "yolo.utils.callbacks.tensorboard",
        "peekOfCode": "def on_fit_epoch_end(trainer):\n    _log_scalars(trainer.metrics, trainer.epoch + 1)\ncallbacks = {\n    \"on_pretrain_routine_start\": on_pretrain_routine_start,\n    \"on_fit_epoch_end\": on_fit_epoch_end,\n    \"on_batch_end\": on_batch_end}",
        "detail": "yolo.utils.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "writer",
        "kind": 5,
        "importPath": "yolo.utils.callbacks.tensorboard",
        "description": "yolo.utils.callbacks.tensorboard",
        "peekOfCode": "writer = None  # TensorBoard SummaryWriter instance\ndef _log_scalars(scalars, step=0):\n    for k, v in scalars.items():\n        writer.add_scalar(k, v, step)\ndef on_pretrain_routine_start(trainer):\n    global writer\n    writer = SummaryWriter(str(trainer.save_dir))\ndef on_batch_end(trainer):\n    _log_scalars(trainer.label_loss_items(trainer.tloss, prefix=\"train\"), trainer.epoch + 1)\ndef on_fit_epoch_end(trainer):",
        "detail": "yolo.utils.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "callbacks",
        "kind": 5,
        "importPath": "yolo.utils.callbacks.tensorboard",
        "description": "yolo.utils.callbacks.tensorboard",
        "peekOfCode": "callbacks = {\n    \"on_pretrain_routine_start\": on_pretrain_routine_start,\n    \"on_fit_epoch_end\": on_fit_epoch_end,\n    \"on_batch_end\": on_batch_end}",
        "detail": "yolo.utils.callbacks.tensorboard",
        "documentation": {}
    },
    {
        "label": "check_train_batch_size",
        "kind": 2,
        "importPath": "yolo.utils.autobatch",
        "description": "yolo.utils.autobatch",
        "peekOfCode": "def check_train_batch_size(model, imgsz=640, amp=True):\n    # Check YOLOv5 training batch size\n    with torch.cuda.amp.autocast(amp):\n        return autobatch(deepcopy(model).train(), imgsz)  # compute optimal batch size\ndef autobatch(model, imgsz=640, fraction=0.7, batch_size=16):\n    # Automatically estimate best YOLOv5 batch size to use `fraction` of available CUDA memory\n    # Usage:\n    #     import torch\n    #     from utils.autobatch import autobatch\n    #     model = torch.hub.load('ultralytics/yolov5', 'yolov5s', autoshape=False)",
        "detail": "yolo.utils.autobatch",
        "documentation": {}
    },
    {
        "label": "autobatch",
        "kind": 2,
        "importPath": "yolo.utils.autobatch",
        "description": "yolo.utils.autobatch",
        "peekOfCode": "def autobatch(model, imgsz=640, fraction=0.7, batch_size=16):\n    # Automatically estimate best YOLOv5 batch size to use `fraction` of available CUDA memory\n    # Usage:\n    #     import torch\n    #     from utils.autobatch import autobatch\n    #     model = torch.hub.load('ultralytics/yolov5', 'yolov5s', autoshape=False)\n    #     print(autobatch(model))\n    # Check device\n    prefix = colorstr('AutoBatch: ')\n    LOGGER.info(f'{prefix}Computing optimal batch size for --imgsz {imgsz}')",
        "detail": "yolo.utils.autobatch",
        "documentation": {}
    },
    {
        "label": "is_ascii",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def is_ascii(s) -> bool:\n    \"\"\"\n    Check if a string is composed of only ASCII characters.\n    Args:\n        s (str): String to be checked.\n    Returns:\n        bool: True if the string is composed only of ASCII characters, False otherwise.\n    \"\"\"\n    # Convert list, tuple, None, etc. to string\n    s = str(s)",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imgsz",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def check_imgsz(imgsz, stride=32, min_dim=1, floor=0):\n    \"\"\"\n    Verify image size is a multiple of the given stride in each dimension. If the image size is not a multiple of the\n    stride, update it to the nearest multiple of the stride that is greater than or equal to the given floor value.\n    Args:\n        imgsz (int or List[int]): Image size.\n        stride (int): Stride value.\n        min_dim (int): Minimum number of dimensions.\n        floor (int): Minimum allowed value for image size.\n    Returns:",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_version",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def check_version(current: str = \"0.0.0\",\n                  minimum: str = \"0.0.0\",\n                  name: str = \"version \",\n                  pinned: bool = False,\n                  hard: bool = False,\n                  verbose: bool = False) -> bool:\n    \"\"\"\n    Check current version against the required minimum version.\n    Args:\n        current (str): Current version.",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_font",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def check_font(font: str = FONT, progress: bool = False) -> None:\n    \"\"\"\n    Download font file to the user's configuration directory if it does not already exist.\n    Args:\n        font (str): Path to font file.\n        progress (bool): If True, display a progress bar during the download.\n    Returns:\n        None\n    \"\"\"\n    font = Path(font)",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_online",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def check_online() -> bool:\n    \"\"\"\n    Check internet connectivity by attempting to connect to a known online host.\n    Returns:\n        bool: True if connection is successful, False otherwise.\n    \"\"\"\n    import socket\n    try:\n        # Check host accessibility by attempting to establish a connection\n        socket.create_connection((\"1.1.1.1\", 443), timeout=5)",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_python",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def check_python(minimum: str = '3.7.0') -> bool:\n    \"\"\"\n    Check current python version against the required minimum version.\n    Args:\n        minimum (str): Required minimum version of python.\n    Returns:\n        None\n    \"\"\"\n    check_version(platform.python_version(), minimum, name='Python ', hard=True)\n@TryExcept()",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_requirements",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def check_requirements(requirements=ROOT.parent / 'requirements.txt', exclude=(), install=True, cmds=''):\n    # Check installed dependencies meet YOLOv5 requirements (pass *.txt file or list of packages or single package str)\n    prefix = colorstr('red', 'bold', 'requirements:')\n    check_python()  # check python version\n    if isinstance(requirements, Path):  # requirements.txt file\n        file = requirements.resolve()\n        assert file.exists(), f\"{prefix} {file} not found, check failed.\"\n        with file.open() as f:\n            requirements = [f'{x.name}{x.specifier}' for x in pkg.parse_requirements(f) if x.name not in exclude]\n    elif isinstance(requirements, str):",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_suffix",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def check_suffix(file='yolov8n.pt', suffix=('.pt',), msg=''):\n    # Check file(s) for acceptable suffix\n    if file and suffix:\n        if isinstance(suffix, str):\n            suffix = [suffix]\n        for f in file if isinstance(file, (list, tuple)) else [file]:\n            s = Path(f).suffix.lower()  # file suffix\n            if len(s):\n                assert s in suffix, f\"{msg}{f} acceptable suffix is {suffix}\"\ndef check_file(file, suffix=''):",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_file",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def check_file(file, suffix=''):\n    # Search/download file (if necessary) and return path\n    check_suffix(file, suffix)  # optional\n    file = str(file)  # convert to str()\n    if Path(file).is_file() or not file:  # exists\n        return file\n    elif file.startswith(('http:/', 'https:/')):  # download\n        url = file  # warning: Pathlib turns :// -> :/\n        file = Path(urllib.parse.unquote(file).split('?')[0]).name  # '%2F' to '/', split https://url.com/file.txt?auth\n        if Path(file).is_file():",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_yaml",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def check_yaml(file, suffix=('.yaml', '.yml')):\n    # Search/download YAML file (if necessary) and return path, checking suffix\n    return check_file(file, suffix)\ndef check_imshow(warn=False):\n    # Check if environment supports image displays\n    try:\n        assert not is_jupyter_notebook()\n        assert not is_docker()\n        cv2.imshow('test', np.zeros((1, 1, 3)))\n        cv2.waitKey(1)",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "check_imshow",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def check_imshow(warn=False):\n    # Check if environment supports image displays\n    try:\n        assert not is_jupyter_notebook()\n        assert not is_docker()\n        cv2.imshow('test', np.zeros((1, 1, 3)))\n        cv2.waitKey(1)\n        cv2.destroyAllWindows()\n        cv2.waitKey(1)\n        return True",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "git_describe",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def git_describe(path=ROOT):  # path must be a directory\n    # Return human-readable git description, i.e. v5.0-5-g3e25f1e https://git-scm.com/docs/git-describe\n    try:\n        assert (Path(path) / '.git').is_dir()\n        return check_output(f'git -C {path} describe --tags --long --always', shell=True).decode()[:-1]\n    except Exception:\n        return ''\ndef print_args(args: Optional[dict] = None, show_file=True, show_func=False):\n    # Print function arguments (optional args dict)\n    x = inspect.currentframe().f_back  # previous frame",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "print_args",
        "kind": 2,
        "importPath": "yolo.utils.checks",
        "description": "yolo.utils.checks",
        "peekOfCode": "def print_args(args: Optional[dict] = None, show_file=True, show_func=False):\n    # Print function arguments (optional args dict)\n    x = inspect.currentframe().f_back  # previous frame\n    file, _, func, _, _ = inspect.getframeinfo(x)\n    if args is None:  # get args automatically\n        args, _, _, frm = inspect.getargvalues(x)\n        args = {k: v for k, v in frm.items() if k in args}\n    try:\n        file = Path(file).resolve().relative_to(ROOT).with_suffix('')\n    except ValueError:",
        "detail": "yolo.utils.checks",
        "documentation": {}
    },
    {
        "label": "find_free_network_port",
        "kind": 2,
        "importPath": "yolo.utils.dist",
        "description": "yolo.utils.dist",
        "peekOfCode": "def find_free_network_port() -> int:\n    # https://github.com/Lightning-AI/lightning/blob/master/src/lightning_lite/plugins/environments/lightning.py\n    \"\"\"Finds a free port on localhost.\n    It is useful in single-node training when we don't want to connect to a real main node but have to set the\n    `MASTER_PORT` environment variable.\n    \"\"\"\n    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    s.bind((\"\", 0))\n    port = s.getsockname()[1]\n    s.close()",
        "detail": "yolo.utils.dist",
        "documentation": {}
    },
    {
        "label": "generate_ddp_file",
        "kind": 2,
        "importPath": "yolo.utils.dist",
        "description": "yolo.utils.dist",
        "peekOfCode": "def generate_ddp_file(trainer):\n    import_path = '.'.join(str(trainer.__class__).split(\".\")[1:-1])\n    if not trainer.resume:\n        shutil.rmtree(trainer.save_dir)  # remove the save_dir\n    content = f'''config = {dict(trainer.args)} \\nif __name__ == \"__main__\":\n    from {import_path} import {trainer.__class__.__name__}\n    trainer = {trainer.__class__.__name__}(config=config)\n    trainer.train()'''\n    (USER_CONFIG_DIR / 'DDP').mkdir(exist_ok=True)\n    with tempfile.NamedTemporaryFile(prefix=\"_temp_\",",
        "detail": "yolo.utils.dist",
        "documentation": {}
    },
    {
        "label": "generate_ddp_command",
        "kind": 2,
        "importPath": "yolo.utils.dist",
        "description": "yolo.utils.dist",
        "peekOfCode": "def generate_ddp_command(world_size, trainer):\n    import __main__  # noqa local import to avoid https://github.com/Lightning-AI/lightning/issues/15218\n    file_name = os.path.abspath(sys.argv[0])\n    using_cli = not file_name.endswith(\".py\")\n    if using_cli:\n        file_name = generate_ddp_file(trainer)\n    return [\n        sys.executable, \"-m\", \"torch.distributed.run\", \"--nproc_per_node\", f\"{world_size}\", \"--master_port\",\n        f\"{find_free_network_port()}\", file_name] + sys.argv[1:]\ndef ddp_cleanup(command, trainer):",
        "detail": "yolo.utils.dist",
        "documentation": {}
    },
    {
        "label": "ddp_cleanup",
        "kind": 2,
        "importPath": "yolo.utils.dist",
        "description": "yolo.utils.dist",
        "peekOfCode": "def ddp_cleanup(command, trainer):\n    # delete temp file if created\n    tempfile_suffix = f\"{id(trainer)}.py\"\n    if tempfile_suffix in \"\".join(command):\n        for chunk in command:\n            if tempfile_suffix in chunk:\n                os.remove(chunk)\n                break",
        "detail": "yolo.utils.dist",
        "documentation": {}
    },
    {
        "label": "safe_download",
        "kind": 2,
        "importPath": "yolo.utils.downloads",
        "description": "yolo.utils.downloads",
        "peekOfCode": "def safe_download(file, url, url2=None, min_bytes=1E0, error_msg=''):\n    # Attempts to download file from url or url2, checks and removes incomplete downloads < min_bytes\n    file = Path(file)\n    assert_msg = f\"Downloaded file '{file}' does not exist or size is < min_bytes={min_bytes}\"\n    try:  # url1\n        LOGGER.info(f'Downloading {url} to {file}...')\n        torch.hub.download_url_to_file(url, str(file), progress=LOGGER.level <= logging.INFO)\n        assert file.exists() and file.stat().st_size > min_bytes, assert_msg  # check\n    except Exception as e:  # url2\n        if file.exists():",
        "detail": "yolo.utils.downloads",
        "documentation": {}
    },
    {
        "label": "is_url",
        "kind": 2,
        "importPath": "yolo.utils.downloads",
        "description": "yolo.utils.downloads",
        "peekOfCode": "def is_url(url, check=True):\n    # Check if string is URL and check if URL exists\n    try:\n        url = str(url)\n        result = urllib.parse.urlparse(url)\n        assert all([result.scheme, result.netloc])  # check if is url\n        return (urllib.request.urlopen(url).getcode() == 200) if check else True  # check if exists online\n    except (AssertionError, urllib.request.HTTPError):\n        return False\ndef attempt_download(file, repo='ultralytics/assets', release='v0.0.0'):",
        "detail": "yolo.utils.downloads",
        "documentation": {}
    },
    {
        "label": "attempt_download",
        "kind": 2,
        "importPath": "yolo.utils.downloads",
        "description": "yolo.utils.downloads",
        "peekOfCode": "def attempt_download(file, repo='ultralytics/assets', release='v0.0.0'):\n    # Attempt file download from GitHub release assets if not found locally. release = 'latest', 'v6.2', etc.\n    def github_assets(repository, version='latest'):\n        # Return GitHub repo tag and assets (i.e. ['yolov8n.pt', 'yolov5m.pt', ...])\n        # Return GitHub repo tag and assets (i.e. ['yolov8n.pt', 'yolov8s.pt', ...])\n        if version != 'latest':\n            version = f'tags/{version}'  # i.e. tags/v6.2\n        response = requests.get(f'https://api.github.com/repos/{repository}/releases/{version}').json()  # github api\n        return response['tag_name'], [x['name'] for x in response['assets']]  # tag, assets\n    file = Path(str(file).strip().replace(\"'\", ''))",
        "detail": "yolo.utils.downloads",
        "documentation": {}
    },
    {
        "label": "download",
        "kind": 2,
        "importPath": "yolo.utils.downloads",
        "description": "yolo.utils.downloads",
        "peekOfCode": "def download(url, dir=Path.cwd(), unzip=True, delete=True, curl=False, threads=1, retry=3):\n    # Multithreaded file download and unzip function, used in data.yaml for autodownload\n    def download_one(url, dir):\n        # Download 1 file\n        success = True\n        if Path(url).is_file():\n            f = Path(url)  # filename\n        else:  # does not exist\n            f = dir / Path(url).name\n            LOGGER.info(f'Downloading {url} to {f}...')",
        "detail": "yolo.utils.downloads",
        "documentation": {}
    },
    {
        "label": "WorkingDirectory",
        "kind": 6,
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "peekOfCode": "class WorkingDirectory(contextlib.ContextDecorator):\n    # Usage: @WorkingDirectory(dir) decorator or 'with WorkingDirectory(dir):' context manager\n    def __init__(self, new_dir):\n        self.dir = new_dir  # new dir\n        self.cwd = Path.cwd().resolve()  # current dir\n    def __enter__(self):\n        os.chdir(self.dir)\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        os.chdir(self.cwd)\ndef increment_path(path, exist_ok=False, sep='', mkdir=False):",
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "increment_path",
        "kind": 2,
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "peekOfCode": "def increment_path(path, exist_ok=False, sep='', mkdir=False):\n    \"\"\"\n    Increments a file or directory path, i.e. runs/exp --> runs/exp{sep}2, runs/exp{sep}3, ... etc.\n    If the path exists and exist_ok is not set to True, the path will be incremented by appending a number and sep to\n    the end of the path. If the path is a file, the file extension will be preserved. If the path is a directory, the\n    number will be appended directly to the end of the path. If mkdir is set to True, the path will be created as a\n    directory if it does not already exist.\n    Args:\n    path (str or pathlib.Path): Path to increment.\n    exist_ok (bool, optional): If True, the path will not be incremented and will be returned as-is. Defaults to False.",
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "unzip_file",
        "kind": 2,
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "peekOfCode": "def unzip_file(file, path=None, exclude=('.DS_Store', '__MACOSX')):\n    # Unzip a *.zip file to path/, excluding files containing strings in exclude list\n    if path is None:\n        path = Path(file).parent  # default path\n    with ZipFile(file) as zipObj:\n        for f in zipObj.namelist():  # list all archived filenames in the zip\n            if all(x not in f for x in exclude):\n                zipObj.extract(f, path=path)\ndef file_age(path=__file__):\n    # Return days since last file update",
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "file_age",
        "kind": 2,
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "peekOfCode": "def file_age(path=__file__):\n    # Return days since last file update\n    dt = (datetime.now() - datetime.fromtimestamp(Path(path).stat().st_mtime))  # delta\n    return dt.days  # + dt.seconds / 86400  # fractional days\ndef file_date(path=__file__):\n    # Return human-readable file modification date, i.e. '2021-3-26'\n    t = datetime.fromtimestamp(Path(path).stat().st_mtime)\n    return f'{t.year}-{t.month}-{t.day}'\ndef file_size(path):\n    # Return file/dir size (MB)",
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "file_date",
        "kind": 2,
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "peekOfCode": "def file_date(path=__file__):\n    # Return human-readable file modification date, i.e. '2021-3-26'\n    t = datetime.fromtimestamp(Path(path).stat().st_mtime)\n    return f'{t.year}-{t.month}-{t.day}'\ndef file_size(path):\n    # Return file/dir size (MB)\n    mb = 1 << 20  # bytes to MiB (1024 ** 2)\n    path = Path(path)\n    if path.is_file():\n        return path.stat().st_size / mb",
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "file_size",
        "kind": 2,
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "peekOfCode": "def file_size(path):\n    # Return file/dir size (MB)\n    mb = 1 << 20  # bytes to MiB (1024 ** 2)\n    path = Path(path)\n    if path.is_file():\n        return path.stat().st_size / mb\n    elif path.is_dir():\n        return sum(f.stat().st_size for f in path.glob('**/*') if f.is_file()) / mb\n    else:\n        return 0.0",
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "url2file",
        "kind": 2,
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "peekOfCode": "def url2file(url):\n    # Convert URL to filename, i.e. https://url.com/file.txt?auth -> file.txt\n    url = str(Path(url)).replace(':/', '://')  # Pathlib turns :// -> :/\n    return Path(urllib.parse.unquote(url)).name.split('?')[0]  # '%2F' to '/', split https://url.com/file.txt?auth\ndef get_latest_run(search_dir='.'):\n    # Return path to most recent 'last.pt' in /runs (i.e. to --resume from)\n    last_list = glob.glob(f'{search_dir}/**/last*.pt', recursive=True)\n    return max(last_list, key=os.path.getctime) if last_list else ''",
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "get_latest_run",
        "kind": 2,
        "importPath": "yolo.utils.files",
        "description": "yolo.utils.files",
        "peekOfCode": "def get_latest_run(search_dir='.'):\n    # Return path to most recent 'last.pt' in /runs (i.e. to --resume from)\n    last_list = glob.glob(f'{search_dir}/**/last*.pt', recursive=True)\n    return max(last_list, key=os.path.getctime) if last_list else ''",
        "detail": "yolo.utils.files",
        "documentation": {}
    },
    {
        "label": "Bboxes",
        "kind": 6,
        "importPath": "yolo.utils.instance",
        "description": "yolo.utils.instance",
        "peekOfCode": "class Bboxes:\n    \"\"\"Now only numpy is supported\"\"\"\n    def __init__(self, bboxes, format=\"xyxy\") -> None:\n        assert format in _formats\n        bboxes = bboxes[None, :] if bboxes.ndim == 1 else bboxes\n        assert bboxes.ndim == 2\n        assert bboxes.shape[1] == 4\n        self.bboxes = bboxes\n        self.format = format\n        # self.normalized = normalized",
        "detail": "yolo.utils.instance",
        "documentation": {}
    },
    {
        "label": "Instances",
        "kind": 6,
        "importPath": "yolo.utils.instance",
        "description": "yolo.utils.instance",
        "peekOfCode": "class Instances:\n    def __init__(self, bboxes, segments=None, keypoints=None, bbox_format=\"xywh\", normalized=True) -> None:\n        \"\"\"\n        Args:\n            bboxes (ndarray): bboxes with shape [N, 4].\n            segments (list | ndarray): segments.\n            keypoints (ndarray): keypoints with shape [N, 17, 2].\n        \"\"\"\n        if segments is None:\n            segments = []",
        "detail": "yolo.utils.instance",
        "documentation": {}
    },
    {
        "label": "to_4tuple",
        "kind": 5,
        "importPath": "yolo.utils.instance",
        "description": "yolo.utils.instance",
        "peekOfCode": "to_4tuple = _ntuple(4)\n# `xyxy` means left top and right bottom\n# `xywh` means center x, center y and width, height(yolo format)\n# `ltwh` means left top and width, height(coco format)\n_formats = [\"xyxy\", \"xywh\", \"ltwh\"]\n__all__ = [\"Bboxes\"]\nclass Bboxes:\n    \"\"\"Now only numpy is supported\"\"\"\n    def __init__(self, bboxes, format=\"xyxy\") -> None:\n        assert format in _formats",
        "detail": "yolo.utils.instance",
        "documentation": {}
    },
    {
        "label": "_formats",
        "kind": 5,
        "importPath": "yolo.utils.instance",
        "description": "yolo.utils.instance",
        "peekOfCode": "_formats = [\"xyxy\", \"xywh\", \"ltwh\"]\n__all__ = [\"Bboxes\"]\nclass Bboxes:\n    \"\"\"Now only numpy is supported\"\"\"\n    def __init__(self, bboxes, format=\"xyxy\") -> None:\n        assert format in _formats\n        bboxes = bboxes[None, :] if bboxes.ndim == 1 else bboxes\n        assert bboxes.ndim == 2\n        assert bboxes.shape[1] == 4\n        self.bboxes = bboxes",
        "detail": "yolo.utils.instance",
        "documentation": {}
    },
    {
        "label": "__all__",
        "kind": 5,
        "importPath": "yolo.utils.instance",
        "description": "yolo.utils.instance",
        "peekOfCode": "__all__ = [\"Bboxes\"]\nclass Bboxes:\n    \"\"\"Now only numpy is supported\"\"\"\n    def __init__(self, bboxes, format=\"xyxy\") -> None:\n        assert format in _formats\n        bboxes = bboxes[None, :] if bboxes.ndim == 1 else bboxes\n        assert bboxes.ndim == 2\n        assert bboxes.shape[1] == 4\n        self.bboxes = bboxes\n        self.format = format",
        "detail": "yolo.utils.instance",
        "documentation": {}
    },
    {
        "label": "VarifocalLoss",
        "kind": 6,
        "importPath": "yolo.utils.loss",
        "description": "yolo.utils.loss",
        "peekOfCode": "class VarifocalLoss(nn.Module):\n    # Varifocal loss by Zhang et al. https://arxiv.org/abs/2008.13367\n    def __init__(self):\n        super().__init__()\n    def forward(self, pred_score, gt_score, label, alpha=0.75, gamma=2.0):\n        weight = alpha * pred_score.sigmoid().pow(gamma) * (1 - label) + gt_score * label\n        with torch.cuda.amp.autocast(enabled=False):\n            loss = (F.binary_cross_entropy_with_logits(pred_score.float(), gt_score.float(), reduction=\"none\") *\n                    weight).sum()\n        return loss",
        "detail": "yolo.utils.loss",
        "documentation": {}
    },
    {
        "label": "BboxLoss",
        "kind": 6,
        "importPath": "yolo.utils.loss",
        "description": "yolo.utils.loss",
        "peekOfCode": "class BboxLoss(nn.Module):\n    def __init__(self, reg_max, use_dfl=False):\n        super().__init__()\n        self.reg_max = reg_max\n        self.use_dfl = use_dfl\n    def forward(self, pred_dist, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask):\n        # IoU loss\n        weight = torch.masked_select(target_scores.sum(-1), fg_mask).unsqueeze(-1)\n        iou = bbox_iou(pred_bboxes[fg_mask], target_bboxes[fg_mask], xywh=False, CIoU=True)\n        loss_iou = ((1.0 - iou) * weight).sum() / target_scores_sum",
        "detail": "yolo.utils.loss",
        "documentation": {}
    },
    {
        "label": "FocalLoss",
        "kind": 6,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "class FocalLoss(nn.Module):\n    # Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)\n    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):\n        super().__init__()\n        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = loss_fcn.reduction\n        self.loss_fcn.reduction = 'none'  # required to apply FL to each element\n    def forward(self, pred, true):",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "ConfusionMatrix",
        "kind": 6,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "class ConfusionMatrix:\n    # Updated version of https://github.com/kaanakan/object_detection_confusion_matrix\n    def __init__(self, nc, conf=0.25, iou_thres=0.45):\n        self.matrix = np.zeros((nc + 1, nc + 1))\n        self.nc = nc  # number of classes\n        self.conf = conf\n        self.iou_thres = iou_thres\n    def process_batch(self, detections, labels):\n        \"\"\"\n        Return intersection-over-union (Jaccard index) of boxes.",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "Metric",
        "kind": 6,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "class Metric:\n    def __init__(self) -> None:\n        self.p = []  # (nc, )\n        self.r = []  # (nc, )\n        self.f1 = []  # (nc, )\n        self.all_ap = []  # (nc, 10)\n        self.ap_class_index = []  # (nc, )\n    @property\n    def ap50(self):\n        \"\"\"AP@0.5 of all classes.",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "DetMetrics",
        "kind": 6,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "class DetMetrics:\n    def __init__(self, save_dir=Path(\".\"), plot=False, names=()) -> None:\n        self.save_dir = save_dir\n        self.plot = plot\n        self.names = names\n        self.metric = Metric()\n    def process(self, tp, conf, pred_cls, target_cls):\n        results = ap_per_class(tp, conf, pred_cls, target_cls, plot=self.plot, save_dir=self.save_dir,\n                               names=self.names)[2:]\n        self.metric.update(results)",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "SegmentMetrics",
        "kind": 6,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "class SegmentMetrics:\n    def __init__(self, save_dir=Path(\".\"), plot=False, names=()) -> None:\n        self.save_dir = save_dir\n        self.plot = plot\n        self.names = names\n        self.metric_box = Metric()\n        self.metric_mask = Metric()\n    def process(self, tp_m, tp_b, conf, pred_cls, target_cls):\n        results_mask = ap_per_class(tp_m,\n                                    conf,",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "ClassifyMetrics",
        "kind": 6,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "class ClassifyMetrics:\n    def __init__(self) -> None:\n        self.top1 = 0\n        self.top5 = 0\n    def process(self, targets, pred):\n        # target classes and predicted classes\n        pred, targets = torch.cat(pred), torch.cat(targets)\n        correct = (targets[:, None] == pred).float()\n        acc = torch.stack((correct[:, 0], correct.max(1).values), dim=1)  # (top1, top5) accuracy\n        self.top1, self.top5 = acc.mean(0).tolist()",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "box_area",
        "kind": 2,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "def box_area(box):\n    # box = xyxy(4,n)\n    return (box[2] - box[0]) * (box[3] - box[1])\ndef bbox_ioa(box1, box2, eps=1e-7):\n    \"\"\"Returns the intersection over box2 area given box1, box2. Boxes are x1y1x2y2\n    box1:       np.array of shape(nx4)\n    box2:       np.array of shape(mx4)\n    returns:    np.array of shape(nxm)\n    \"\"\"\n    # Get the coordinates of bounding boxes",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "bbox_ioa",
        "kind": 2,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "def bbox_ioa(box1, box2, eps=1e-7):\n    \"\"\"Returns the intersection over box2 area given box1, box2. Boxes are x1y1x2y2\n    box1:       np.array of shape(nx4)\n    box2:       np.array of shape(mx4)\n    returns:    np.array of shape(nxm)\n    \"\"\"\n    # Get the coordinates of bounding boxes\n    b1_x1, b1_y1, b1_x2, b1_y2 = box1.T\n    b2_x1, b2_y1, b2_x2, b2_y2 = box2.T\n    # Intersection area",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "box_iou",
        "kind": 2,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "def box_iou(box1, box2, eps=1e-7):\n    # https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py\n    \"\"\"\n    Return intersection-over-union (Jaccard index) of boxes.\n    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n    Arguments:\n        box1 (Tensor[N, 4])\n        box2 (Tensor[M, 4])\n    Returns:\n        iou (Tensor[N, M]): the NxM matrix containing the pairwise",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "bbox_iou",
        "kind": 2,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "def bbox_iou(box1, box2, xywh=True, GIoU=False, DIoU=False, CIoU=False, eps=1e-7):\n    # Returns Intersection over Union (IoU) of box1(1,4) to box2(n,4)\n    # Get the coordinates of bounding boxes\n    if xywh:  # transform from xywh to xyxy\n        (x1, y1, w1, h1), (x2, y2, w2, h2) = box1.chunk(4, -1), box2.chunk(4, -1)\n        w1_, h1_, w2_, h2_ = w1 / 2, h1 / 2, w2 / 2, h2 / 2\n        b1_x1, b1_x2, b1_y1, b1_y2 = x1 - w1_, x1 + w1_, y1 - h1_, y1 + h1_\n        b2_x1, b2_x2, b2_y1, b2_y2 = x2 - w2_, x2 + w2_, y2 - h2_, y2 + h2_\n    else:  # x1, y1, x2, y2 = box1\n        b1_x1, b1_y1, b1_x2, b1_y2 = box1.chunk(4, -1)",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "mask_iou",
        "kind": 2,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "def mask_iou(mask1, mask2, eps=1e-7):\n    \"\"\"\n    mask1: [N, n] m1 means number of predicted objects\n    mask2: [M, n] m2 means number of gt objects\n    Note: n means image_w x image_h\n    return: masks iou, [N, M]\n    \"\"\"\n    intersection = torch.matmul(mask1, mask2.t()).clamp(0)\n    union = (mask1.sum(1)[:, None] + mask2.sum(1)[None]) - intersection  # (area1 + area2) - intersection\n    return intersection / (union + eps)",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "masks_iou",
        "kind": 2,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "def masks_iou(mask1, mask2, eps=1e-7):\n    \"\"\"\n    mask1: [N, n] m1 means number of predicted objects\n    mask2: [N, n] m2 means number of gt objects\n    Note: n means image_w x image_h\n    return: masks iou, (N, )\n    \"\"\"\n    intersection = (mask1 * mask2).sum(1).clamp(0)  # (N, )\n    union = (mask1.sum(1) + mask2.sum(1))[None] - intersection  # (area1 + area2) - intersection\n    return intersection / (union + eps)",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "smooth_BCE",
        "kind": 2,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "def smooth_BCE(eps=0.1):  # https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441\n    # return positive, negative label smoothing BCE targets\n    return 1.0 - 0.5 * eps, 0.5 * eps\n# losses\nclass FocalLoss(nn.Module):\n    # Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)\n    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):\n        super().__init__()\n        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()\n        self.gamma = gamma",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "smooth",
        "kind": 2,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "def smooth(y, f=0.05):\n    # Box filter of fraction f\n    nf = round(len(y) * f * 2) // 2 + 1  # number of filter elements (must be odd)\n    p = np.ones(nf // 2)  # ones padding\n    yp = np.concatenate((p * y[0], y, p * y[-1]), 0)  # y padded\n    return np.convolve(yp, np.ones(nf) / nf, mode='valid')  # y-smoothed\ndef plot_pr_curve(px, py, ap, save_dir=Path('pr_curve.png'), names=()):\n    # Precision-recall curve\n    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)\n    py = np.stack(py, axis=1)",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "plot_pr_curve",
        "kind": 2,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "def plot_pr_curve(px, py, ap, save_dir=Path('pr_curve.png'), names=()):\n    # Precision-recall curve\n    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)\n    py = np.stack(py, axis=1)\n    if 0 < len(names) < 21:  # display per-class legend if < 21 classes\n        for i, y in enumerate(py.T):\n            ax.plot(px, y, linewidth=1, label=f'{names[i]} {ap[i, 0]:.3f}')  # plot(recall, precision)\n    else:\n        ax.plot(px, py, linewidth=1, color='grey')  # plot(recall, precision)\n    ax.plot(px, py.mean(1), linewidth=3, color='blue', label='all classes %.3f mAP@0.5' % ap[:, 0].mean())",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "plot_mc_curve",
        "kind": 2,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "def plot_mc_curve(px, py, save_dir=Path('mc_curve.png'), names=(), xlabel='Confidence', ylabel='Metric'):\n    # Metric-confidence curve\n    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)\n    if 0 < len(names) < 21:  # display per-class legend if < 21 classes\n        for i, y in enumerate(py):\n            ax.plot(px, y, linewidth=1, label=f'{names[i]}')  # plot(confidence, metric)\n    else:\n        ax.plot(px, py.T, linewidth=1, color='grey')  # plot(confidence, metric)\n    y = smooth(py.mean(0), 0.05)\n    ax.plot(px, y, linewidth=3, color='blue', label=f'all classes {y.max():.2f} at {px[y.argmax()]:.3f}')",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "compute_ap",
        "kind": 2,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "def compute_ap(recall, precision):\n    \"\"\" Compute the average precision, given the recall and precision curves\n    # Arguments\n        recall:    The recall curve (list)\n        precision: The precision curve (list)\n    # Returns\n        Average precision, precision curve, recall curve\n    \"\"\"\n    # Append sentinel values to beginning and end\n    mrec = np.concatenate(([0.0], recall, [1.0]))",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "ap_per_class",
        "kind": 2,
        "importPath": "yolo.utils.metrics",
        "description": "yolo.utils.metrics",
        "peekOfCode": "def ap_per_class(tp, conf, pred_cls, target_cls, plot=False, save_dir=Path(), names=(), eps=1e-16, prefix=\"\"):\n    \"\"\" Compute the average precision, given the recall and precision curves.\n    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n    # Arguments\n        tp:  True positives (nparray, nx1 or nx10).\n        conf:  Objectness value from 0-1 (nparray).\n        pred_cls:  Predicted object classes (nparray).\n        target_cls:  True object classes (nparray).\n        plot:  Plot precision-recall curve at mAP@0.5\n        save_dir:  Plot save directory",
        "detail": "yolo.utils.metrics",
        "documentation": {}
    },
    {
        "label": "Profile",
        "kind": 6,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "class Profile(contextlib.ContextDecorator):\n    # YOLOv5 Profile class. Usage: @Profile() decorator or 'with Profile():' context manager\n    def __init__(self, t=0.0):\n        self.t = t\n        self.cuda = torch.cuda.is_available()\n    def __enter__(self):\n        self.start = self.time()\n        return self\n    def __exit__(self, type, value, traceback):\n        self.dt = self.time() - self.start  # delta-time",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "coco80_to_coco91_class",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def coco80_to_coco91_class():  # converts 80-index (val2014) to 91-index (paper)\n    # https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n    # a = np.loadtxt('data/coco.names', dtype='str', delimiter='\\n')\n    # b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\\n')\n    # x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # darknet to coco\n    # x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]  # coco to darknet\n    return [\n        1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 31, 32, 33, 34,\n        35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\n        64, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90]",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "segment2box",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def segment2box(segment, width=640, height=640):\n    \"\"\"\n    > Convert 1 segment label to 1 box label, applying inside-image constraint, i.e. (xy1, xy2, ...) to\n    (xyxy)\n    Args:\n      segment: the segment label\n      width: the width of the image. Defaults to 640\n      height: The height of the image. Defaults to 640\n    Returns:\n      the minimum and maximum x and y values of the segment.",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "scale_boxes",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def scale_boxes(img1_shape, boxes, img0_shape, ratio_pad=None):\n    \"\"\"\n    > Rescale boxes (xyxy) from img1_shape to img0_shape\n    Args:\n      img1_shape: The shape of the image that the bounding boxes are for.\n      boxes: the bounding boxes of the objects in the image\n      img0_shape: the shape of the original image\n      ratio_pad: a tuple of (ratio, pad)\n    Returns:\n      The boxes are being returned.",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def make_divisible(x, divisor):\n    # Returns nearest x divisible by divisor\n    if isinstance(divisor, torch.Tensor):\n        divisor = int(divisor.max())  # to int\n    return math.ceil(x / divisor) * divisor\ndef non_max_suppression(\n        prediction,\n        conf_thres=0.25,\n        iou_thres=0.45,\n        classes=None,",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "non_max_suppression",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def non_max_suppression(\n        prediction,\n        conf_thres=0.25,\n        iou_thres=0.45,\n        classes=None,\n        agnostic=False,\n        multi_label=False,\n        labels=(),\n        max_det=300,\n        nm=0,  # number of masks",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "clip_boxes",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def clip_boxes(boxes, shape):\n    \"\"\"\n    > It takes a list of bounding boxes and a shape (height, width) and clips the bounding boxes to the\n    shape\n    Args:\n      boxes: the bounding boxes to clip\n      shape: the shape of the image\n    \"\"\"\n    if isinstance(boxes, torch.Tensor):  # faster individually\n        boxes[..., 0].clamp_(0, shape[1])  # x1",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "clip_coords",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def clip_coords(boxes, shape):\n    # Clip bounding xyxy bounding boxes to image shape (height, width)\n    if isinstance(boxes, torch.Tensor):  # faster individually\n        boxes[:, 0].clamp_(0, shape[1])  # x1\n        boxes[:, 1].clamp_(0, shape[0])  # y1\n        boxes[:, 2].clamp_(0, shape[1])  # x2\n        boxes[:, 3].clamp_(0, shape[0])  # y2\n    else:  # np.array (faster grouped)\n        boxes[:, [0, 2]] = boxes[:, [0, 2]].clip(0, shape[1])  # x1, x2\n        boxes[:, [1, 3]] = boxes[:, [1, 3]].clip(0, shape[0])  # y1, y2",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "scale_image",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def scale_image(im1_shape, masks, im0_shape, ratio_pad=None):\n    \"\"\"\n    > It takes a mask, and resizes it to the original image size\n    Args:\n      im1_shape: model input shape, [h, w]\n      masks: [h, w, num]\n      im0_shape: the original image shape\n      ratio_pad: the ratio of the padding to the original image.\n    Returns:\n      The masks are being returned.",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyxy2xywh",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def xyxy2xywh(x):\n    \"\"\"\n    > It takes a list of bounding boxes, and converts them from the format [x1, y1, x2, y2] to [x, y, w,\n    h]  where xy1=top-left, xy2=bottom-right\n    Args:\n      x: the input tensor\n    Returns:\n      the center of the box, the width and the height of the box.\n    \"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywh2xyxy",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def xywh2xyxy(x):\n    \"\"\"\n    > It converts the bounding box from x,y,w,h to x1,y1,x2,y2 where xy1=top-left, xy2=bottom-right\n    Args:\n      x: the input tensor\n    Returns:\n      the top left and bottom right coordinates of the bounding box.\n    \"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[..., 0] = x[..., 0] - x[..., 2] / 2  # top left x",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywhn2xyxy",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def xywhn2xyxy(x, w=640, h=640, padw=0, padh=0):\n    \"\"\"\n    > It converts the normalized coordinates to the actual coordinates [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right\n    Args:\n      x: the bounding box coordinates\n      w: width of the image. Defaults to 640\n      h: height of the image. Defaults to 640\n      padw: padding width. Defaults to 0\n      padh: height of the padding. Defaults to 0\n    Returns:",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyxy2xywhn",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def xyxy2xywhn(x, w=640, h=640, clip=False, eps=0.0):\n    \"\"\"\n    > It takes in a list of bounding boxes, and returns a list of bounding boxes, but with the x and y\n    coordinates normalized to the width and height of the image\n    Args:\n      x: the bounding box coordinates\n      w: width of the image. Defaults to 640\n      h: height of the image. Defaults to 640\n      clip: If True, the boxes will be clipped to the image boundaries. Defaults to False\n      eps: the minimum value of the box's width and height.",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyn2xy",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def xyn2xy(x, w=640, h=640, padw=0, padh=0):\n    \"\"\"\n    > It converts normalized segments into pixel segments of shape (n,2)\n    Args:\n      x: the normalized coordinates of the bounding box\n      w: width of the image. Defaults to 640\n      h: height of the image. Defaults to 640\n      padw: padding width. Defaults to 0\n      padh: padding height. Defaults to 0\n    Returns:",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xywh2ltwh",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def xywh2ltwh(x):\n    \"\"\"\n    > It converts the bounding box from [x, y, w, h] to [x1, y1, w, h] where xy1=top-left\n    Args:\n      x: the x coordinate of the center of the bounding box\n    Returns:\n      the top left x and y coordinates of the bounding box.\n    \"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "xyxy2ltwh",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def xyxy2ltwh(x):\n    \"\"\"\n    > Convert nx4 boxes from [x1, y1, x2, y2] to [x1, y1, w, h] where xy1=top-left, xy2=bottom-right\n    Args:\n      x: the input tensor\n    Returns:\n      the xyxy2ltwh function.\n    \"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[:, 2] = x[:, 2] - x[:, 0]  # width",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "ltwh2xywh",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def ltwh2xywh(x):\n    \"\"\"\n    > Convert nx4 boxes from [x1, y1, w, h] to [x, y, w, h] where xy1=top-left, xy=center\n    Args:\n      x: the input tensor\n    \"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)\n    y[:, 0] = x[:, 0] + x[:, 2] / 2  # center x\n    y[:, 1] = x[:, 1] + x[:, 3] / 2  # center y\n    return y",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "ltwh2xyxy",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def ltwh2xyxy(x):\n    \"\"\"\n    > It converts the bounding box from [x1, y1, w, h] to [x1, y1, x2, y2] where xy1=top-left,\n    xy2=bottom-right\n    Args:\n      x: the input image\n    Returns:\n      the xyxy coordinates of the bounding boxes.\n    \"\"\"\n    y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "segments2boxes",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def segments2boxes(segments):\n    \"\"\"\n    > It converts segment labels to box labels, i.e. (cls, xy1, xy2, ...) to (cls, xywh)\n    Args:\n      segments: list of segments, each segment is a list of points, each point is a list of x, y\n    coordinates\n    Returns:\n      the xywh coordinates of the bounding boxes.\n    \"\"\"\n    boxes = []",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "resample_segments",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def resample_segments(segments, n=1000):\n    \"\"\"\n    > It takes a list of segments (n,2) and returns a list of segments (n,2) where each segment has been\n    up-sampled to n points\n    Args:\n      segments: a list of (n,2) arrays, where n is the number of points in the segment.\n      n: number of points to resample the segment to. Defaults to 1000\n    Returns:\n      the resampled segments.\n    \"\"\"",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "crop_mask",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def crop_mask(masks, boxes):\n    \"\"\"\n    > It takes a mask and a bounding box, and returns a mask that is cropped to the bounding box\n    Args:\n      masks: [h, w, n] tensor of masks\n      boxes: [n, 4] tensor of bbox coords in relative point form\n    Returns:\n      The masks are being cropped to the bounding box.\n    \"\"\"\n    n, h, w = masks.shape",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "process_mask_upsample",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def process_mask_upsample(protos, masks_in, bboxes, shape):\n    \"\"\"\n    > It takes the output of the mask head, and applies the mask to the bounding boxes. This produces masks of higher\n    quality but is slower.\n    Args:\n      protos: [mask_dim, mask_h, mask_w]\n      masks_in: [n, mask_dim], n is number of masks after nms\n      bboxes: [n, 4], n is number of masks after nms\n      shape: the size of the input image\n    Returns:",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "process_mask",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def process_mask(protos, masks_in, bboxes, shape, upsample=False):\n    \"\"\"\n    > It takes the output of the mask head, and applies the mask to the bounding boxes. This is faster but produces\n    downsampled quality of mask\n    Args:\n      protos: [mask_dim, mask_h, mask_w]\n      masks_in: [n, mask_dim], n is number of masks after nms\n      bboxes: [n, 4], n is number of masks after nms\n      shape: the size of the input image\n    Returns:",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "process_mask_native",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def process_mask_native(protos, masks_in, bboxes, shape):\n    \"\"\"\n    > It takes the output of the mask head, and crops it after upsampling to the bounding boxes.\n    Args:\n      protos: [mask_dim, mask_h, mask_w]\n      masks_in: [n, mask_dim], n is number of masks after nms\n      bboxes: [n, 4], n is number of masks after nms\n      shape: input_image_size, (h, w)\n    Returns:\n      masks: [h, w, n]",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "scale_segments",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def scale_segments(img1_shape, segments, img0_shape, ratio_pad=None, normalize=False):\n    \"\"\"\n    > Rescale segment coords (xyxy) from img1_shape to img0_shape\n    Args:\n      img1_shape: The shape of the image that the segments are from.\n      segments: the segments to be scaled\n      img0_shape: the shape of the image that the segmentation is being applied to\n      ratio_pad: the ratio of the image size to the padded image size.\n      normalize: If True, the coordinates will be normalized to the range [0, 1]. Defaults to False\n    Returns:",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "masks2segments",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def masks2segments(masks, strategy='largest'):\n    \"\"\"\n    > It takes a list of masks(n,h,w) and returns a list of segments(n,xy)\n    Args:\n      masks: the output of the model, which is a tensor of shape (batch_size, 160, 160)\n      strategy: 'concat' or 'largest'. Defaults to largest\n    Returns:\n      segments (List): list of segment masks\n    \"\"\"\n    segments = []",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "clip_segments",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def clip_segments(segments, shape):\n    \"\"\"\n    > It takes a list of line segments (x1,y1,x2,y2) and clips them to the image shape (height, width)\n    Args:\n      segments: a list of segments, each segment is a list of points, each point is a list of x,y\n    coordinates\n      shape: the shape of the image\n    \"\"\"\n    if isinstance(segments, torch.Tensor):  # faster individually\n        segments[:, 0].clamp_(0, shape[1])  # x",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "clean_str",
        "kind": 2,
        "importPath": "yolo.utils.ops",
        "description": "yolo.utils.ops",
        "peekOfCode": "def clean_str(s):\n    # Cleans a string by replacing special characters with underscore _\n    return re.sub(pattern=\"[|@#!¡·$€%&()=?¿^*;:,¨´><+]\", repl=\"_\", string=s)",
        "detail": "yolo.utils.ops",
        "documentation": {}
    },
    {
        "label": "Colors",
        "kind": 6,
        "importPath": "yolo.utils.plotting",
        "description": "yolo.utils.plotting",
        "peekOfCode": "class Colors:\n    # Ultralytics color palette https://com/\n    def __init__(self):\n        # hex = matplotlib.colors.TABLEAU_COLORS.values()\n        hexs = ('7fff00', '7fff00', '7fff00', '7fff00', '7fff00', '7fff00', '7fff00', '7fff00', '1A9334', '00D4BB',\n                '2C99A8', '00C2FF', '344593', '6473FF', '0018EC', '8438FF', '520085', 'CB38FF', 'FF95C8', 'FF37C7')\n        self.palette = [self.hex2rgb(f'#{c}') for c in hexs]\n        self.n = len(self.palette)\n    def __call__(self, i, bgr=False):\n        c = self.palette[int(i) % self.n]",
        "detail": "yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "Annotator",
        "kind": 6,
        "importPath": "yolo.utils.plotting",
        "description": "yolo.utils.plotting",
        "peekOfCode": "class Annotator:\n    # YOLOv5 Annotator for train/val mosaics and jpgs and detect/hub inference annotations\n    def __init__(self, im, line_width=None, font_size=None, font='Arial.ttf', pil=False, example='abc'):\n        assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to Annotator() input images.'\n        non_ascii = not is_ascii(example)  # non-latin labels, i.e. asian, arabic, cyrillic\n        self.pil = pil or non_ascii\n        if self.pil:  # use PIL\n            self.im = im if isinstance(im, Image.Image) else Image.fromarray(im)\n            self.draw = ImageDraw.Draw(self.im)\n            self.font = check_pil_font(font='Arial.Unicode.ttf' if non_ascii else font,",
        "detail": "yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "check_pil_font",
        "kind": 2,
        "importPath": "yolo.utils.plotting",
        "description": "yolo.utils.plotting",
        "peekOfCode": "def check_pil_font(font=FONT, size=10):\n    # Return a PIL TrueType Font, downloading to CONFIG_DIR if necessary\n    font = Path(font)\n    font = font if font.exists() else (USER_CONFIG_DIR / font.name)\n    try:\n        return ImageFont.truetype(str(font) if font.exists() else font.name, size)\n    except Exception:  # download if missing\n        try:\n            check_font(font)\n            return ImageFont.truetype(str(font), size)",
        "detail": "yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "save_one_box",
        "kind": 2,
        "importPath": "yolo.utils.plotting",
        "description": "yolo.utils.plotting",
        "peekOfCode": "def save_one_box(xyxy, im, file=Path('im.jpg'), gain=1.02, pad=10, square=False, BGR=False, save=True):\n    # Save image crop as {file} with crop size multiple {gain} and {pad} pixels. Save and/or return crop\n    xyxy = torch.tensor(xyxy).view(-1, 4)\n    b = xyxy2xywh(xyxy)  # boxes\n    if square:\n        b[:, 2:] = b[:, 2:].max(1)[0].unsqueeze(1)  # attempt rectangle to square\n    b[:, 2:] = b[:, 2:] * gain + pad  # box wh * gain + pad\n    xyxy = xywh2xyxy(b).long()\n    clip_coords(xyxy, im.shape)\n    crop = im[int(xyxy[0, 1]):int(xyxy[0, 3]), int(xyxy[0, 0]):int(xyxy[0, 2]), ::(1 if BGR else -1)]",
        "detail": "yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_images",
        "kind": 2,
        "importPath": "yolo.utils.plotting",
        "description": "yolo.utils.plotting",
        "peekOfCode": "def plot_images(images,\n                batch_idx,\n                cls,\n                bboxes,\n                masks=np.zeros(0, dtype=np.uint8),\n                paths=None,\n                fname='images.jpg',\n                names=None):\n    # Plot image grid with labels\n    if isinstance(images, torch.Tensor):",
        "detail": "yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "plot_results",
        "kind": 2,
        "importPath": "yolo.utils.plotting",
        "description": "yolo.utils.plotting",
        "peekOfCode": "def plot_results(file='path/to/results.csv', dir='', segment=False):\n    # Plot training results.csv. Usage: from utils.plots import *; plot_results('path/to/results.csv')\n    save_dir = Path(file).parent if file else Path(dir)\n    if segment:\n        fig, ax = plt.subplots(2, 8, figsize=(18, 6), tight_layout=True)\n        index = [1, 2, 3, 4, 5, 6, 9, 10, 13, 14, 15, 16, 7, 8, 11, 12]\n    else:\n        fig, ax = plt.subplots(2, 5, figsize=(12, 6), tight_layout=True)\n        index = [1, 2, 3, 4, 5, 8, 9, 10, 6, 7]\n    ax = ax.ravel()",
        "detail": "yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "output_to_target",
        "kind": 2,
        "importPath": "yolo.utils.plotting",
        "description": "yolo.utils.plotting",
        "peekOfCode": "def output_to_target(output, max_det=300):\n    # Convert model output to target format [batch_id, class_id, x, y, w, h, conf] for plotting\n    targets = []\n    for i, o in enumerate(output):\n        box, conf, cls = o[:max_det, :6].cpu().split((4, 1, 1), 1)\n        j = torch.full((conf.shape[0], 1), i)\n        targets.append(torch.cat((j, cls, xyxy2xywh(box), conf), 1))\n    targets = torch.cat(targets, 0).numpy()\n    return targets[:, 0], targets[:, 1], targets[:, 2:]",
        "detail": "yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "colors",
        "kind": 5,
        "importPath": "yolo.utils.plotting",
        "description": "yolo.utils.plotting",
        "peekOfCode": "colors = Colors()  # create instance for 'from utils.plots import colors'\nclass Annotator:\n    # YOLOv5 Annotator for train/val mosaics and jpgs and detect/hub inference annotations\n    def __init__(self, im, line_width=None, font_size=None, font='Arial.ttf', pil=False, example='abc'):\n        assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to Annotator() input images.'\n        non_ascii = not is_ascii(example)  # non-latin labels, i.e. asian, arabic, cyrillic\n        self.pil = pil or non_ascii\n        if self.pil:  # use PIL\n            self.im = im if isinstance(im, Image.Image) else Image.fromarray(im)\n            self.draw = ImageDraw.Draw(self.im)",
        "detail": "yolo.utils.plotting",
        "documentation": {}
    },
    {
        "label": "TaskAlignedAssigner",
        "kind": 6,
        "importPath": "yolo.utils.tal",
        "description": "yolo.utils.tal",
        "peekOfCode": "class TaskAlignedAssigner(nn.Module):\n    def __init__(self, topk=13, num_classes=80, alpha=1.0, beta=6.0, eps=1e-9):\n        super().__init__()\n        self.topk = topk\n        self.num_classes = num_classes\n        self.bg_idx = num_classes\n        self.alpha = alpha\n        self.beta = beta\n        self.eps = eps\n    @torch.no_grad()",
        "detail": "yolo.utils.tal",
        "documentation": {}
    },
    {
        "label": "select_candidates_in_gts",
        "kind": 2,
        "importPath": "yolo.utils.tal",
        "description": "yolo.utils.tal",
        "peekOfCode": "def select_candidates_in_gts(xy_centers, gt_bboxes, eps=1e-9):\n    \"\"\"select the positive anchor center in gt\n    Args:\n        xy_centers (Tensor): shape(h*w, 4)\n        gt_bboxes (Tensor): shape(b, n_boxes, 4)\n    Return:\n        (Tensor): shape(b, n_boxes, h*w)\n    \"\"\"\n    n_anchors = xy_centers.shape[0]\n    bs, n_boxes, _ = gt_bboxes.shape",
        "detail": "yolo.utils.tal",
        "documentation": {}
    },
    {
        "label": "select_highest_overlaps",
        "kind": 2,
        "importPath": "yolo.utils.tal",
        "description": "yolo.utils.tal",
        "peekOfCode": "def select_highest_overlaps(mask_pos, overlaps, n_max_boxes):\n    \"\"\"if an anchor box is assigned to multiple gts,\n        the one with the highest iou will be selected.\n    Args:\n        mask_pos (Tensor): shape(b, n_max_boxes, h*w)\n        overlaps (Tensor): shape(b, n_max_boxes, h*w)\n    Return:\n        target_gt_idx (Tensor): shape(b, h*w)\n        fg_mask (Tensor): shape(b, h*w)\n        mask_pos (Tensor): shape(b, n_max_boxes, h*w)",
        "detail": "yolo.utils.tal",
        "documentation": {}
    },
    {
        "label": "make_anchors",
        "kind": 2,
        "importPath": "yolo.utils.tal",
        "description": "yolo.utils.tal",
        "peekOfCode": "def make_anchors(feats, strides, grid_cell_offset=0.5):\n    \"\"\"Generate anchors from features.\"\"\"\n    anchor_points, stride_tensor = [], []\n    assert feats is not None\n    dtype, device = feats[0].dtype, feats[0].device\n    for i, stride in enumerate(strides):\n        _, _, h, w = feats[i].shape\n        sx = torch.arange(end=w, device=device, dtype=dtype) + grid_cell_offset  # shift x\n        sy = torch.arange(end=h, device=device, dtype=dtype) + grid_cell_offset  # shift y\n        sy, sx = torch.meshgrid(sy, sx, indexing='ij') if TORCH_1_10 else torch.meshgrid(sy, sx)",
        "detail": "yolo.utils.tal",
        "documentation": {}
    },
    {
        "label": "dist2bbox",
        "kind": 2,
        "importPath": "yolo.utils.tal",
        "description": "yolo.utils.tal",
        "peekOfCode": "def dist2bbox(distance, anchor_points, xywh=True, dim=-1):\n    \"\"\"Transform distance(ltrb) to box(xywh or xyxy).\"\"\"\n    lt, rb = torch.split(distance, 2, dim)\n    x1y1 = anchor_points - lt\n    x2y2 = anchor_points + rb\n    if xywh:\n        c_xy = (x1y1 + x2y2) / 2\n        wh = x2y2 - x1y1\n        return torch.cat((c_xy, wh), dim)  # xywh bbox\n    return torch.cat((x1y1, x2y2), dim)  # xyxy bbox",
        "detail": "yolo.utils.tal",
        "documentation": {}
    },
    {
        "label": "bbox2dist",
        "kind": 2,
        "importPath": "yolo.utils.tal",
        "description": "yolo.utils.tal",
        "peekOfCode": "def bbox2dist(anchor_points, bbox, reg_max):\n    \"\"\"Transform bbox(xyxy) to dist(ltrb).\"\"\"\n    x1y1, x2y2 = torch.split(bbox, 2, -1)\n    return torch.cat((anchor_points - x1y1, x2y2 - anchor_points), -1).clamp(0, reg_max - 0.01)  # dist (lt, rb)",
        "detail": "yolo.utils.tal",
        "documentation": {}
    },
    {
        "label": "TORCH_1_10",
        "kind": 5,
        "importPath": "yolo.utils.tal",
        "description": "yolo.utils.tal",
        "peekOfCode": "TORCH_1_10 = check_version(torch.__version__, '1.10.0')\ndef select_candidates_in_gts(xy_centers, gt_bboxes, eps=1e-9):\n    \"\"\"select the positive anchor center in gt\n    Args:\n        xy_centers (Tensor): shape(h*w, 4)\n        gt_bboxes (Tensor): shape(b, n_boxes, 4)\n    Return:\n        (Tensor): shape(b, n_boxes, h*w)\n    \"\"\"\n    n_anchors = xy_centers.shape[0]",
        "detail": "yolo.utils.tal",
        "documentation": {}
    },
    {
        "label": "ModelEMA",
        "kind": 6,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "class ModelEMA:\n    \"\"\" Updated Exponential Moving Average (EMA) from https://github.com/rwightman/pytorch-image-models\n    Keeps a moving average of everything in the model state_dict (parameters and buffers)\n    For EMA details see https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n    \"\"\"\n    def __init__(self, model, decay=0.9999, tau=2000, updates=0):\n        # Create EMA\n        self.ema = deepcopy(de_parallel(model)).eval()  # FP32 EMA\n        self.updates = updates  # number of EMA updates\n        self.decay = lambda x: decay * (1 - math.exp(-x / tau))  # decay exponential ramp (to help early epochs)",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "torch_distributed_zero_first",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def torch_distributed_zero_first(local_rank: int):\n    # Decorator to make all processes in distributed training wait for each local_master to do something\n    initialized = torch.distributed.is_initialized()  # prevent 'Default process group has not been initialized' errors\n    if initialized and local_rank not in {-1, 0}:\n        dist.barrier(device_ids=[local_rank])\n    yield\n    if initialized and local_rank == 0:\n        dist.barrier(device_ids=[0])\ndef smart_inference_mode(torch_1_9=check_version(torch.__version__, '1.9.0')):\n    # Applies torch.inference_mode() decorator if torch>=1.9.0 else torch.no_grad() decorator",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "smart_inference_mode",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def smart_inference_mode(torch_1_9=check_version(torch.__version__, '1.9.0')):\n    # Applies torch.inference_mode() decorator if torch>=1.9.0 else torch.no_grad() decorator\n    def decorate(fn):\n        return (torch.inference_mode if torch_1_9 else torch.no_grad)()(fn)\n    return decorate\ndef DDP_model(model):\n    # Model DDP creation with checks\n    assert not check_version(torch.__version__, '1.12.0', pinned=True), \\\n        'torch==1.12.0 torchvision==0.13.0 DDP training is not supported due to a known issue. ' \\\n        'Please upgrade or downgrade torch to use DDP. See https://github.com/ultralytics/yolov5/issues/8395'",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "DDP_model",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def DDP_model(model):\n    # Model DDP creation with checks\n    assert not check_version(torch.__version__, '1.12.0', pinned=True), \\\n        'torch==1.12.0 torchvision==0.13.0 DDP training is not supported due to a known issue. ' \\\n        'Please upgrade or downgrade torch to use DDP. See https://github.com/ultralytics/yolov5/issues/8395'\n    if check_version(torch.__version__, '1.11.0'):\n        return DDP(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK, static_graph=True)\n    else:\n        return DDP(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK)\ndef select_device(device='', batch_size=0, newline=False):",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "select_device",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def select_device(device='', batch_size=0, newline=False):\n    # device = None or 'cpu' or 0 or '0' or '0,1,2,3'\n    ver = git_describe() or __version__  # git commit or pip package version\n    s = f'Ultralytics YOLOv{ver} 🚀 Python-{platform.python_version()} torch-{torch.__version__} '\n    device = str(device).strip().lower().replace('cuda:', '').replace('none', '')  # to string, 'cuda:0' to '0'\n    cpu = device == 'cpu'\n    mps = device == 'mps'  # Apple Metal Performance Shaders (MPS)\n    if cpu or mps:\n        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # force torch.cuda.is_available() = False\n    elif device:  # non-cpu device requested",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "time_sync",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def time_sync():\n    # PyTorch-accurate time\n    if torch.cuda.is_available():\n        torch.cuda.synchronize()\n    return time.time()\ndef fuse_conv_and_bn(conv, bn):\n    # Fuse Conv2d() and BatchNorm2d() layers https://tehnokv.com/posts/fusing-batchnorm-and-conv/\n    fusedconv = nn.Conv2d(conv.in_channels,\n                          conv.out_channels,\n                          kernel_size=conv.kernel_size,",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "fuse_conv_and_bn",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def fuse_conv_and_bn(conv, bn):\n    # Fuse Conv2d() and BatchNorm2d() layers https://tehnokv.com/posts/fusing-batchnorm-and-conv/\n    fusedconv = nn.Conv2d(conv.in_channels,\n                          conv.out_channels,\n                          kernel_size=conv.kernel_size,\n                          stride=conv.stride,\n                          padding=conv.padding,\n                          dilation=conv.dilation,\n                          groups=conv.groups,\n                          bias=True).requires_grad_(False).to(conv.weight.device)",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "model_info",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def model_info(model, verbose=False, imgsz=640):\n    # Model information. imgsz may be int or list, i.e. imgsz=640 or imgsz=[640, 320]\n    n_p = get_num_params(model)\n    n_g = get_num_gradients(model)  # number gradients\n    if verbose:\n        print(f\"{'layer':>5} {'name':>40} {'gradient':>9} {'parameters':>12} {'shape':>20} {'mu':>10} {'sigma':>10}\")\n        for i, (name, p) in enumerate(model.named_parameters()):\n            name = name.replace('module_list.', '')\n            print('%5g %40s %9s %12g %20s %10.3g %10.3g' %\n                  (i, name, p.requires_grad, p.numel(), list(p.shape), p.mean(), p.std()))",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_num_params",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def get_num_params(model):\n    return sum(x.numel() for x in model.parameters())\ndef get_num_gradients(model):\n    return sum(x.numel() for x in model.parameters() if x.requires_grad)\ndef get_flops(model, imgsz=640):\n    try:\n        model = de_parallel(model)\n        p = next(model.parameters())\n        stride = max(int(model.stride.max()), 32) if hasattr(model, 'stride') else 32  # max stride\n        im = torch.empty((1, p.shape[1], stride, stride), device=p.device)  # input image in BCHW format",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_num_gradients",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def get_num_gradients(model):\n    return sum(x.numel() for x in model.parameters() if x.requires_grad)\ndef get_flops(model, imgsz=640):\n    try:\n        model = de_parallel(model)\n        p = next(model.parameters())\n        stride = max(int(model.stride.max()), 32) if hasattr(model, 'stride') else 32  # max stride\n        im = torch.empty((1, p.shape[1], stride, stride), device=p.device)  # input image in BCHW format\n        flops = thop.profile(deepcopy(model), inputs=(im,), verbose=False)[0] / 1E9 * 2  # stride GFLOPs\n        imgsz = imgsz if isinstance(imgsz, list) else [imgsz, imgsz]  # expand if int/float",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "get_flops",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def get_flops(model, imgsz=640):\n    try:\n        model = de_parallel(model)\n        p = next(model.parameters())\n        stride = max(int(model.stride.max()), 32) if hasattr(model, 'stride') else 32  # max stride\n        im = torch.empty((1, p.shape[1], stride, stride), device=p.device)  # input image in BCHW format\n        flops = thop.profile(deepcopy(model), inputs=(im,), verbose=False)[0] / 1E9 * 2  # stride GFLOPs\n        imgsz = imgsz if isinstance(imgsz, list) else [imgsz, imgsz]  # expand if int/float\n        flops = flops * imgsz[0] / stride * imgsz[1] / stride  # 640x640 GFLOPs\n        return flops",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "initialize_weights",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def initialize_weights(model):\n    for m in model.modules():\n        t = type(m)\n        if t is nn.Conv2d:\n            pass  # nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n        elif t is nn.BatchNorm2d:\n            m.eps = 1e-3\n            m.momentum = 0.03\n        elif t in [nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6, nn.SiLU]:\n            m.inplace = True",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "scale_img",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def scale_img(img, ratio=1.0, same_shape=False, gs=32):  # img(16,3,256,416)\n    # Scales img(bs,3,y,x) by ratio constrained to gs-multiple\n    if ratio == 1.0:\n        return img\n    h, w = img.shape[2:]\n    s = (int(h * ratio), int(w * ratio))  # new size\n    img = F.interpolate(img, size=s, mode='bilinear', align_corners=False)  # resize\n    if not same_shape:  # pad/crop img\n        h, w = (math.ceil(x * ratio / gs) * gs for x in (h, w))\n    return F.pad(img, [0, w - s[1], 0, h - s[0]], value=0.447)  # value = imagenet mean",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "make_divisible",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def make_divisible(x, divisor):\n    # Returns nearest x divisible by divisor\n    if isinstance(divisor, torch.Tensor):\n        divisor = int(divisor.max())  # to int\n    return math.ceil(x / divisor) * divisor\ndef copy_attr(a, b, include=(), exclude=()):\n    # Copy attributes from b to a, options to only include [...] and to exclude [...]\n    for k, v in b.__dict__.items():\n        if (len(include) and k not in include) or k.startswith('_') or k in exclude:\n            continue",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "copy_attr",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def copy_attr(a, b, include=(), exclude=()):\n    # Copy attributes from b to a, options to only include [...] and to exclude [...]\n    for k, v in b.__dict__.items():\n        if (len(include) and k not in include) or k.startswith('_') or k in exclude:\n            continue\n        else:\n            setattr(a, k, v)\ndef intersect_dicts(da, db, exclude=()):\n    # Dictionary intersection of matching keys and shapes, omitting 'exclude' keys, using da values\n    return {k: v for k, v in da.items() if k in db and all(x not in k for x in exclude) and v.shape == db[k].shape}",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "intersect_dicts",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def intersect_dicts(da, db, exclude=()):\n    # Dictionary intersection of matching keys and shapes, omitting 'exclude' keys, using da values\n    return {k: v for k, v in da.items() if k in db and all(x not in k for x in exclude) and v.shape == db[k].shape}\ndef is_parallel(model):\n    # Returns True if model is of type DP or DDP\n    return type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)\ndef de_parallel(model):\n    # De-parallelize a model: returns single-GPU model if model is of type DP or DDP\n    return model.module if is_parallel(model) else model\ndef one_cycle(y1=0.0, y2=1.0, steps=100):",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "is_parallel",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def is_parallel(model):\n    # Returns True if model is of type DP or DDP\n    return type(model) in (nn.parallel.DataParallel, nn.parallel.DistributedDataParallel)\ndef de_parallel(model):\n    # De-parallelize a model: returns single-GPU model if model is of type DP or DDP\n    return model.module if is_parallel(model) else model\ndef one_cycle(y1=0.0, y2=1.0, steps=100):\n    # lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf\n    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1\ndef init_seeds(seed=0, deterministic=False):",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "de_parallel",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def de_parallel(model):\n    # De-parallelize a model: returns single-GPU model if model is of type DP or DDP\n    return model.module if is_parallel(model) else model\ndef one_cycle(y1=0.0, y2=1.0, steps=100):\n    # lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf\n    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1\ndef init_seeds(seed=0, deterministic=False):\n    # Initialize random number generator (RNG) seeds https://pytorch.org/docs/stable/notes/randomness.html\n    random.seed(seed)\n    np.random.seed(seed)",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "one_cycle",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def one_cycle(y1=0.0, y2=1.0, steps=100):\n    # lambda function for sinusoidal ramp from y1 to y2 https://arxiv.org/pdf/1812.01187.pdf\n    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1\ndef init_seeds(seed=0, deterministic=False):\n    # Initialize random number generator (RNG) seeds https://pytorch.org/docs/stable/notes/randomness.html\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)  # for Multi-GPU, exception safe",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "init_seeds",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def init_seeds(seed=0, deterministic=False):\n    # Initialize random number generator (RNG) seeds https://pytorch.org/docs/stable/notes/randomness.html\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)  # for Multi-GPU, exception safe\n    # torch.backends.cudnn.benchmark = True  # AutoBatch problem https://github.com/ultralytics/yolov5/issues/9287\n    if deterministic and check_version(torch.__version__, '1.12.0'):  # https://github.com/ultralytics/yolov5/pull/8213\n        torch.use_deterministic_algorithms(True)",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "strip_optimizer",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def strip_optimizer(f='best.pt', s=''):\n    \"\"\"\n    Strip optimizer from 'f' to finalize training, optionally save as 's'.\n    Usage:\n        from yolo.utils.torch_utils import strip_optimizer\n        from pathlib import Path\n        for f in Path('/Users/glennjocher/Downloads/weights').glob('*.pt'):\n            strip_optimizer(f)\n    Args:\n        f (str): file path to model state to strip the optimizer from. Default is 'best.pt'.",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "guess_task_from_head",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def guess_task_from_head(head):\n    task = None\n    if head.lower() in [\"classify\", \"classifier\", \"cls\", \"fc\"]:\n        task = \"classify\"\n    if head.lower() in [\"detect\"]:\n        task = \"detect\"\n    if head.lower() in [\"segment\"]:\n        task = \"segment\"\n    if not task:\n        raise SyntaxError(\"task or model not recognized! Please refer the docs at : \")  # TODO: add docs links",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "profile",
        "kind": 2,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "def profile(input, ops, n=10, device=None):\n    \"\"\" YOLOv5 speed/memory/FLOPs profiler\n    Usage:\n        input = torch.randn(16, 3, 640, 640)\n        m1 = lambda x: x * torch.sigmoid(x)\n        m2 = nn.SiLU()\n        profile(input, [m1, m2], n=100)  # profile over 100 iterations\n    \"\"\"\n    results = []\n    if not isinstance(device, torch.device):",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "LOCAL_RANK",
        "kind": 5,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html\nRANK = int(os.getenv('RANK', -1))\nWORLD_SIZE = int(os.getenv('WORLD_SIZE', 1))\n@contextmanager\ndef torch_distributed_zero_first(local_rank: int):\n    # Decorator to make all processes in distributed training wait for each local_master to do something\n    initialized = torch.distributed.is_initialized()  # prevent 'Default process group has not been initialized' errors\n    if initialized and local_rank not in {-1, 0}:\n        dist.barrier(device_ids=[local_rank])\n    yield",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "RANK",
        "kind": 5,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "RANK = int(os.getenv('RANK', -1))\nWORLD_SIZE = int(os.getenv('WORLD_SIZE', 1))\n@contextmanager\ndef torch_distributed_zero_first(local_rank: int):\n    # Decorator to make all processes in distributed training wait for each local_master to do something\n    initialized = torch.distributed.is_initialized()  # prevent 'Default process group has not been initialized' errors\n    if initialized and local_rank not in {-1, 0}:\n        dist.barrier(device_ids=[local_rank])\n    yield\n    if initialized and local_rank == 0:",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "WORLD_SIZE",
        "kind": 5,
        "importPath": "yolo.utils.torch_utils",
        "description": "yolo.utils.torch_utils",
        "peekOfCode": "WORLD_SIZE = int(os.getenv('WORLD_SIZE', 1))\n@contextmanager\ndef torch_distributed_zero_first(local_rank: int):\n    # Decorator to make all processes in distributed training wait for each local_master to do something\n    initialized = torch.distributed.is_initialized()  # prevent 'Default process group has not been initialized' errors\n    if initialized and local_rank not in {-1, 0}:\n        dist.barrier(device_ids=[local_rank])\n    yield\n    if initialized and local_rank == 0:\n        dist.barrier(device_ids=[0])",
        "detail": "yolo.utils.torch_utils",
        "documentation": {}
    },
    {
        "label": "DetectionPredictor",
        "kind": 6,
        "importPath": "yolo.v8.detect.detect_and_trk",
        "description": "yolo.v8.detect.detect_and_trk",
        "peekOfCode": "class DetectionPredictor(BasePredictor):\n    def get_annotator(self, img):\n        return Annotator(img, line_width=self.args.line_thickness, example=str(self.model.names))\n    def preprocess(self, img):\n        img = torch.from_numpy(img).to(self.model.device)\n        img = img.half() if self.model.fp16 else img.float()  # uint8 to fp16/32\n        img /= 255  # 0 - 255 to 0.0 - 1.0\n        return img\n    def postprocess(self, preds, img, orig_img):\n        preds = ops.non_max_suppression(preds,",
        "detail": "yolo.v8.detect.detect_and_trk",
        "documentation": {}
    },
    {
        "label": "init_tracker",
        "kind": 2,
        "importPath": "yolo.v8.detect.detect_and_trk",
        "description": "yolo.v8.detect.detect_and_trk",
        "peekOfCode": "def init_tracker():\n    global tracker\n    sort_max_age = 5 \n    sort_min_hits = 2\n    sort_iou_thresh = 0.2\n    tracker =Sort(max_age=sort_max_age,min_hits=sort_min_hits,iou_threshold=sort_iou_thresh)\nrand_color_list = []\ndef draw_boxes(img, bbox, identities=None, categories=None, names=None, offset=(0, 0)):\n    for i, box in enumerate(bbox):\n        x1, y1, x2, y2 = [int(i) for i in box]",
        "detail": "yolo.v8.detect.detect_and_trk",
        "documentation": {}
    },
    {
        "label": "draw_boxes",
        "kind": 2,
        "importPath": "yolo.v8.detect.detect_and_trk",
        "description": "yolo.v8.detect.detect_and_trk",
        "peekOfCode": "def draw_boxes(img, bbox, identities=None, categories=None, names=None, offset=(0, 0)):\n    for i, box in enumerate(bbox):\n        x1, y1, x2, y2 = [int(i) for i in box]\n        x1 += offset[0]\n        x2 += offset[0]\n        y1 += offset[1]\n        y2 += offset[1]\n        id = int(identities[i]) if identities is not None else 0\n        box_center = (int((box[0]+box[2])/2),(int((box[1]+box[3])/2)))\n        label = str(id)",
        "detail": "yolo.v8.detect.detect_and_trk",
        "documentation": {}
    },
    {
        "label": "random_color_list",
        "kind": 2,
        "importPath": "yolo.v8.detect.detect_and_trk",
        "description": "yolo.v8.detect.detect_and_trk",
        "peekOfCode": "def random_color_list():\n    global rand_color_list\n    rand_color_list = []\n    for i in range(0,5005):\n        r = randint(0, 255)\n        g = randint(0, 255)\n        b = randint(0, 255)\n        rand_color = (r, g, b)\n        rand_color_list.append(rand_color)\n    #......................................",
        "detail": "yolo.v8.detect.detect_and_trk",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "yolo.v8.detect.detect_and_trk",
        "description": "yolo.v8.detect.detect_and_trk",
        "peekOfCode": "def predict(cfg):\n    init_tracker()\n    random_color_list()\n    cfg.model = cfg.model or \"yolov8n.pt\"\n    cfg.imgsz = check_imgsz(cfg.imgsz, min_dim=2)  # check image size\n    cfg.source = cfg.source if cfg.source is not None else ROOT / \"assets\"\n    predictor = DetectionPredictor(cfg)\n    predictor()\nif __name__ == \"__main__\":\n    predict()",
        "detail": "yolo.v8.detect.detect_and_trk",
        "documentation": {}
    },
    {
        "label": "tracker",
        "kind": 5,
        "importPath": "yolo.v8.detect.detect_and_trk",
        "description": "yolo.v8.detect.detect_and_trk",
        "peekOfCode": "tracker = None\ndef init_tracker():\n    global tracker\n    sort_max_age = 5 \n    sort_min_hits = 2\n    sort_iou_thresh = 0.2\n    tracker =Sort(max_age=sort_max_age,min_hits=sort_min_hits,iou_threshold=sort_iou_thresh)\nrand_color_list = []\ndef draw_boxes(img, bbox, identities=None, categories=None, names=None, offset=(0, 0)):\n    for i, box in enumerate(bbox):",
        "detail": "yolo.v8.detect.detect_and_trk",
        "documentation": {}
    },
    {
        "label": "rand_color_list",
        "kind": 5,
        "importPath": "yolo.v8.detect.detect_and_trk",
        "description": "yolo.v8.detect.detect_and_trk",
        "peekOfCode": "rand_color_list = []\ndef draw_boxes(img, bbox, identities=None, categories=None, names=None, offset=(0, 0)):\n    for i, box in enumerate(bbox):\n        x1, y1, x2, y2 = [int(i) for i in box]\n        x1 += offset[0]\n        x2 += offset[0]\n        y1 += offset[1]\n        y2 += offset[1]\n        id = int(identities[i]) if identities is not None else 0\n        box_center = (int((box[0]+box[2])/2),(int((box[1]+box[3])/2)))",
        "detail": "yolo.v8.detect.detect_and_trk",
        "documentation": {}
    },
    {
        "label": "DetectionPredictor",
        "kind": 6,
        "importPath": "yolo.v8.detect.predict",
        "description": "yolo.v8.detect.predict",
        "peekOfCode": "class DetectionPredictor(BasePredictor):\n    def get_annotator(self, img):\n        return Annotator(img, line_width=self.args.line_thickness, example=str(self.model.names))\n    def preprocess(self, img):\n        img = torch.from_numpy(img).to(self.model.device)\n        img = img.half() if self.model.fp16 else img.float()  # uint8 to fp16/32\n        img /= 255  # 0 - 255 to 0.0 - 1.0\n        return img\n    def postprocess(self, preds, img, orig_img):\n        preds = ops.non_max_suppression(preds,",
        "detail": "yolo.v8.detect.predict",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "yolo.v8.detect.predict",
        "description": "yolo.v8.detect.predict",
        "peekOfCode": "def predict(cfg):\n    cfg.model = cfg.model or \"yolov8n.pt\"\n    cfg.imgsz = check_imgsz(cfg.imgsz, min_dim=2)  # check image size\n    cfg.source = cfg.source or ROOT / \"assets\"\n    predictor = DetectionPredictor(cfg)\n    predictor()\nif __name__ == \"__main__\":\n    predict()",
        "detail": "yolo.v8.detect.predict",
        "documentation": {}
    },
    {
        "label": "KalmanBoxTracker",
        "kind": 6,
        "importPath": "yolo.v8.detect.sort",
        "description": "yolo.v8.detect.sort",
        "peekOfCode": "class KalmanBoxTracker(object):\n    count = 0\n    def __init__(self, bbox):\n        \"\"\"\n        Initialize a tracker using initial bounding box\n        Parameter 'bbox' must have 'detected class' int number at the -1 position.\n        \"\"\"\n        self.kf = KalmanFilter(dim_x=7, dim_z=4)\n        self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],[0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n        self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])",
        "detail": "yolo.v8.detect.sort",
        "documentation": {}
    },
    {
        "label": "Sort",
        "kind": 6,
        "importPath": "yolo.v8.detect.sort",
        "description": "yolo.v8.detect.sort",
        "peekOfCode": "class Sort(object):\n    def __init__(self, max_age=1, min_hits=3, iou_threshold=0.3):\n        \"\"\"\n        Parameters for SORT\n        \"\"\"\n        self.max_age = max_age\n        self.min_hits = min_hits\n        self.iou_threshold = iou_threshold\n        self.trackers = []\n        self.frame_count = 0",
        "detail": "yolo.v8.detect.sort",
        "documentation": {}
    },
    {
        "label": "linear_assignment",
        "kind": 2,
        "importPath": "yolo.v8.detect.sort",
        "description": "yolo.v8.detect.sort",
        "peekOfCode": "def linear_assignment(cost_matrix):\n    try:\n        import lap #linear assignment problem solver\n        _, x, y = lap.lapjv(cost_matrix, extend_cost = True)\n        return np.array([[y[i],i] for i in x if i>=0])\n    except ImportError:\n        from scipy.optimize import linear_sum_assignment\n        x,y = linear_sum_assignment(cost_matrix)\n        return np.array(list(zip(x,y)))\n\"\"\"From SORT: Computes IOU between two boxes in the form [x1,y1,x2,y2]\"\"\"",
        "detail": "yolo.v8.detect.sort",
        "documentation": {}
    },
    {
        "label": "iou_batch",
        "kind": 2,
        "importPath": "yolo.v8.detect.sort",
        "description": "yolo.v8.detect.sort",
        "peekOfCode": "def iou_batch(bb_test, bb_gt):\n    bb_gt = np.expand_dims(bb_gt, 0)\n    bb_test = np.expand_dims(bb_test, 1)\n    xx1 = np.maximum(bb_test[...,0], bb_gt[..., 0])\n    yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n    xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n    yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n    w = np.maximum(0., xx2 - xx1)\n    h = np.maximum(0., yy2 - yy1)\n    wh = w * h",
        "detail": "yolo.v8.detect.sort",
        "documentation": {}
    },
    {
        "label": "convert_bbox_to_z",
        "kind": 2,
        "importPath": "yolo.v8.detect.sort",
        "description": "yolo.v8.detect.sort",
        "peekOfCode": "def convert_bbox_to_z(bbox):\n    w = bbox[2] - bbox[0]\n    h = bbox[3] - bbox[1]\n    x = bbox[0] + w/2.\n    y = bbox[1] + h/2.\n    s = w * h    \n    #scale is just area\n    r = w / float(h)\n    return np.array([x, y, s, r]).reshape((4, 1))\n\"\"\"Takes a bounding box in the centre form [x,y,s,r] and returns it in the form",
        "detail": "yolo.v8.detect.sort",
        "documentation": {}
    },
    {
        "label": "convert_x_to_bbox",
        "kind": 2,
        "importPath": "yolo.v8.detect.sort",
        "description": "yolo.v8.detect.sort",
        "peekOfCode": "def convert_x_to_bbox(x, score=None):\n    w = np.sqrt(x[2] * x[3])\n    h = x[2] / w\n    if(score==None):\n        return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.]).reshape((1,4))\n    else:\n        return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.,score]).reshape((1,5))\n\"\"\"This class represents the internal state of individual tracked objects observed as bbox.\"\"\"\nclass KalmanBoxTracker(object):\n    count = 0",
        "detail": "yolo.v8.detect.sort",
        "documentation": {}
    },
    {
        "label": "associate_detections_to_trackers",
        "kind": 2,
        "importPath": "yolo.v8.detect.sort",
        "description": "yolo.v8.detect.sort",
        "peekOfCode": "def associate_detections_to_trackers(detections, trackers, iou_threshold = 0.3):\n    \"\"\"\n    Assigns detections to tracked object (both represented as bounding boxes)\n    Returns 3 lists of \n    1. matches,\n    2. unmatched_detections\n    3. unmatched_trackers\n    \"\"\"\n    if(len(trackers)==0):\n        return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,5),dtype=int)",
        "detail": "yolo.v8.detect.sort",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "yolo.v8.detect.sort",
        "description": "yolo.v8.detect.sort",
        "peekOfCode": "def parse_args():\n    \"\"\"Parse input arguments.\"\"\"\n    parser = argparse.ArgumentParser(description='SORT demo')\n    parser.add_argument('--display', dest='display', help='Display online tracker output (slow) [False]',action='store_true')\n    parser.add_argument(\"--seq_path\", help=\"Path to detections.\", type=str, default='data')\n    parser.add_argument(\"--phase\", help=\"Subdirectory in seq_path.\", type=str, default='train')\n    parser.add_argument(\"--max_age\", \n                        help=\"Maximum number of frames to keep alive a track without associated detections.\", \n                        type=int, default=1)\n    parser.add_argument(\"--min_hits\", ",
        "detail": "yolo.v8.detect.sort",
        "documentation": {}
    },
    {
        "label": "DetectionTrainer",
        "kind": 6,
        "importPath": "yolo.v8.detect.train",
        "description": "yolo.v8.detect.train",
        "peekOfCode": "class DetectionTrainer(BaseTrainer):\n    def get_dataloader(self, dataset_path, batch_size, mode=\"train\", rank=0):\n        # TODO: manage splits differently\n        # calculate stride - check if model is initialized\n        gs = max(int(de_parallel(self.model).stride.max() if self.model else 0), 32)\n        return create_dataloader(path=dataset_path,\n                                 imgsz=self.args.imgsz,\n                                 batch_size=batch_size,\n                                 stride=gs,\n                                 hyp=dict(self.args),",
        "detail": "yolo.v8.detect.train",
        "documentation": {}
    },
    {
        "label": "Loss",
        "kind": 6,
        "importPath": "yolo.v8.detect.train",
        "description": "yolo.v8.detect.train",
        "peekOfCode": "class Loss:\n    def __init__(self, model):  # model must be de-paralleled\n        device = next(model.parameters()).device  # get model device\n        h = model.args  # hyperparameters\n        m = model.model[-1]  # Detect() module\n        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n        self.hyp = h\n        self.stride = m.stride  # model strides\n        self.nc = m.nc  # number of classes\n        self.no = m.no",
        "detail": "yolo.v8.detect.train",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "yolo.v8.detect.train",
        "description": "yolo.v8.detect.train",
        "peekOfCode": "def train(cfg):\n    cfg.model = cfg.model or \"yolov8n.yaml\"\n    cfg.data = cfg.data or \"coco128.yaml\"  # or yolo.ClassificationDataset(\"mnist\")\n    # trainer = DetectionTrainer(cfg)\n    # trainer.train()\n    from ultralytics import YOLO\n    model = YOLO(cfg.model)\n    model.train(**cfg)\nif __name__ == \"__main__\":\n    \"\"\"",
        "detail": "yolo.v8.detect.train",
        "documentation": {}
    },
    {
        "label": "DetectionValidator",
        "kind": 6,
        "importPath": "yolo.v8.detect.val",
        "description": "yolo.v8.detect.val",
        "peekOfCode": "class DetectionValidator(BaseValidator):\n    def __init__(self, dataloader=None, save_dir=None, pbar=None, logger=None, args=None):\n        super().__init__(dataloader, save_dir, pbar, logger, args)\n        self.data_dict = yaml_load(check_file(self.args.data), append_filename=True) if self.args.data else None\n        self.is_coco = False\n        self.class_map = None\n        self.metrics = DetMetrics(save_dir=self.save_dir, plot=self.args.plots)\n        self.iouv = torch.linspace(0.5, 0.95, 10)  # iou vector for mAP@0.5:0.95\n        self.niou = self.iouv.numel()\n    def preprocess(self, batch):",
        "detail": "yolo.v8.detect.val",
        "documentation": {}
    },
    {
        "label": "val",
        "kind": 2,
        "importPath": "yolo.v8.detect.val",
        "description": "yolo.v8.detect.val",
        "peekOfCode": "def val(cfg):\n    cfg.data = cfg.data or \"coco128.yaml\"\n    validator = DetectionValidator(args=cfg)\n    validator(model=cfg.model)\nif __name__ == \"__main__\":\n    val()",
        "detail": "yolo.v8.detect.val",
        "documentation": {}
    },
    {
        "label": "cli",
        "kind": 2,
        "importPath": "yolo.cli",
        "description": "yolo.cli",
        "peekOfCode": "def cli(cfg):\n    \"\"\"\n    Run a specified task and mode with the given configuration.\n    Args:\n        cfg (DictConfig): Configuration for the task and mode.\n    \"\"\"\n    # LOGGER.info(f\"{colorstr(f'Ultralytics YOLO v{ultralytics.__version__}')}\")\n    task, mode = cfg.task.lower(), cfg.mode.lower()\n    # Special case for initializing the configuration\n    if task == \"init\":",
        "detail": "yolo.cli",
        "documentation": {}
    },
    {
        "label": "DIR",
        "kind": 5,
        "importPath": "yolo.cli",
        "description": "yolo.cli",
        "peekOfCode": "DIR = Path(__file__).parent\n@hydra.main(version_base=None, config_path=str(DEFAULT_CONFIG.parent.relative_to(DIR)), config_name=DEFAULT_CONFIG.name)\ndef cli(cfg):\n    \"\"\"\n    Run a specified task and mode with the given configuration.\n    Args:\n        cfg (DictConfig): Configuration for the task and mode.\n    \"\"\"\n    # LOGGER.info(f\"{colorstr(f'Ultralytics YOLO v{ultralytics.__version__}')}\")\n    task, mode = cfg.task.lower(), cfg.mode.lower()",
        "detail": "yolo.cli",
        "documentation": {}
    }
]